{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigTable MTLM - dataset perplexity testing\n",
    "\n",
    "Aim of this notebook:\n",
    "1. Generate student + question datasets\n",
    "2. Generate N sets of encounters\n",
    "3. Report on agreement between these sets\n",
    "\n",
    "The error between the datasets (for large N) is the inherent probabilistic error in the model\n",
    "- How does this translate to tolerances in the $\\alpha$ and $\\delta$ parameters\n",
    "\n",
    "## Model perplexity\n",
    "A model $q$ is used to predict the values of a set of samples, $\\mathbf{x}$.  Perplexity is defined as:\n",
    "\n",
    "\\\\[{perplex}_{q}(\\mathbf{x}) = b^{-\\frac{1}{N}\\Sigma_{i=1}^{N}{log_{b}(q(x_i))}}\\\\]\n",
    "\n",
    "Perplexity is a measure of `surprise' as a divergence from the predictions that are seen in the true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from copy import copy\n",
    "from math import exp, sqrt, log\n",
    "from random import random, shuffle, choice, randint, uniform\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.constraints import non_neg, max_norm\n",
    "from numpy import array, mean, ones\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, multiply, subtract, add, Activation, Lambda, Flatten\n",
    "from keras.layers import Dense, concatenate, MaxPooling1D, LocallyConnected1D, Reshape, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras import constraints\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import generate_student_name\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIYIF SANAB '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_student_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = lambda z: 1/(1+exp(-z))\n",
    "\n",
    "class Question():\n",
    "    def __init__(self, qix, min_diff, max_diff, nt, n_active):\n",
    "        self.id = qix\n",
    "\n",
    "        if n_active:\n",
    "            if len(n_active)==2:\n",
    "                min_active = n_active[0]\n",
    "                max_active = n_active[1]\n",
    "                n_c =  numpy.random.choice(range(min_active, max_active+1))\n",
    "        else:\n",
    "            n_c = nt\n",
    "\n",
    "        choices = numpy.random.choice(range(nt), size=n_c, replace=False)\n",
    "        not_present= 0#min_diff\n",
    "        self.betas = [ not_present for _ in range(nt) ]        \n",
    "  \n",
    "        for c in choices:\n",
    "#             self.betas[c] = min_diff\n",
    "#             self.betas[c] = inv_sigmoid(p) \n",
    "#             self.betas[c]=0\n",
    "            self.betas[c]= uniform(min_diff, max_diff)\n",
    "    \n",
    "class Student():\n",
    "    def __init__(self, ix, min_a, max_a, nt=None):\n",
    "        self.id = ix\n",
    "        self.name = generate_student_name()\n",
    "        n_c = nt\n",
    "#         n_c = numpy.random.choice(range(int(nt/2),nt+1))\n",
    "#         n_c = numpy.random.choice(range(1,nt+1))\n",
    "        choices = numpy.random.choice(range(nt), size=n_c, replace=False)\n",
    "#         mass = random.uniform(0,(max_a-min_a)*len(choices))\n",
    "\n",
    "        not_present= 0 #min_a\n",
    "        \n",
    "        self.thetas = [ not_present for _ in range(nt) ]        \n",
    "\n",
    "                \n",
    "        minp=sigmoid(min_a)\n",
    "        maxp=sigmoid(max_a)\n",
    "                \n",
    "        for c in choices:\n",
    "#             self.betas[c] = min_diff\n",
    "#             assume_b = 6#uniform(1,11)\n",
    "#             assume_pass = uniform(.0001**(1/n_c), .9999**(1/n_c))\n",
    "# #             p = random.uniform(.0001**(1/n_c), .9999**(1/n_c))\n",
    "# #             p = random.uniform(minp, maxp)\n",
    "# #             self.thetas[c] = inv_sigmoid(p) + 6\n",
    "# #             self.thetas[c] = 0\n",
    "#             z = inv_sigmoid(assume_pass)\n",
    "#             th = z + assume_b\n",
    "#             self.thetas[c]= th\n",
    "            self.thetas[c] = uniform(min_a, max_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt_q(student: Student, q: Question):\n",
    "    p = calculate_pass_probability(student.thetas, q.betas)\n",
    "    this_att = uniform(0,1)\n",
    "    if (this_att <= p):\n",
    "        passed=1\n",
    "#         print(\"passed\")\n",
    "#         student.mastery[q.id] = 1\n",
    "    else:\n",
    "        passed=0\n",
    "\n",
    "    return p,passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pass_probability(thetas, betas):\n",
    "    p_pass = 1.0\n",
    "    for th,b in zip(thetas,betas):\n",
    "#         if b==0:\n",
    "#             p_pass_step=1.0\n",
    "#         else:\n",
    "#             if th==0:\n",
    "# #                 print(\"blocking component, ret 0\")\n",
    "#                 return 0\n",
    "#             else:\n",
    "        z = (th-b)\n",
    "        p_pass_step = 1.0 / (1.0 + exp(-z))\n",
    "# #                 print(th,\"vs\",b,\": \", p_pass_step)\n",
    "        p_pass *= p_pass_step # simple conjunctive model of success!\n",
    "    try:\n",
    "        pass\n",
    "#         print(\"p_pass={}\".format(p_pass))\n",
    "    except OverflowError:\n",
    "        p_pass = 0.0\n",
    "    #print(\"real p_pass = {}\".format(p_pass))\n",
    "    return p_pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qs(n_qs, nt, active_limits, beta_min, beta_max):\n",
    "\n",
    "    max_mag = sqrt((beta_max**2)*nt)\n",
    "    min_mag = sqrt((beta_min**2)*nt)\n",
    "    print(\"Vector length limits:\",min_mag,max_mag)\n",
    "\n",
    "    master_qs = [Question(qix, beta_min,beta_max, nt, active_limits) for qix in range(n_qs)]\n",
    "    mags = []\n",
    "    no_comps = []\n",
    "    for q in master_qs:\n",
    "        comps = [c for c in q.betas if c>0]\n",
    "        mag = sqrt(sum([ pow(b, 2) for b in comps ]))\n",
    "        print(\"Q:{}, difficulty={:.2f} across {} components\".format(q.id, mag, len(comps)))\n",
    "        mags.append(mag)\n",
    "        no_comps.append(len(comps))\n",
    "    \n",
    "    plt.hist(mags)\n",
    "    plt.show()\n",
    "    plt.hist(no_comps)\n",
    "    plt.show()\n",
    "    \n",
    "    for q in master_qs:\n",
    "        print(\"qid\",q.id,q.betas)\n",
    "    return master_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_students(n_students, nt, theta_min, theta_max):\n",
    "\n",
    "    psi_list = [ Student(psix, theta_min,theta_max, nt=nt) for psix in range(n_students)]\n",
    "    mags = []\n",
    "    for psi in psi_list[0:30]:\n",
    "#         print(psi.name, psi.thetas)\n",
    "        comps = [c for c in psi.thetas if c>0]\n",
    "        mag = sqrt(sum([ pow(b, 2) for b in comps ]))\n",
    "        print(\"{}, skill={:.2f} across {} comps\".format(psi.name, mag, len(comps)))\n",
    "        mags.append(mag)\n",
    "    \n",
    " ################ PLOTs follow\n",
    "\n",
    "    fig,ax = plt.subplots(1,2)\n",
    "    fig.set_size_inches(20,10)\n",
    "    \n",
    "    ax[0].hist(mags)\n",
    "    \n",
    "    if nt >1:\n",
    "        itemz = array([ s.thetas for s in psi_list ])\n",
    "    #     fig.set_size_inches(10, 10)\n",
    "        ax[1].scatter(itemz[:,0], itemz[:,1], alpha=0.2)\n",
    "        for i, txt in enumerate(itemz):\n",
    "            ax[1].annotate(i, (itemz[i,0], itemz[i,1]))\n",
    "        plt.show()\n",
    "    \n",
    "    return psi_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "This is where sh!t gets real.  We take our tr_len (1000?) students, and iterate over them 100 times to create 100,000 *complete examples* of a student attacking the curriculum.  The questions themselves are attacked in random order: the student has no intelligent guidance throught the material. (Obvious we may wish to provide that guidance at some point in the future.)\n",
    "\n",
    "Remember, there are only 12 exercises in the curriculum, so if the student is taking 60 or 70 goes to answer them all, that's pretty poor.  But some of these kids are dumb as lumber, so cut them some slack!  They will all get there in the end since by the CMU AFM practice will, eventually, make perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def generate_attempts(master_qs, psi_list):\n",
    "    attempts =[]\n",
    "    attempts_by_q = {}\n",
    "    attempts_by_psi = {}\n",
    "    attempt_n_map = Counter()\n",
    "\n",
    "    user_budget = math.inf\n",
    "    user_patience = 10 #math.inf\n",
    "    pass_to_remove = True\n",
    "    \n",
    "    passes=0\n",
    "    for run in range(1):\n",
    "        print(\"----{}\\n\".format(run))\n",
    "        for psi in psi_list:\n",
    "            spend=0\n",
    "            qs = [ix for ix in range(len(master_qs))]\n",
    "            while qs:\n",
    "                qix = random.choice(qs)\n",
    "                q = master_qs[qix]\n",
    "                passed=0\n",
    "\n",
    "                if psi.name not in attempts_by_psi:\n",
    "                    attempts_by_psi[psi.name]=[]\n",
    "\n",
    "                if q not in attempts_by_q:\n",
    "                    attempts_by_q[q]=[]\n",
    "\n",
    "                att = 0\n",
    "#                 while (not passed) and att<user_patience:\n",
    "#                     pp,passed = attempt_q(psi, q)\n",
    "#                     tup = (psi.id, q.id, passed, passed)\n",
    "#                     attempt_n_map[(q.id,psi.id)] += 1\n",
    "#                     attempts.append(tup)\n",
    "#                     print(\"p_pass was\",pp,\"=\",passed) #, \"run p:\", 1-(1-pp)**max_atts)\n",
    "#                     attempts_by_psi[psi.name].append(tup)\n",
    "#                     attempts_by_q[q].append(tup)\n",
    "#                     att += 1\n",
    "#                 if (not pass_to_remove) or (pass_to_remove and passed):\n",
    "#                     qs.remove(qix)\n",
    "                pp,passed = attempt_q(psi, q)\n",
    "                if passed:\n",
    "                    passes+=1\n",
    "                tup = (psi.id, q.id, passed, passed)\n",
    "                attempt_n_map[(q.id,psi.id)] += 1\n",
    "                attempts.append(tup)\n",
    "#                 print(\"p_pass was\",pp,\"=\",passed) #, \"run p:\", 1-(1-pp)**max_atts)\n",
    "                attempts_by_psi[psi.name].append(tup)\n",
    "                attempts_by_q[q].append(tup)\n",
    "                att += 1\n",
    "                qs.remove(qix)\n",
    "#                 print(\"len qs is\", len(qs))\n",
    "    gc.collect()\n",
    "    print(\"passed {}/{}\".format(passes,len(attempts)))\n",
    "    return attempts, attempts_by_q, attempts_by_psi, attempt_n_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from IPython.display import clear_output\n",
    "\n",
    "serieses = []\n",
    "min_errs = []\n",
    "n_qs = 100\n",
    "n_students = 100\n",
    "n_epochs = 10\n",
    "\n",
    "# desired confusion prop/n mx\n",
    "# .5  0 \n",
    "#  0 .5\n",
    "\n",
    "def gen_run(n_traits, minth, maxth, minb, maxb, min_active_traits, max_active_traits):\n",
    "    qs = create_qs(n_qs, n_traits, (min_active_traits, max_active_traits), minb, maxb)\n",
    "    #     qs, q_table = create_qs_from_blobs(n_qs, 2, n_traits)\n",
    "    ss = create_students(n_students, n_traits, minth, maxth)\n",
    "\n",
    "    x = []\n",
    "\n",
    "    for _ in range(1):\n",
    "        xa, _,_,_ = generate_attempts(qs,ss) # this is our x list of samples\n",
    "        x.extend(xa)\n",
    "\n",
    "    tp,fp,tn,fn=0,0,0,0\n",
    "    base = 2\n",
    "    summa=0\n",
    "    N = len(x)\n",
    "    for tup in x:\n",
    "        (psi_id, q_id, passed, passed) = tup\n",
    "        p = calculate_pass_probability(ss[psi_id].thetas, qs[q_id].betas)\n",
    "        summa += log((p if passed else (1-p)), base)\n",
    "\n",
    "        pp = uniform(0,1)\n",
    "        if pp <= p:\n",
    "            if passed:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "        else:\n",
    "            if passed:\n",
    "                fn+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "\n",
    "    acc = (tp+tn)/len(x)\n",
    "    print(\"model acc:\",acc)\n",
    "    print(tp,fp)\n",
    "    print(fn,tn)\n",
    "\n",
    "    ppx = pow( base, (-summa/N))\n",
    "    print(\"perplexity is {}\".format(ppx))\n",
    "    return (fn + fp) + abs(tp-tn), tp,tn,fp,fn\n",
    "    \n",
    "dims_scores = {}\n",
    "param_freedom = 10\n",
    "random.seed()\n",
    "seen = set()\n",
    "mini = 1\n",
    "maxi = 100\n",
    "#dimslist = [1,2,3,5,10,25,100]:\n",
    "for dims in [100]:\n",
    "    i=0\n",
    "    while i < 100:\n",
    "#         minb = 1\n",
    "#         maxb = uniform(minb,minb+maxi)\n",
    "#         minth = uniform(minb,maxb)\n",
    "#         maxth = uniform(minth,minth+maxi)\n",
    "        \n",
    "        minb = uniform(mini,maxi)\n",
    "        maxb = uniform(minb,minb+maxi)\n",
    "        minth = uniform(minb,maxb+maxi)\n",
    "        maxth = uniform(maxb+maxi,maxb+2*maxi)\n",
    "    \n",
    "        if (dims,minb,maxb,minth,maxth) in seen:\n",
    "            continue\n",
    "        clear_output()\n",
    "        seen.add((dims,minb,maxb,minth,maxth))\n",
    "        i+=1\n",
    "        print(\">>>\",i)\n",
    "        outz = gen_run(dims, minth, maxth, minb, maxb, dims, dims)\n",
    "        loss, losstup = outz[0], outz[1:]\n",
    "        if (dims not in dims_scores) or (dims_scores[dims][0] > loss):\n",
    "            dims_scores[dims] = (loss, losstup, minth,maxth,minb,maxb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 (1930, (4972, 4035, 473, 520), 174.41967776840482, 334.3340155161033, 94.16026461348221, 187.59829029717753)\n"
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "for dim in dims_scores:\n",
    "    tup = dims_scores[dim]\n",
    "    print(dim, tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
