{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rasch (Nx1PL) MLTM\n",
    "(Based on Cen 2009)\n",
    "This model is used to explain the power law in learning.  In this notebook we try to build a neuralised version of the AFM and train it using simulated data.  The aim of using the AFM is to disentangle the latent traits that make up the overall score going into the sigmoid probability estimator.\n",
    "\n",
    "The model is compensatory, which is a weakness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from copy import copy\n",
    "from math import exp, sqrt, log\n",
    "from random import random, shuffle, choice, randint, uniform\n",
    "import numpy\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.constraints import non_neg, max_norm\n",
    "from numpy import array, mean, ones\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, multiply, subtract, add, Activation, Lambda, Flatten\n",
    "from keras.layers import Dense, concatenate, MaxPooling1D, LocallyConnected1D, Reshape\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras import constraints\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import generate_student_name\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "n_traits = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PHUDOY JECU '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_student_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.constraints import Constraint\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers\n",
    "\n",
    "class WeightClip(Constraint):\n",
    "    '''Clips the weights incident to each hidden unit to be inside a range\n",
    "    '''\n",
    "    def __init__(self, min_w=0, max_w=4):\n",
    "        self.min_w = min_w\n",
    "        self.max_w = max_w\n",
    "\n",
    "    def __call__(self, p):\n",
    "        return K.clip(p, self.min_w, self.max_w)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__,\n",
    "                'min_w': self.min_w,\n",
    "                'max_w': self.max_w }\n",
    "\n",
    "\n",
    "class ProductLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, kernel_constraint=WeightClip(min_w=-4.0, max_w=4.0), minv=-4,maxv=4, **kwargs):\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        super(ProductLayer, self).__init__(**kwargs)\n",
    "        self.kernel_constraint= constraints.get(kernel_constraint)\n",
    "        self.min_v = minv\n",
    "        self.max_v = maxv\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(1, self.output_dim),\n",
    "                                      initializer=initializers.RandomUniform(minval=self.min_v,maxval=self.max_v),\n",
    "#                                       initializer=initializers.Constant(value=2.0),\n",
    "                                      trainable=True,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        \n",
    "        super(ProductLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        p = x * self.kernel\n",
    "        print(\"shape p\", p.shape)\n",
    "        return p\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "class DifferenceLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, kernel_constraint=WeightClip(min_w=-4.0, max_w=4.0), minv=-4,maxv=4, invert=False, **kwargs):\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        super(DifferenceLayer, self).__init__(**kwargs)\n",
    "        self.kernel_constraint= constraints.get(kernel_constraint)\n",
    "        self.min_v = minv\n",
    "        self.max_v = maxv\n",
    "        self.invert = invert\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        initialiser = initializers.RandomUniform(minval=self.min_v,maxval=self.max_v)\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(1, self.output_dim),\n",
    "                                      initializer=initialiser,\n",
    "#                                       initializer=initializers.Constant(value=2.0),\n",
    "                                      trainable=True,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        super(DifferenceLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.invert:\n",
    "            x = tf.Print(x, [x], message=\"x is:\", first_n=-1, summarize=1024)\n",
    "            k = tf.Print(self.kernel, [self.kernel], message=\"- kernel is:\", first_n=-1, summarize=1024)\n",
    "            p = x - k\n",
    "        else:\n",
    "            k = tf.Print(self.kernel, [self.kernel], message=\"kernel is:\", first_n=-1, summarize=1024)\n",
    "            x = tf.Print(x, [x], message=\"- x is:\", first_n=-1, summarize=1024)\n",
    "            p = k - x\n",
    "#         p = K.print_tensor(p, message=\"p is:\")\n",
    "        p =  tf.Print(p, [p], message=\"p is:\", first_n=-1, summarize=1024)\n",
    "        print(\"shape p\", p.shape)\n",
    "        return p\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20 2.0611536181902037e-09\n",
      "-10 4.5397868702434395e-05\n",
      "-4 0.01798620996209156\n",
      "-3 0.04742587317756678\n",
      "-2 0.11920292202211755\n",
      "-1 0.2689414213699951\n",
      "0 0.5\n",
      "1 0.7310585786300049\n",
      "2 0.8807970779778823\n",
      "3 0.9525741268224334\n",
      "4 0.9820137900379085\n",
      "delz 3.650491699884092 -1.2447699535774288\n",
      "spread 4.895261653461521\n",
      "th 4 11\n",
      "b 0 6\n",
      "max prob (rnd) 0.999983298578152\n",
      "min prob (rnd) 0.11920292202211755\n",
      "max actl prob 0.9999665974352416\n",
      "min actl prob 0.014209336618611037\n"
     ]
    }
   ],
   "source": [
    "for z in [-20, -10, -4,-3,-2,-1,0,1,2,3,4]:\n",
    "    print(z, 1/(1+exp(-z)) )\n",
    "    \n",
    "    \n",
    "# q_p_avg = 0.45\n",
    "\n",
    "q_p_easiest = 0.95\n",
    "q_p_hardest = 0.05\n",
    "\n",
    "# pr_k_avg = q_p_avg**(1/n_traits)\n",
    "# print(\"pr k avg:\", pr_k_avg)\n",
    "\n",
    "pr_k_easiest = q_p_easiest**(1/n_traits)\n",
    "pr_k_hardest = q_p_hardest**(1/n_traits)\n",
    "\n",
    "inv_sigmoid = lambda pr : ( -log((1/pr) -1) )\n",
    "k_delta_easiest = inv_sigmoid(pr_k_easiest)\n",
    "k_delta_hardest = inv_sigmoid(pr_k_hardest)\n",
    "\n",
    "print(\"delz\", k_delta_easiest, k_delta_hardest)\n",
    "import math\n",
    "\n",
    "spread = k_delta_easiest - k_delta_hardest\n",
    "print(\"spread\",spread)\n",
    "\n",
    "beta_min = 0 #math.floor(0)\n",
    "beta_max = 6 #math.ceil(beta_min + spread/2.0)\n",
    "\n",
    "theta_min = 4 # math.floor(beta_max + spread/2.0)\n",
    "theta_max = 11 # theta_min + math.ceil(k_delta_easiest)\n",
    "\n",
    "print(\"th\", theta_min, theta_max)\n",
    "print(\"b\", beta_min, beta_max)\n",
    "\n",
    "max_comp_prob = 1/(1+exp(-(theta_max - beta_min)))\n",
    "min_comp_prob = 1/(1+exp(-(theta_min - beta_max)))\n",
    "\n",
    "print(\"max prob (rnd)\", max_comp_prob)\n",
    "print(\"min prob (rnd)\", min_comp_prob)\n",
    "\n",
    "print(\"max actl prob\", (max_comp_prob)**n_traits)\n",
    "print(\"min actl prob\", (min_comp_prob)**n_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question():\n",
    "    def __init__(self, qix, min_diff, max_diff, nt=None, nnw=None, optimiser=None):\n",
    "        #self.MAX_BETA = 15\n",
    "        self.id = qix\n",
    "#         no_dummies = randint(1,(nt-1))\n",
    "#         print(\"no_dummies=\",no_dummies)\n",
    "#         not_present=-20\n",
    "#         min_diff = 0\n",
    "#         max_diff = 10\n",
    "#         self.betas = [ not_present for _ in range(nt) ]\n",
    "        self.betas = [randint(min_diff,max_diff) for _ in range(nt)]\n",
    "#         print(\"nt=\",nt)\n",
    "#         choices = [ x for x in range(nt) ]\n",
    "#         for _ in range(no_dummies):\n",
    "#             ch = random.choice(choices)\n",
    "#             choices.remove(ch)\n",
    "#             self.betas[ch]=randint(min_diff,max_diff)\n",
    "        #print(\"Made q with betas:\", self.betas)\n",
    "        \n",
    "        th = Input(shape=(nnw,), name=\"user_theta\")\n",
    "        b_in = Input(shape=(nnw,), name=\"beta_in\")\n",
    "        av_diff = (min_diff + max_diff)/2.0\n",
    "#         bvar = ProductLayer(nnw\n",
    "#                             , kernel_constraint=WeightClip(min_w=min_diff, max_w=max_diff), minv=0.9*av_diff,maxv=1.1*av_diff) # introduce nt trainable weights for the beta values\n",
    "#         b = bvar(b_in)\n",
    "        \n",
    "        bvar = DifferenceLayer(nnw, kernel_constraint=WeightClip(min_w=min_diff, max_w=max_diff), minv=0.9*av_diff,maxv=1.1*av_diff, invert=True) # introduce nt trainable weights for the beta values)\n",
    "        dif =bvar(th)\n",
    "#         dif = subtract([th,b])\n",
    "        print(\"dif\",dif.shape)\n",
    "#         Pr = Dense(1, activation=\"sigmoid\")(dif)\n",
    "        Prs = Lambda(lambda z: 1.0 / (1.0 + K.exp(-z)), name=\"qPr_sigmoid\")(dif)\n",
    "        print(\"Prs\",Prs.shape)\n",
    "        Pr = Lambda(lambda ps: K.prod(ps, axis=1, keepdims=True), name=\"qPr_prod\")(Prs)\n",
    "        print(\"Pr_prod\",Pr.shape)\n",
    "#         Pr = Reshape((1,))(Pr)\n",
    "#         print(\"Pr\",Pr.shape)\n",
    "        model = Model(inputs=[th,b_in], outputs=Pr)\n",
    "#         o = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#         optimiser = Adam(lr=0.1)\n",
    "        model.compile(optimizer=optimiser, loss=\"binary_crossentropy\", metrics=[\"mse\",\"accuracy\"])\n",
    "        self.model = model\n",
    "        self.pred_betas = bvar\n",
    "        print(\"q weights at init\", model.get_weights())\n",
    "        \n",
    "        \n",
    "# qs = [Question(qix, n_traits) for qix in range(10)]\n",
    "# qs[0].model.summary()\n",
    "\n",
    "# random.seed(666)\n",
    "# qs = [Question(qix, n_traits) for qix in range(10)]\n",
    "# for q in qs:\n",
    "#     print(q.id, q.betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student():\n",
    "    def __init__(self, min_abil, max_abil, nt=None, nnw=None, optimiser=None):\n",
    "        #self.MAX_BETA = 15\n",
    "        self.name = generate_student_name()\n",
    "#         min_abil = 0\n",
    "#         max_abil = 10\n",
    "        self.thetas = [ randint(min_abil, max_abil) for _ in range(nt) ]\n",
    "#         self.mastery = [0 for _ in range(nq)]\n",
    "#         self.o_practice = [0 for _ in range(nq)]\n",
    "#         self.h_practice = [0 for _ in range(nt)]\n",
    "        #print(\"Made q with betas:\", self.betas)\n",
    "        th_in = Input(shape=(nnw,), name=\"theta_in\")\n",
    "        b = Input(shape=(nnw,), name=\"qn_beta\")\n",
    "        av_abil = (min_abil + max_abil)/2.0\n",
    "#         th_var = ProductLayer(nnw, kernel_constraint=WeightClip(min_w=min_abil, max_w=max_abil), minv=0.9*av_abil, maxv=1.1*av_abil) # introduce nt trainable weights for the beta values\n",
    "\n",
    "        th_var = DifferenceLayer(nnw, kernel_constraint=WeightClip(min_w=min_abil, max_w=max_abil), minv=0.9*av_abil,maxv=1.1*av_abil, invert=False) # introduce nt trainable weights for the beta values)\n",
    "        dif = th_var(b)\n",
    "\n",
    "#         th = th_var(th_in)\n",
    "#         dif = subtract([th,b])\n",
    "        print(\"dif\",dif.shape)\n",
    "        Prs = Lambda(lambda z: 1.0 / (1.0 + K.exp(-z)), name=\"sPr_sigmoid\")(dif)\n",
    "        print(\"Prs\",Prs.shape)\n",
    "        Pr = Lambda(lambda ps: K.prod(ps, axis=1, keepdims=True), name=\"sPr_prod\")(Prs)\n",
    "        print(\"Pr\",Pr.shape)\n",
    "#         Pr = Reshape((1,))(Pr)\n",
    "        model = Model(inputs=[th_in,b], outputs=Pr)\n",
    "#         o = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#         optimiser= Adam(lr=0.1)\n",
    "        model.compile(optimizer=optimiser, loss=\"binary_crossentropy\", metrics=[\"mse\",\"accuracy\"])\n",
    "#         print(\"s weights at init\", model.get_weights())\n",
    "        self.model = model\n",
    "        self.pred_theta = th_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt_q(student: Student, q: Question):\n",
    "    p = calculate_pass_probability(student.thetas, q.betas)\n",
    "    this_att = uniform(0,1)\n",
    "    if (this_att <= p):\n",
    "        passed=True\n",
    "#         student.mastery[q.id] = 1\n",
    "    else:\n",
    "        passed=False\n",
    "\n",
    "    return passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pass_probability(thetas, betas):\n",
    "    # additive factors model is:\n",
    "    # p_pass = 1 / 1 + exp(-z)\n",
    "    # where z = a + sum[1:n]( -b + gT )\n",
    "    \n",
    "    p_pass = 1.0\n",
    "    print(\"th,b\",thetas,betas)\n",
    "    for th,b in zip(thetas,betas):\n",
    "#         if b < 0:\n",
    "#             continue\n",
    "        z = (th-b)\n",
    "        p_pass_step = 1.0 / (1.0 + exp(-z))\n",
    "        p_pass *= p_pass_step # simple conjunctive model of success!\n",
    "    try:        \n",
    "        print(\"p_pass={}\".format(p_pass))\n",
    "    except OverflowError:\n",
    "        p_pass = 0.0\n",
    "    #print(\"real p_pass = {}\".format(p_pass))\n",
    "    return p_pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qopt = Adam(lr=0.01)\n",
    "\n",
    "def create_qs(n_qs, nt=n_traits, nnw=n_traits, optimiser=qopt):\n",
    "    random.seed(666)\n",
    "    master_qs = [Question(qix, beta_min,beta_max, nt=nt, nnw=nnw, optimiser=optimiser) for qix in range(n_qs)]\n",
    "    for q in master_qs:\n",
    "        nocomps = len(q.betas)\n",
    "        mag = sqrt(sum([ pow(b, 2) for b in q.betas if b!=-10 ]))\n",
    "        print(\"Q:{}, difficulty={:.2f} across {} components\".format(q.id, mag, nocomps))\n",
    "    return master_qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "This is where sh!t gets real.  We take our tr_len (1000?) students, and iterate over them 100 times to create 100,000 *complete examples* of a student attacking the curriculum.  The questions themselves are attacked in random order: the student has no intelligent guidance throught the material. (Obvious we may wish to provide that guidance at some point in the future.)\n",
    "\n",
    "Remember, there are only 12 exercises in the curriculum, so if the student is taking 60 or 70 goes to answer them all, that's pretty poor.  But some of these kids are dumb as lumber, so cut them some slack!  They will all get there in the end since by the CMU AFM practice will, eventually, make perfect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi_opt = Adam()\n",
    "def create_students(n_students, nt=n_traits, nnw=n_traits, optimiser=None):\n",
    "    random.seed(666)\n",
    "    psi_list = [ Student(theta_min,theta_max, nt=nt, nnw=nnw, optimiser=optimiser) for _ in range(n_students)]\n",
    "    for psi in psi_list:\n",
    "        print(psi.name, psi.thetas)\n",
    "    return psi_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_pop=False\n",
    "extend_by = 90\n",
    "if extend_pop:\n",
    "    for _ in range(extend_by):\n",
    "        nu_psi = Student(nt=n_traits, nq=len(master_qs), optimiser=psi_opt)\n",
    "        psi_list.append(nu_psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def generate_attempts(master_qs, psi_list):\n",
    "    attempts_by_psi = {}\n",
    "    attempts_by_q = {}\n",
    "\n",
    "    user_budget = 100\n",
    "    user_patience = 10\n",
    "    for run in range(1):\n",
    "        print(\"----{}\\n\".format(run))\n",
    "        for psi in psi_list:\n",
    "            spend=0\n",
    "            #psi.mastery = [0 for _ in range(nq)]\n",
    "            qs = [ix for ix in range(len(master_qs))]\n",
    "            print(\"* * * **** USER {}\".format(psi.name))\n",
    "            print(\"* * * * ** THETAS {}\".format(psi.thetas))\n",
    "\n",
    "            while(True):\n",
    "                q_ct = 0\n",
    "                qix = random.choice(qs)\n",
    "                q = master_qs[qix]\n",
    "                passed=False\n",
    "\n",
    "                if psi.name not in attempts_by_psi:\n",
    "                    attempts_by_psi[psi.name]=[]\n",
    "\n",
    "                if q not in attempts_by_q:\n",
    "                    attempts_by_q[q]=[]\n",
    "\n",
    "                while not passed and q_ct<user_patience:\n",
    "                    passed = attempt_q(psi, q)\n",
    "                    tup = (psi, q, passed)\n",
    "                    #attempts.append(tup)\n",
    "                    attempts_by_psi[psi.name].append(tup)\n",
    "                    attempts_by_q[q].append(tup)\n",
    "                    q_ct+=1\n",
    "\n",
    "                if passed:\n",
    "                    print(\"passed\")\n",
    "                    qs.remove(qix)\n",
    "\n",
    "                spend += 1\n",
    "\n",
    "                if qs == [] or spend>=user_budget:\n",
    "                        print(\"* ** *QFIN USER {}\".format(psi.name))\n",
    "                        break\n",
    "    gc.collect()\n",
    "    return attempts_by_psi, attempts_by_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "def calibrate(master_qs, psi_list, attempts_by_q, attempts_by_psi, n_iter=20, record_param_fit=False):\n",
    "    es = EarlyStopping(monitor=\"loss\", mode=\"auto\")\n",
    "    random.seed(666)\n",
    "    min_mse = 1000\n",
    "    min_avg_fit_rmse = 1000\n",
    "    mses=[]\n",
    "    accs=[]\n",
    "    q_outer_mses = []\n",
    "    q_outer_accs = []\n",
    "    s_outer_mses = []\n",
    "    s_outer_accs = []\n",
    "    th_mses = []\n",
    "    b_mses = []\n",
    "    th_accs= []\n",
    "    b_accs =[]\n",
    "    avg_fit_rmses = []\n",
    "    th_fit_rmses = []\n",
    "    b_fit_rmses = []\n",
    "\n",
    "    losses = []\n",
    "    for ix in range(n_iter):\n",
    "        gc.collect()\n",
    "        q_clf_accs = []\n",
    "        q_clf_mses = []\n",
    "        q_clf_losses = []\n",
    "#         for q in master_qs:\n",
    "        q = random.choice(master_qs)\n",
    "        if True:\n",
    "            print(q.id)\n",
    "            thetas = [ tup[0].pred_theta.get_weights()[0][0] for tup in attempts_by_q[q]]\n",
    "            pfs = [ [tup[2]] for tup in attempts_by_q[q]]\n",
    "            preb = q.pred_betas.get_weights()[0][0]\n",
    "            \n",
    "            arr_thetas = array(thetas)\n",
    "            arr_pfs = array(pfs)\n",
    "            arr_ones = numpy.ones( (len(thetas),len(thetas[0])) )            \n",
    "            print(\"q arr_ones, shape:\", arr_ones.shape)\n",
    "            \n",
    "            h = q.model.fit(x=[arr_thetas, arr_ones], y=arr_pfs, verbose=0, batch_size=1, callbacks=[es])\n",
    "            del h\n",
    "            #gc.collect()\n",
    "            \n",
    "            loss, mse, acc = q.model.evaluate(x=[arr_thetas, arr_ones], y=arr_pfs, verbose=0)\n",
    "            q_clf_accs.append(acc)\n",
    "            q_clf_mses.append(mse)\n",
    "            q_clf_losses.append(loss)\n",
    "            postb = q.pred_betas.get_weights()[0][0]\n",
    "            print(\"q{} true({}), preb {} postb {}\".format(q.id, q.betas, preb, postb))\n",
    "\n",
    "        s_clf_accs=[]\n",
    "        s_clf_mses=[]\n",
    "        s_clf_losses = []\n",
    "#         for _student in psi_list:\n",
    "        _student = random.choice(psi_list)\n",
    "        if True:\n",
    "            betas = [ tup[1].pred_betas.get_weights()[0][0] for tup in attempts_by_psi[_student.name]]# if tup[1]==q]\n",
    "            pfs = [ [tup[2]] for tup in attempts_by_psi[_student.name]]# if tup[1]==q]\n",
    "            preth= _student.pred_theta.get_weights()[0][0] \n",
    "\n",
    "            arr_betas = array(betas)\n",
    "            arr_pfs = array(pfs)\n",
    "            arr_ones = numpy.ones( (len(betas),len(betas[0])) )\n",
    "            print(\"student shape arr ones = \", arr_ones.shape)\n",
    "            \n",
    "            h = _student.model.fit(x=[arr_ones, arr_betas], y=arr_pfs, verbose=0, batch_size=1, callbacks=[es])\n",
    "            del h\n",
    "                        \n",
    "            loss, mse, acc = _student.model.evaluate(x=[arr_ones, arr_betas], y=arr_pfs, verbose=0)\n",
    "            s_clf_accs.append(acc)\n",
    "            s_clf_mses.append(mse)\n",
    "            s_clf_losses.append(loss)\n",
    "            postth= _student.pred_theta.get_weights()[0][0]\n",
    "            print(\"s{}: true({}), {} -> {}\".format(_student.name, _student.thetas, preth, postth))\n",
    "\n",
    "#         th_rmse = sqrt(mean([(numpy.sort(s.thetas) - numpy.sort(s.pred_theta.get_weights()[0][0]))**2 for s in psi_list]))\n",
    "#         b_rmse = sqrt(mean([(numpy.sort(q.betas) - numpy.sort(q.pred_betas.get_weights()[0][0]))**2 for q in master_qs]))\n",
    "\n",
    "#         avg_fit_rmse = (th_rmse + b_rmse)/2.0\n",
    "        mse = (mean(s_clf_mses) + mean(q_clf_mses))/2.0\n",
    "        acc = (mean(s_clf_accs) + mean(q_clf_accs)) /2.0\n",
    "        loss = (mean(s_clf_losses) + mean(q_clf_losses)) /2.0\n",
    "        \n",
    "        if(record_param_fit):\n",
    "            th_rmse = sqrt(mean([(numpy.sort(s.thetas) - numpy.sort(s.pred_theta.get_weights()[0][0]))**2 for s in psi_list]))\n",
    "            b_rmse = sqrt(mean([(numpy.sort(q.betas) - numpy.sort(q.pred_betas.get_weights()[0][0]))**2 for q in master_qs]))\n",
    "\n",
    "        print(\"iteration\",ix)\n",
    "#         print(\"b rmse:\", b_rmse, \"del:\", (beta_rmses[-1] - b_rmse) if beta_rmses else 0)\n",
    "#         print(\"th rmse: {} del: {}\".format(th_rmse, (theta_rmses[-1] - th_rmse) if theta_rmses else 0))\n",
    "        print(\"avg clf mse: {} del: {}\".format(mse, (mses[-1] - mse) if mses else 0))\n",
    "        print(\"avg clf loss {} del {}\".format(loss, (losses[-1]-loss) if losses else 0))\n",
    "        print(\"acc = {}\".format(acc))\n",
    "#         theta_rmses.append(th_rmse)\n",
    "#         beta_rmses.append(b_rmse)\n",
    "        mses.append(mse)\n",
    "        accs.append(acc)\n",
    "\n",
    "        if record_param_fit:\n",
    "            th_fit_rmses.append(th_rmse)\n",
    "            b_fit_rmses.append(b_rmse)\n",
    "        \n",
    "        th_mses.append(mean(s_clf_mses))\n",
    "        b_mses.append(mean(q_clf_mses))\n",
    "        th_accs.append(mean(s_clf_accs))\n",
    "        b_accs.append(mean(q_clf_accs))\n",
    "#         avg_fit_rmses.append(avg_fit_rmse)\n",
    "#         s_outer_mses.append(mean(s_clf_mses))\n",
    "#         s_outer_accs.append(mean(s_clf_accs))\n",
    "#         q_outer_mses.append(mean(q_clf_mses))\n",
    "#         q_outer_accs.append(mean(q_clf_accs))\n",
    "        losses.append(loss)\n",
    "\n",
    "#         if(min_fit_rmse > avg_fit_rmse):\n",
    "#             min_fit_rmse = avg_fit_rmse\n",
    "        \n",
    "#         if(min_loss > loss):\n",
    "#             min_loss = loss\n",
    "#             patience_ct = 0\n",
    "#         else:\n",
    "#             patience_ct += 1\n",
    "#         if patience_ct > max_pat:\n",
    "#             print(\"patience exhausted:\",max_pat,\"iterations with no new clf MSE minimum\")\n",
    "#             break\n",
    "\n",
    "        duration = .3  # second\n",
    "        freq = 440  # Hz\n",
    "#         os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))\n",
    "        \n",
    "#     print(\"final beta rmse = {}\".format(beta_rmses[-1]))\n",
    "#     print(\"final theta rmse = {}\".format(theta_rmses[-1]))\n",
    "#     print(\"final avg fit rmse = {}\".format(avg_fit_rmses[-1]))\n",
    "    print(\"final classifier mse = {}\".format(mses[-1]))\n",
    "    print(\"final acc = {}\".format(accs[-1]))\n",
    "    print(\"final loss = {}\".format(losses[-1]))\n",
    "    print(\"min mse =\", min_mse)\n",
    "\n",
    "    for m in [1, 1.5, 2, 2.5, 3]:\n",
    "        duration = .1  # second\n",
    "        freq = 440*m  # Hz\n",
    "        os.system('play --no-show-progress --null --channels 1 synth %s sine %f' % (duration, freq))\n",
    "#     jingle = IPython.display.Audio(\"calibration_complete.mp3\", autoplay=True)\n",
    "#     del jingle\n",
    "\n",
    "    if record_param_fit:\n",
    "        return th_fit_rmses,b_fit_rmses\n",
    "    else:\n",
    "        return (mses,accs, th_mses,th_accs, b_mses,b_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape p (?, 2)\n",
      "dif (?, 2)\n",
      "Prs (?, 2)\n",
      "Pr_prod (?, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7e73e60ef3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_students\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnnw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_traits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_students\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_students\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_traits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mattempts_by_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattempts_by_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_attempts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-d30568cdcb5e>\u001b[0m in \u001b[0;36mcreate_qs\u001b[0;34m(n_qs, nt, nnw, optimiser)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_traits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_traits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmaster_qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mQuestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimiser\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaster_qs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnocomps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-d30568cdcb5e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_traits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_traits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmaster_qs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mQuestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_min\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimiser\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaster_qs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnocomps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-af3e96e75a3f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, qix, min_diff, max_diff, nt, nnw, optimiser)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_betas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q weights at init\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1989\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \"\"\"\n\u001b[1;32m   2201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2203\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 182\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1291\u001b[0m                 run_metadata):\n\u001b[1;32m   1292\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1294\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         graph_def, self._current_version = self._graph._as_graph_def(\n\u001b[1;32m   1348\u001b[0m             \u001b[0mfrom_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             add_shapes=self._add_shapes)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venvs/isaac/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   2722\u001b[0m       \u001b[0mbytesize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mop_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_version\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mop_id\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mfrom_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m           \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn_dimensions = [n_traits]\n",
    "serieses = []\n",
    "min_errs = []\n",
    "n_qs = 10\n",
    "n_students = 100\n",
    "for ix,nnw in enumerate(nn_dimensions):\n",
    "    qs = create_qs(n_qs, n_traits, nnw, optimiser=qopt)\n",
    "    ss = create_students(n_students, n_traits, nnw, optimiser=qopt)\n",
    "    attempts_by_psi, attempts_by_q = generate_attempts(qs,ss)\n",
    "    print(qs[0].pred_betas.get_weights()[0][0])\n",
    "    print(ss[0].pred_theta.get_weights()[0][0])\n",
    "    th_rmses,b_rmses = calibrate(qs,ss,attempts_by_q, attempts_by_psi, n_iter=1000, record_param_fit=True)\n",
    "#     serieses += resultz\n",
    "    serieses.append( (th_rmses,b_rmses) )\n",
    "#     if ix < len(serieses): #append to old series\n",
    "#         (_mses,_accs) = serieses[ix]\n",
    "#         _mses += mses\n",
    "#         _accs += accs\n",
    "#         serieuses[ix] = (_mses,_accs)\n",
    "#     else: #create new series\n",
    "#         serieses.append((mses,accs))\n",
    "    gc.collect()\n",
    "from pygame import mixer\n",
    "mixer.init()\n",
    "mixer.music.load('calibration_complete.mp3')\n",
    "mixer.music.play()\n",
    "\n",
    "xs = range(len(th_rmses))\n",
    "# plt.plot(xs, numpy.multiply(1,theta_rmses), 'b--')\n",
    "# plt.plot(xs, numpy.multiply(1,beta_rmses), 'b')\n",
    "for th_rmses, b_rmses in serieses:\n",
    "    plt.plot(xs, numpy.multiply(1,th_rmses), label=\"w=5, students\"),\n",
    "    plt.plot(xs, numpy.multiply(1,b_rmses), label=\"w=5, qns\")\n",
    "\n",
    "# plt.plot(xs, accs, \"m\")\n",
    "# plt.plot(xs, numpy.multiply(1,s_outer_accs), \"g\")\n",
    "# plt.plot(xs, numpy.multiply(1,q_outer_accs), \"k\")\n",
    "\n",
    "# plt.plot(xs, numpy.multiply(1,mses), \"m--\")\n",
    "# plt.plot(xs, numpy.multiply(1,s_outer_mses), \"g--\")\n",
    "# plt.plot(xs, numpy.multiply(1,q_outer_mses), \"k--\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 5)\n",
    "plt.xlabel(\"#iterations\")\n",
    "plt.ylabel(\"fit error (RMSE)\")\n",
    "plt.suptitle(\"Neural-MLTM Parameter Fitting\")\n",
    "plt.title(\"(skills=5, items=10, students=100)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_traits = 5\n",
    "nn_dimensions = [1,3,5,7,9]\n",
    "serieses = []\n",
    "min_errs = []\n",
    "n_qs = 10\n",
    "n_students = 100\n",
    "for ix,nnw in enumerate(nn_dimensions):\n",
    "    qs = create_qs(n_qs, n_traits, nnw, optimiser=qopt)\n",
    "    ss = create_students(n_students, n_traits, nnw, optimiser=qopt)\n",
    "    attempts_by_psi, attempts_by_q = generate_attempts(qs,ss)\n",
    "    print(qs[0].pred_betas.get_weights()[0][0])\n",
    "    print(ss[0].pred_theta.get_weights()[0][0])\n",
    "    resultz = calibrate(qs,ss,attempts_by_q, attempts_by_psi, n_iter=70)\n",
    "    serieses.append( resultz )\n",
    "#     if ix < len(serieses): #append to old series\n",
    "#         (_mses,_accs) = serieses[ix]\n",
    "#         _mses += mses\n",
    "#         _accs += accs\n",
    "#         serieuses[ix] = (_mses,_accs)\n",
    "#     else: #create new series\n",
    "#         serieses.append((mses,accs))\n",
    "    \n",
    "from pygame import mixer\n",
    "mixer.init()\n",
    "mixer.music.load('calibration_complete.mp3')\n",
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump( serieses, open( \"serieses.p\", \"wb\" ) )\n",
    "\n",
    "xmax=10\n",
    "xs = range(len(serieses[0][0]))[0:xmax]\n",
    "print(len(serieses))\n",
    "for s in serieses:\n",
    "    print(len(s))\n",
    "# plt.plot(xs, numpy.multiply(1,theta_rmses), 'b--')\n",
    "# plt.plot(xs, numpy.multiply(1,beta_rmses), 'b')\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2)\n",
    "print(axes.shape)\n",
    "for (mses,accs, th_mses,th_accs, b_mses,b_accs),c,d in zip(serieses,[\"r--\",\"y--\",\"k-\",\"c--\",\"b--\"],nn_dimensions):\n",
    "    axes[0,0].plot(xs, numpy.multiply(1,mses[0:xmax]), c, label=\"nnw={}\".format(d))\n",
    "    axes[0,1].plot(xs, numpy.multiply(1,accs[0:xmax]), c, label=\"nnw={}\".format(d))\n",
    "    axes[1,0].plot(xs, numpy.multiply(1,th_mses[0:xmax]), c, label=\"nnw={}\".format(d))\n",
    "    axes[1,1].plot(xs, numpy.multiply(1,th_accs[0:xmax]), c, label=\"nnw={}\".format(d))\n",
    "    axes[2,0].plot(xs, numpy.multiply(1,b_mses[0:xmax]), c, label=\"nnw={}\".format(d))\n",
    "    axes[2,1].plot(xs, numpy.multiply(1,b_accs[0:xmax]), c, label=\"nnw={}\".format(d))\n",
    "\n",
    "# plt.plot(xs, accs, \"m\")\n",
    "# plt.plot(xs, numpy.multiply(1,s_outer_accs), \"g\")7\n",
    "# plt.plot(xs, numpy.multiply(1,q_outer_accs), \"k\")\n",
    "\n",
    "# plt.plot(xs, numpy.multiply(1,mses), \"m--\")\n",
    "# plt.plot(xs, numpy.multiply(1,s_outer_mses), \"g--\")\n",
    "# plt.plot(xs, numpy.multiply(1,q_outer_mses), \"k--\")\n",
    "for ix in range(axes.shape[0]):\n",
    "    subcats = [\"Combined\",\"Student\",\"Question\"]\n",
    "    for iy in range(axes.shape[1]):\n",
    "        axes[ix,iy].set_xlabel(\"#iterations\")\n",
    "        axes[ix,iy].legend()\n",
    "        if iy==0:\n",
    "            axes[ix,iy].set_title(\"{} fit error\".format(subcats[ix]))\n",
    "            axes[ix,iy].set_ylabel(\"fit error (RMSE)\")\n",
    "        else:\n",
    "            axes[ix,iy].set_title(\"{} fit accuracy\".format(subcats[ix]))\n",
    "            axes[ix,iy].set_ylabel(\"prediction accuracy\")\n",
    "\n",
    "fig.suptitle(\"Neural-MLTM Parameter Fitting (k={}, q={}, s={})\".format(n_traits, n_qs, n_students))\n",
    "fig.set_size_inches(18, 18)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = range(len(serieses[0][0]))\n",
    "print(len(serieses))\n",
    "for s in serieses:\n",
    "    print(len(s))\n",
    "# plt.plot(xs, numpy.multiply(1,theta_rmses), 'b--')\n",
    "# plt.plot(xs, numpy.multiply(1,beta_rmses), 'b')\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "print(axes.shape)\n",
    "\n",
    "min_mses = []\n",
    "max_accs = []\n",
    "bmin_mses = []\n",
    "bmax_accs = []\n",
    "\n",
    "for (mses,accs, th_mses,th_accs, b_mses,b_accs),c,d in zip(serieses,[\"r--\",\"y--\",\"k-\",\"c--\",\"b--\"],nn_dimensions):\n",
    "    mm = min(th_mses)\n",
    "    ma = max(th_accs)\n",
    "    min_mses.append(mm)\n",
    "    max_accs.append(ma)\n",
    "    mm = min(b_mses)\n",
    "    ma = max(b_accs)\n",
    "    bmin_mses.append(mm)\n",
    "    bmax_accs.append(ma)\n",
    "    \n",
    "\n",
    "axes[0].plot(nn_dimensions, numpy.multiply(1,min_mses))\n",
    "axes[0].plot(nn_dimensions, numpy.multiply(1,bmin_mses))\n",
    "axes[1].plot(nn_dimensions, numpy.multiply(1,max_accs))\n",
    "axes[1].plot(nn_dimensions, numpy.multiply(1,bmax_accs))\n",
    "axes[0].axvline(x=5, linestyle=\"--\")\n",
    "axes[1].axvline(x=5, linestyle=\"--\")\n",
    "\n",
    "fig.suptitle(\"Neural-MLTM Parameter Fitting (k={}, q={}, s={})\".format(n_traits, n_qs, n_students))\n",
    "fig.set_size_inches(18,4)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
