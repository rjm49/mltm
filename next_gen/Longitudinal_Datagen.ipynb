{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "Wf0XGW7uQbqT",
    "outputId": "7c4ebc30-d696-46d7-edb4-9ecca5f2b728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "started\n",
      "                                     qn_id     activity_name  \\\n",
      "qn_id                                                          \n",
      "Dialogue 1~1.0              Dialogue 1~1.0        Dialogue 1   \n",
      "Dialogue 1~2.0              Dialogue 1~2.0        Dialogue 1   \n",
      "Dialogue 1~3.0              Dialogue 1~3.0        Dialogue 1   \n",
      "Dialogue 1~4.0              Dialogue 1~4.0        Dialogue 1   \n",
      "Dialogue 1~5.0              Dialogue 1~5.0        Dialogue 1   \n",
      "Minimal pairs 1~1.0    Minimal pairs 1~1.0   Minimal pairs 1   \n",
      "Minimal pairs 1~2.0    Minimal pairs 1~2.0   Minimal pairs 1   \n",
      "Minimal pairs 1~3.0    Minimal pairs 1~3.0   Minimal pairs 1   \n",
      "Minimal pairs 1~4.0    Minimal pairs 1~4.0   Minimal pairs 1   \n",
      "Minimal pairs 1~5.0    Minimal pairs 1~5.0   Minimal pairs 1   \n",
      "Minimal pairs 1~6.0    Minimal pairs 1~6.0   Minimal pairs 1   \n",
      "Minimal pairs 1~7.0    Minimal pairs 1~7.0   Minimal pairs 1   \n",
      "Minimal pairs 1~8.0    Minimal pairs 1~8.0   Minimal pairs 1   \n",
      "Minimal pairs 1~9.0    Minimal pairs 1~9.0   Minimal pairs 1   \n",
      "Minimal pairs 1~10.0  Minimal pairs 1~10.0   Minimal pairs 1   \n",
      "Minimal pairs 1~11.0  Minimal pairs 1~11.0   Minimal pairs 1   \n",
      "Minimal pairs 1~12.0  Minimal pairs 1~12.0   Minimal pairs 1   \n",
      "Minimal pairs 1~13.0  Minimal pairs 1~13.0   Minimal pairs 1   \n",
      "Minimal pairs 1~14.0  Minimal pairs 1~14.0   Minimal pairs 1   \n",
      "Minimal pairs 1~15.0  Minimal pairs 1~15.0   Minimal pairs 1   \n",
      "Speed reading 14~1.0  Speed reading 14~1.0  Speed reading 14   \n",
      "Speed reading 14~2.0  Speed reading 14~2.0  Speed reading 14   \n",
      "Speed reading 14~3.0  Speed reading 14~3.0  Speed reading 14   \n",
      "Speed reading 14~4.0  Speed reading 14~4.0  Speed reading 14   \n",
      "Speed reading 14~5.0  Speed reading 14~5.0  Speed reading 14   \n",
      "Error finding 1~1.0    Error finding 1~1.0   Error finding 1   \n",
      "Error finding 1~2.0    Error finding 1~2.0   Error finding 1   \n",
      "Error finding 1~3.0    Error finding 1~3.0   Error finding 1   \n",
      "Error finding 1~4.0    Error finding 1~4.0   Error finding 1   \n",
      "Error finding 1~5.0    Error finding 1~5.0   Error finding 1   \n",
      "...                                    ...               ...   \n",
      "Spelling 3~6.0              Spelling 3~6.0        Spelling 3   \n",
      "Spelling 3~7.0              Spelling 3~7.0        Spelling 3   \n",
      "Spelling 3~8.0              Spelling 3~8.0        Spelling 3   \n",
      "Spelling 3~9.0              Spelling 3~9.0        Spelling 3   \n",
      "Spelling 3~10.0            Spelling 3~10.0        Spelling 3   \n",
      "Spelling 3~11.0            Spelling 3~11.0        Spelling 3   \n",
      "Spelling 3~12.0            Spelling 3~12.0        Spelling 3   \n",
      "Spelling 3~13.0            Spelling 3~13.0        Spelling 3   \n",
      "Spelling 3~14.0            Spelling 3~14.0        Spelling 3   \n",
      "Spelling 3~15.0            Spelling 3~15.0        Spelling 3   \n",
      "Spelling 3~16.0            Spelling 3~16.0        Spelling 3   \n",
      "Spelling 3~17.0            Spelling 3~17.0        Spelling 3   \n",
      "Spelling 3~18.0            Spelling 3~18.0        Spelling 3   \n",
      "Speed reading 13~1.0  Speed reading 13~1.0  Speed reading 13   \n",
      "Speed reading 13~2.0  Speed reading 13~2.0  Speed reading 13   \n",
      "Speed reading 13~3.0  Speed reading 13~3.0  Speed reading 13   \n",
      "Speed reading 13~4.0  Speed reading 13~4.0  Speed reading 13   \n",
      "Speed reading 13~5.0  Speed reading 13~5.0  Speed reading 13   \n",
      "Error finding 6~1.0    Error finding 6~1.0   Error finding 6   \n",
      "Error finding 6~2.0    Error finding 6~2.0   Error finding 6   \n",
      "Error finding 6~3.0    Error finding 6~3.0   Error finding 6   \n",
      "Error finding 6~4.0    Error finding 6~4.0   Error finding 6   \n",
      "Error finding 6~5.0    Error finding 6~5.0   Error finding 6   \n",
      "Error finding 6~6.0    Error finding 6~6.0   Error finding 6   \n",
      "Error finding 6~7.0    Error finding 6~7.0   Error finding 6   \n",
      "Phrasal verbs 3~1.0    Phrasal verbs 3~1.0   Phrasal verbs 3   \n",
      "Phrasal verbs 3~2.0    Phrasal verbs 3~2.0   Phrasal verbs 3   \n",
      "Phrasal verbs 3~3.0    Phrasal verbs 3~3.0   Phrasal verbs 3   \n",
      "Phrasal verbs 3~4.0    Phrasal verbs 3~4.0   Phrasal verbs 3   \n",
      "Phrasal verbs 3~5.0    Phrasal verbs 3~5.0   Phrasal verbs 3   \n",
      "\n",
      "                                activity_skill  \n",
      "qn_id                                           \n",
      "Dialogue 1~1.0               speaking~dialogue  \n",
      "Dialogue 1~2.0               speaking~dialogue  \n",
      "Dialogue 1~3.0               speaking~dialogue  \n",
      "Dialogue 1~4.0               speaking~dialogue  \n",
      "Dialogue 1~5.0               speaking~dialogue  \n",
      "Minimal pairs 1~1.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~2.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~3.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~4.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~5.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~6.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~7.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~8.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~9.0    listening~minimal_pairs  \n",
      "Minimal pairs 1~10.0   listening~minimal_pairs  \n",
      "Minimal pairs 1~11.0   listening~minimal_pairs  \n",
      "Minimal pairs 1~12.0   listening~minimal_pairs  \n",
      "Minimal pairs 1~13.0   listening~minimal_pairs  \n",
      "Minimal pairs 1~14.0   listening~minimal_pairs  \n",
      "Minimal pairs 1~15.0   listening~minimal_pairs  \n",
      "Speed reading 14~1.0     reading~speed_reading  \n",
      "Speed reading 14~2.0     reading~speed_reading  \n",
      "Speed reading 14~3.0     reading~speed_reading  \n",
      "Speed reading 14~4.0     reading~speed_reading  \n",
      "Speed reading 14~5.0     reading~speed_reading  \n",
      "Error finding 1~1.0   writing~error_correction  \n",
      "Error finding 1~2.0   writing~error_correction  \n",
      "Error finding 1~3.0   writing~error_correction  \n",
      "Error finding 1~4.0   writing~error_correction  \n",
      "Error finding 1~5.0   writing~error_correction  \n",
      "...                                        ...  \n",
      "Spelling 3~6.0                writing~spelling  \n",
      "Spelling 3~7.0                writing~spelling  \n",
      "Spelling 3~8.0                writing~spelling  \n",
      "Spelling 3~9.0                writing~spelling  \n",
      "Spelling 3~10.0               writing~spelling  \n",
      "Spelling 3~11.0               writing~spelling  \n",
      "Spelling 3~12.0               writing~spelling  \n",
      "Spelling 3~13.0               writing~spelling  \n",
      "Spelling 3~14.0               writing~spelling  \n",
      "Spelling 3~15.0               writing~spelling  \n",
      "Spelling 3~16.0               writing~spelling  \n",
      "Spelling 3~17.0               writing~spelling  \n",
      "Spelling 3~18.0               writing~spelling  \n",
      "Speed reading 13~1.0     reading~speed_reading  \n",
      "Speed reading 13~2.0     reading~speed_reading  \n",
      "Speed reading 13~3.0     reading~speed_reading  \n",
      "Speed reading 13~4.0     reading~speed_reading  \n",
      "Speed reading 13~5.0     reading~speed_reading  \n",
      "Error finding 6~1.0   writing~error_correction  \n",
      "Error finding 6~2.0   writing~error_correction  \n",
      "Error finding 6~3.0   writing~error_correction  \n",
      "Error finding 6~4.0   writing~error_correction  \n",
      "Error finding 6~5.0   writing~error_correction  \n",
      "Error finding 6~6.0   writing~error_correction  \n",
      "Error finding 6~7.0   writing~error_correction  \n",
      "Phrasal verbs 3~1.0      reading~phrasal_verbs  \n",
      "Phrasal verbs 3~2.0      reading~phrasal_verbs  \n",
      "Phrasal verbs 3~3.0      reading~phrasal_verbs  \n",
      "Phrasal verbs 3~4.0      reading~phrasal_verbs  \n",
      "Phrasal verbs 3~5.0      reading~phrasal_verbs  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from importlib import reload\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy\n",
    "\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from random import shuffle, choice, randint\n",
    "\n",
    "import math\n",
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "import pickle\n",
    "\n",
    "def logistic(x, b,off):\n",
    "    z = b*(x-off)\n",
    "    return numpy.exp(z)/(1+numpy.exp(z))\n",
    "\n",
    "def pr_to_spread(p, comps=1, as_A_and_D=True):\n",
    "    per_comp_p = p**(1/(comps))\n",
    "#     print(\"p         \", p)\n",
    "#     print(\"per comp p\", per_comp_p)\n",
    "#     spread = -numpy.log((1.0/per_comp_p)-1.0)\n",
    "    inv_sigmoid = lambda pr : ( -numpy.log((1/pr) -1) )\n",
    "    spread = inv_sigmoid(per_comp_p)\n",
    "#     print(\"spread    \", spread)\n",
    "    if as_A_and_D:\n",
    "        a = spread/2.0\n",
    "        d = -spread/2.0\n",
    "        return a,d\n",
    "    else:\n",
    "        return spread\n",
    "\n",
    "print(\"started\")\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "import sys\n",
    "# sys.path.append('/content/gdrive/My Drive/Colab Notebooks')\n",
    "from NN_utils import BigTable, WeightClip\n",
    "\n",
    "def calc_probs_from_embs(students,questions):\n",
    "    students2 = numpy.repeat(students, len(questions), axis=0)\n",
    "    questions2 = numpy.tile(questions, (len(students),1))\n",
    "    zmask = numpy.isclose(questions2,-10).astype(int)\n",
    "    diffs = students2-questions2\n",
    "    prs = numpy.exp(diffs)/(1.0+ numpy.exp(diffs))\n",
    "    prs = numpy.maximum(zmask,prs)\n",
    "    probs2 = numpy.prod(prs, axis=1).reshape(len(students), len(questions))\n",
    "    return probs2\n",
    "\n",
    "def calc_probs(s,q):\n",
    "    zmask = numpy.isclose(q,-10).astype(int)\n",
    "    diff = s-q\n",
    "    prs = 1.0/(1.0+ numpy.exp(-diff))\n",
    "    prs = numpy.maximum(zmask,prs)\n",
    "    # print(prs)\n",
    "    if len(q.shape)>1 and len(q.shape[0]) > 1:\n",
    "      raise Exception(\"tensor is wrong shape, duh\")\n",
    "      # pr = pr.reshape(len(q))\n",
    "    pr = numpy.prod(prs)\n",
    "    return pr, zmask\n",
    "\n",
    "# home = \"/content/gdrive/My Drive/Colab Notebooks\"\n",
    "home=\".\"\n",
    "\n",
    "import pandas\n",
    "mapping = pandas.read_csv(home+\"/real_data/qn_act_map.csv\")\n",
    "mapping.index = mapping.qn_id\n",
    "# mapping.drop(\"qn_id\", axis=1, inplace=True)\n",
    "print(mapping[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_databundle():\n",
    "# if True:\n",
    "#     raw_df = pandas.read_csv(home+\"/real_data/Worksheet_1041.csv\")\n",
    "#     print(raw_df.columns)\n",
    "#     print(len(raw_df))\n",
    "#     raw_df = raw_df[raw_df.event_type==\"answer_submitted\"]\n",
    "#     print(len(raw_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QjdJJEs-Qs1u"
   },
   "outputs": [],
   "source": [
    "def progress_one_step(q,s, s_gammas):\n",
    "  pr, zmask = calc_probs(s,q)\n",
    "  active_in_q = 1-zmask\n",
    "  # print(active_in_q)\n",
    "  # print(\"pr is\", pr)\n",
    "  passed = 0\n",
    "  if (numpy.random.random() <= pr):\n",
    "    passed = 1\n",
    "  s= s + s_gammas*active_in_q # learning rates from a successful attempt\n",
    "  # else:\n",
    "  #   s= s + s_rhos*active_in_q # learning rates from an unsauccessful attempt\n",
    "  return passed, pr, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAfdTWTpkE1K"
   },
   "outputs": [],
   "source": [
    "def run_data(students, questions, gammas, model_to_train=None):\n",
    "  from collections import defaultdict, Counter\n",
    "  sixs = []\n",
    "  qixs = []\n",
    "  hits = []\n",
    "  outps = []\n",
    "  \n",
    "  r = -1\n",
    "  scores = defaultdict(int)\n",
    "  hit_counter = {}\n",
    "  \n",
    "  s_indices = range(len(students))\n",
    "  # bo_selecta = None\n",
    "  for six in s_indices:\n",
    "    print(\"running student, \", six)\n",
    "    s = students[six]\n",
    "    R = 0  # reset reward for new student\n",
    "    ball_bag = list(range(len(questions)))\n",
    "    while ball_bag:\n",
    "      # print(\"WSH\",s.shape)\n",
    "      # print(numpy.mean(s), numpy.min(s), numpy.max(s))\n",
    "      # for sval in s:\n",
    "      #   print(sval)\n",
    "      # raise Exception(\"WANK\")\n",
    "      # if bo_selecta is None:\n",
    "      bo_selecta = random.choice(ball_bag)\n",
    "      q = questions[bo_selecta]\n",
    "      passed, pr, s_ = progress_one_step(q,s, gammas[six])\n",
    "      students[six] = s_ # Crucially, update the student to make progress...\n",
    "      # print(six, bo_selecta, numpy.mean(students[six]), pr)\n",
    "      if passed:\n",
    "        # print(\"***PASSED***\", six, bo_selecta, pr)\n",
    "        ball_bag.remove(bo_selecta)\n",
    "\n",
    "      # hit_counter[(six, bo_selecta)] += 1\n",
    "      # hit_counter\n",
    "    \n",
    "      if six not in hit_counter:\n",
    "        print(\"INIT'G zeros FOR\", six)\n",
    "        hit_counter[six] = [int(0)]*n_questions #numpy.zeros(n_questions, dtype=\"uint8\")\n",
    "\n",
    "      sixs.append( [int(six)])\n",
    "      qixs.append([int(bo_selecta)])\n",
    "      hits.append( tuple(hit_counter[six]) )\n",
    "      outps.append( [int(passed)] )\n",
    "\n",
    "      # neue = hit_counter[six]\n",
    "      # neue[bo_selecta] += 1\n",
    "      hit_counter[six][bo_selecta] += 1\n",
    "\n",
    "      R += r\n",
    "      # bo_selecta = None\n",
    "    print(R)\n",
    "    scores[six] = R\n",
    "\n",
    "  # if model_to_train:\n",
    "  #   phat = model_to_train.predict([[six], [bo_selecta], [hit_counter[(six,bo_selecta)]] ])\n",
    "  #   mae = abs(pr - phat)\n",
    "  #   print(pr, phat, mae)\n",
    "  #   model_to_train.train_on_batch( [ [six], [bo_selecta], [hit_counter[(six,bo_selecta)]] ], [passed] )\n",
    " \n",
    "  # print(\"Die Arrays werden in Numpy Datentypen verwandelt.\")\n",
    "  # sixs = numpy.array(sixs, dtype=\"uint8\")\n",
    "  # qixs = numpy.array(qixs, dtype=\"uint8\")\n",
    "  # hits = numpy.array(hits, dtype=\"uint8\")\n",
    "  # outps = numpy.array(outps, dtype=\"uint8\")\n",
    "\n",
    "  # print(hits.shape)\n",
    "  # print(outps.shape)\n",
    "\n",
    "  # if model_to_train:\n",
    "    # phat = model_to_train.predict([[six], [bo_selecta], [hit_counter[(six,bo_selecta)]] ])\n",
    "    # mae = abs(pr - phat)\n",
    "    # print(pr, phat, mae)\n",
    "    # model_to_train.fit( inps, outps )\n",
    "  # for (k,v) in scores.items():\n",
    "  #   print(k,v)\n",
    "  print(\"Der Lauf is beendet.\")\n",
    "  vals = list(scores.values())\n",
    "  return numpy.mean(vals), sixs, qixs, hits, outps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7GZiAAj6KSW"
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l1\n",
    "from keras.layers import Reshape, Dense, Dropout, add, multiply, subtract, GaussianNoise, GaussianDropout, Input, Lambda, Embedding, concatenate, Flatten, Maximum, Multiply, dot, Layer\n",
    "from keras import backend as K, Model\n",
    "from keras.initializers import RandomUniform, RandomNormal\n",
    "\n",
    "def hard_sigmoid(x):\n",
    "    return np.maximum(0, np.minimum(1, (x + 2) / 4))\n",
    "\n",
    "def binary_regulariser(x):\n",
    "    return K.sum( 1.0-(4.0*K.pow((0.5 - x),2)) )\n",
    "    # return K.sum(K.log(2*x) +K.log(2*(1-x)))\n",
    "    # return K.log(2*x) +K.log(2*(1-x))\n",
    "    \n",
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) + K.epsilon()\n",
    "    true_positives = K.sum(y_true * y_pred) + K.epsilon()\n",
    "    possible_positives = K.sum(y_true) + K.epsilon()\n",
    "    recall = true_positives / possible_positives\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) + K.epsilon()\n",
    "    true_positives = K.sum(y_true * y_pred) + K.epsilon()\n",
    "    predicted_positives = K.sum(y_pred) + K.epsilon()\n",
    "    precision = true_positives / predicted_positives\n",
    "    return precision\n",
    "\n",
    "def f1_metric(y_true, y_pred, average=\"macro\"):\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "    precision_1 = precision_m(y_true, y_pred)\n",
    "    recall_1 = recall_m(y_true, y_pred)\n",
    "#     print(\"p/r 1\", K.eval(precision_1), K.eval(recall_1))\n",
    "    f1_1 = 2.0*precision_1*recall_1 / (precision_1+recall_1)\n",
    "#     print(\"f1_1\", K.eval(f1_1))\n",
    "    if average==\"macro\":\n",
    "        precision_0 = precision_m((1-y_true), (1-y_pred))\n",
    "        recall_0 = recall_m((1-y_true), (1-y_pred))\n",
    "#         print(\"p/r 0\", K.eval(precision_0), K.eval(recall_0))\n",
    "        f1_0 = 2.0*precision_0*recall_0 / (precision_0+recall_0)\n",
    "#         print(\"f1_0\", K.eval(f1_0))\n",
    "        f1 = (f1_1+f1_0)/2.0\n",
    "#         print(\"f1  \", K.eval(f1))\n",
    "        return f1\n",
    "    else:\n",
    "        return f1_1\n",
    "\n",
    "def f1_loss(y_true, y_pred, average=\"macro\"):\n",
    "    return (1.0 - f1_metric(y_true, y_pred, average=average))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7GZiAAj6KSW"
   },
   "outputs": [],
   "source": [
    "#5e-5/row_w\n",
    "def generate_MLTM_raw_model(n_questions, n_students, row_w, ptqs=None, \n",
    "                        loss=\"binary_crossentropy\",\n",
    "                        metrics=None, init50=True, deep_HEU=False, reg=None, reg_w=None,\n",
    "                        pos_only=False):\n",
    "    print(\"MLTM RAW:\\nROW W is \", row_w)\n",
    "    print(\"reg is\",reg)\n",
    "    print(n_questions, n_students)\n",
    "\n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.regularizers import L2\n",
    "    from keras.constraints import NonNeg\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "#     long_clip = WeightClip(-math.inf, math.inf)\n",
    "#     long_clip = WeightClip(-5,5+sp)\n",
    "#     if pos_only:\n",
    "#     long_clip = WeightClip(0, 6+2*sp)\n",
    "\n",
    "#     q_init = RandomNormal(mean=sp) if init50 else \"uniform\"\n",
    "#     q_init = RandomNormal(mean=-sp) if init50 else \"uniform\"\n",
    "    q_init = RandomUniform(minval=sp-0.5, maxval=sp+0.5) if init50 else \"uniform\"\n",
    "#     q_init = \"uniform\"\n",
    "\n",
    "    if reg_w is None:\n",
    "        reg_w = 0\n",
    "        \n",
    "    reg_pen = 0.001/(((2*(1 if sp==0 else sp))**2)*(n_students*row_w))\n",
    "    print(\"reg_pen is\", reg_pen)\n",
    "    \n",
    "    qn_emb = Embedding(n_questions, row_w, \n",
    "#                        embeddings_regularizer=L2(100.0/(n_questions*row_w)**2) if \"l1\" in reg else None, \n",
    "#                        embeddings_regularizer=L2( reg_pen ),\n",
    "                       embeddings_initializer=q_init,\n",
    "                       name=\"qn_embedding\")\n",
    "#     qn_row = Flatten()(long_clip(qn_emb(qn_sel)))\n",
    "    qn_row = Flatten()(qn_emb(qn_sel))\n",
    "#     qn_row = Dense(row_w)(qn_row)\n",
    "    \n",
    "#     if reg_w is None:\n",
    "#         this_w = 32e-8\n",
    "#     else:\n",
    "#         this_w = (reg_w/row_w)\n",
    "    #embeddings_initializer=RandomNormal(mean=1+sp)\n",
    "    s_init = RandomNormal(mean=2*sp) if init50 else \"uniform\"\n",
    "#     s_init = \"uniform\"\n",
    "#     pos_clip = WeightClip(0, math.inf)\n",
    "#     gamma_row = Flatten()(NonNeg()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel)))\n",
    "    gamma_row = Flatten()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel))\n",
    "    \n",
    "    alpha_row = Flatten()(Embedding(n_students, row_w, \n",
    "                                                embeddings_initializer=s_init, \n",
    "#                                                 embeddings_regularizer=L2(200.0/(n_students*row_w)**2) if \"l2\" in reg else None, \n",
    "                                                embeddings_regularizer=L2( reg_pen ),\n",
    "                                                name=\"alphas\")(psi_sel))\n",
    "#     alpha_row = Dense(row_w)(alpha_row)\n",
    "#     if reg:\n",
    "#         alpha_row = tensorflow.keras.layers.ActivityRegularization(l2=0.01/row_w)(alpha_row)\n",
    "  \n",
    "    kc_practice = Dense(row_w, use_bias=True, name=\"qk_loadings\")(hit_counter)\n",
    "#     kc_practice = Dense(row_w, use_bias=False, kernel_constraint=NonNeg(), name=\"qk_loadings\",)(hit_counter)\n",
    "#     kc_practice = Lambda(lambda x: K.log(x+1e-6))(kc_practice)\n",
    "#     kc_practice = Dense(row_w, kernel_constraint=NonNeg())(kc_practice)\n",
    "#     kc_practice = tensorflow.keras.layers.ActivityRegularization(l1=0.00001/row_w)(kc_practice)\n",
    "    \n",
    "#     psi_row = long_clip( add( [alpha_row, multiply([kc_practice, gamma_row])]) )\n",
    "#     psi_row = Dense(row_w, activation=\"linear\")(psi_row)\n",
    "\n",
    "    psi_row = add( [alpha_row, multiply([kc_practice, gamma_row])])\n",
    "#     psi_row = alpha_row\n",
    "    difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "#     difs = tensorflow.keras.layers.ActivityRegularization(l2=0.001/row_w)(difs)\n",
    "#     difs = Dense(row_w, activity_regularizer=L2(0.1/row_w))(difs)\n",
    "\n",
    "    Prs = Lambda(lambda z: K.sigmoid(z))(difs)\n",
    "    \n",
    "#     logs = Lambda(lambda ps: K.log(ps), name=\"log_step\")(Prs)\n",
    "#     summed_logs = Lambda(lambda ps: K.sum(ps, axis=-1, keepdims=True), name=\"sum_step\")(logs)\n",
    "#     score = Lambda(lambda ps: K.exp(ps), name=\"exp_step\")(summed_logs)\n",
    "\n",
    "    score = Lambda(lambda prs: K.prod(prs, axis=-1, keepdims=True))(Prs)\n",
    "#     score = Lambda(lambda prs: tensorflow.math.reduce_logsumexp(prs, axis=-1, keepdims=True))(Prs)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MLTM0_model(n_questions, n_students, row_w, \n",
    "                        loss=\"binary_crossentropy\",\n",
    "                        metrics=None,\n",
    "                        l2=False):\n",
    "    print(\"ROW W is \", row_w)\n",
    "    # def generate_qs_model(qn_table, psi_table, optimiser, _mode=\"MXFN\", loss=\"MSE\"):  \n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.regularizers import L1,L2\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "    pos_clip = WeightClip(0.0000, 100)\n",
    "#     bin_clip = WeightClip(0.0000, 1.0000)\n",
    "\n",
    "    base = 1\n",
    "    q_init = RandomNormal(mean=base)\n",
    "    qn_emb = Embedding(n_questions, row_w, embeddings_initializer=q_init, \n",
    "#                        activity_regularizer=L1(1/row_w), \n",
    "                       name=\"qn_embedding\")\n",
    "    qn_row = Flatten(name=\"qn_row_out\")(pos_clip(qn_emb(qn_sel)))\n",
    "    \n",
    "# Q MAsking STilL reQuired\n",
    "    k=1000\n",
    "    qmask = Lambda(lambda x: K.clip(x*k,0.0000,1.0000))(qn_row)\n",
    "    \n",
    "    \n",
    "    w2 = 32e-8/row_w\n",
    "    print(\"using penalty\", w2)\n",
    "    alpha_row = Embedding(n_students, row_w, \n",
    "                          embeddings_initializer=RandomNormal(mean=base+sp), name=\"alphas\",\n",
    "                          embeddings_regularizer=L2(w2),\n",
    "                          )(psi_sel)\n",
    "    gamma_row = Embedding(n_students, row_w, name=\"gammas\")(psi_sel)\n",
    "    alpha_row = Flatten()(alpha_row)\n",
    "    gamma_row = Flatten()(gamma_row)\n",
    "\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(hit_counter)\n",
    "    psi_row = add( [alpha_row, multiply([kc_practice, gamma_row])], name=\"psi_row_out\")\n",
    "\n",
    "    difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "    Prs = Lambda(lambda z: K.sigmoid(z))(difs)\n",
    "    Prs = Lambda(lambda x: K.pow(x[0],K.abs(x[1])) )([Prs, qmask])\n",
    "\n",
    "    score = Lambda(lambda ps: K.prod(ps, axis=1, keepdims=True))(Prs)\n",
    "    \n",
    "    # p_LFA = σ(a_s + Σ k ∊ skills(q): 𝜸_k*n_sk - d_k)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_regularizer(x):\n",
    "#     return K.sum(K.square(x), axis=1)\n",
    "\n",
    "def generate_MLTMb_model(n_questions, n_students, row_w, \n",
    "                        loss=\"binary_crossentropy\",\n",
    "                        metrics=None,\n",
    "                        reg=None,\n",
    "                        reg_w = None):\n",
    "    print(\"MLTMb model with reg\", reg)\n",
    "    print(\"ROW W is \", row_w)\n",
    "    # def generate_qs_model(qn_table, psi_table, optimiser, _mode=\"MXFN\", loss=\"MSE\"):  \n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.regularizers import L1,L2\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "\n",
    "    zer0 = Lambda(lambda x: K.cast(K.clip(x,0,0), dtype=\"int32\"))\n",
    "    bin_clip = WeightClip(0.0000, 1.0000)\n",
    "#     lam_clip = Lambda(lambda x: K.clip(x,0.0000,1.0000))\n",
    "#     long_clip = WeightClip(-100,100)\n",
    "    \n",
    "    etas = Embedding(1, row_w, input_length=1, \n",
    "                     embeddings_initializer=RandomNormal(0),\n",
    "                     name=\"skill_diffs\")\n",
    "    \n",
    "    l2_w = reg_w if (reg_w is not None) else 1.5e-06\n",
    "    effs = Embedding(n_questions, row_w, \n",
    "#                      embeddings_constraint=WeightClip(0, 1), \n",
    "                     embeddings_initializer=RandomUniform(0.999,1), \n",
    "                     name=\"qn_embedding\",\n",
    "#                      embeddings_initializer = RandomNormal(1),\n",
    "#                      embeddings_regularizer=L2(10000.0/(n_questions*row_w)**2) if reg==\"l1\" else None,\n",
    "#                      embeddings_regularizer=L1(l2_w/(n_questions*row_w)) #if reg==\"l1\" else None,\n",
    "                        activity_regularizer=L1(1.55e-06) #if reg==\"l1\" else None,\n",
    "                     )\n",
    "    \n",
    "#     effs = Embedding(n_questions, row_w, name=\"qn_embedding\")\n",
    "\n",
    "#     qn_row = Flatten(name=\"qn_row_out\")(long_clip(etas(zer0(qn_sel))))\n",
    "    qn_row = Flatten(name=\"qn_row_out\")(etas(zer0(qn_sel)))\n",
    "\n",
    "#     delta_loading_is_qmask = Flatten(name=\"qmask_out\")(lam_clip(bin_clip(effs(qn_sel))))\n",
    "#     delta_loading_is_qmask = Flatten()(effs(qn_sel))\n",
    "    delta_loading_is_qmask = Flatten(name=\"qmask_out\")(bin_clip(effs(qn_sel)))\n",
    "\n",
    "# Q MAsking STilL reQuired\n",
    "    \n",
    "    w2 = 32*1.5e-6 / row_w\n",
    "    print(\"l2 penalty is\", w2)\n",
    "    alpha_row = Embedding(n_students, row_w, \n",
    "                          embeddings_initializer=RandomNormal(sp), name=\"alphas\",\n",
    "#                           embeddings_regularizer=L2(l2_w/(n_students*row_w)**2) if reg==\"l2\" else None,\n",
    "#                           embeddings_regularizer=L2(l2_w) if reg==\"l2\" else None,\n",
    "#                           embeddings_regularizer=L2(0.01) if reg==\"l2\" else None,\n",
    "#                             embeddings_regularizer=L2(w2)\n",
    "                         )(psi_sel)\n",
    "    gamma_row = Embedding(n_students, row_w, name=\"gammas\", \n",
    "                          embeddings_initializer=RandomNormal(0),\n",
    "                         )(psi_sel)\n",
    "    alpha_row = Flatten()(alpha_row)\n",
    "    gamma_row = Flatten()(gamma_row)\n",
    "\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(hit_counter)\n",
    "    psi_row = add( [alpha_row, multiply([kc_practice, gamma_row])], name=\"psi_row_out\")\n",
    "\n",
    "    difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "    Prs = Lambda(lambda z: K.sigmoid(z))(difs)\n",
    "    Prs = Lambda(lambda x: K.pow(x[0],K.abs(x[1])) )([Prs, delta_loading_is_qmask])\n",
    "    \n",
    "    score = Lambda(lambda ps: K.prod(ps, axis=1, keepdims=True))(Prs)\n",
    "    \n",
    "    # p_LFA = σ(a_s + Σ k ∊ skills(q): 𝜸_k*n_sk - d_k)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CFM_model(n_questions, n_students, row_w, loss=\"binary_crossentropy\", \n",
    "                     sfocus=False, metrics=None, reg=None, reg_w=None):\n",
    "    print(\"Using CFM model!\")\n",
    "\n",
    "    print(\"ROW W is \", row_w)\n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.layers import Add, Reshape, Multiply\n",
    "    from keras.regularizers import L1, L2\n",
    "    \n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    zer0 = Lambda(lambda x: K.cast(K.clip(x,0,0), dtype=\"int32\"))\n",
    "    bin_clip = WeightClip(0.0000, 1.0000)\n",
    "#     bin_clip = Lambda(lambda c: K.clip(c,0,1))\n",
    "    \n",
    "    reg_w = 0 if reg_w is None else reg_w\n",
    "    \n",
    "    sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "    B = Embedding(1 , row_w, name=\"skill_diffs\", embeddings_initializer=RandomNormal(0, stddev=0.1))\n",
    "    theta_i = Flatten()(Embedding(n_students, 1, name=\"alphas\", \n",
    "                                  embeddings_initializer=RandomNormal(sp, stddev=0.1),\n",
    "#                                   embeddings_regularizer=L2(10),\n",
    "                                  embeddings_regularizer= L2(1.45e-05),# if (\"l2\" in reg) else None,\n",
    "#                                   embeddings_regularizer= L2(reg_w) if (\"l2\" in reg) else None,\n",
    "#                                   embeddings_regularizer= L2(1),# if (\"l2\" in reg) else None,\n",
    "                                 )  (psi_sel))\n",
    "\n",
    "    print(\"theta_i shape\", theta_i.shape)\n",
    "    \n",
    "    Q = Embedding(n_questions, row_w, name=\"qn_embedding\", \n",
    "#                        embeddings_constraint=WeightClip(0, 1), \n",
    "                         embeddings_initializer=RandomUniform(0.99,1),\n",
    "#                          embeddings_regularizer = L1(reg_w / (row_w*n_questions) )# if (\"l1\" in reg) else None,\n",
    "                 )\n",
    "        \n",
    "#     gamma_k = Flatten()(Embedding(1, row_w, name=\"gammas\", embeddings_initializer=RandomNormal(0),)  (zer0(qn_sel)))\n",
    "    gamma_k = Flatten()(Embedding(1, row_w, name=\"gammas\")  (zer0(qn_sel)))\n",
    "\n",
    "    beta_k = Flatten()(B( zer0(qn_sel) ))\n",
    "    q_jk = Flatten()(bin_clip( Q(qn_sel) ))\n",
    "\n",
    "    print(\"shape kc-gammas\", gamma_k.shape)\n",
    "    T_jk = Dense(row_w, name=\"qk_loadings\", use_bias=False)(hit_counter)\n",
    "\n",
    "    prog = multiply([gamma_k, T_jk])\n",
    "    \n",
    "    skill_now = Add()([theta_i, prog])\n",
    "    logit_difs = subtract([skill_now, beta_k])\n",
    "    \n",
    "    print(\"logit shape\", logit_difs.shape)\n",
    "    Prs = Lambda(lambda z: K.sigmoid(z))(logit_difs)\n",
    "    \n",
    "#     Prs = Lambda(lambda mx: K.pow(mx[0],mx[1]))([Prs, q_jk])\n",
    "    Prs = Lambda(lambda mx: mx[1]*mx[0] + (1-mx[1]) )([Prs, q_jk])\n",
    "        \n",
    "    print(\"Prs shape\", Prs.shape)\n",
    "    score = Lambda(lambda ps: K.prod(ps, axis=1, keepdims=True))(Prs)\n",
    "    \n",
    "    # p_LFA = σ(a_s + Σ k ∊ skills(q): 𝜸_k*n_sk - d_k)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    from keras.optimizers import SGD, RMSprop, Nadam, Adam\n",
    "    #   optr = SGD(learning_rate=1.0)#, momentum=0.01, nesterov=True)\n",
    "    #   optr = RMSprop()\n",
    "    optr = Adam()\n",
    "    model.compile(optimizer=optr, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgHm-iOt55vE"
   },
   "outputs": [],
   "source": [
    "def create_AFM_model(n_questions, n_students, row_w, loss=\"binary_crossentropy\", \n",
    "                     sfocus=False, metrics=None, reg=None):\n",
    "    print(\"Using {}AFM model!\".format(\"S\" if sfocus else \"\"))\n",
    "    print(\"reg is\", reg)\n",
    "    \n",
    "    #AFM\n",
    "    # p_ij = sig( a_i + sum[k in KC(j)] b_k + g_k*n_ik )\n",
    "    \n",
    "    #sAFM\n",
    "    # p_ij = sig( sum[k in KC(j)] a_ik + b_k + g_k*n_ik )\n",
    "    \n",
    "    print(\"ROW W is \", row_w)\n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.layers import Add, Reshape, Multiply\n",
    "    from keras.constraints import NonNeg\n",
    "    from keras.regularizers import L2,L1\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "\n",
    "    zer0 = Lambda(lambda x: K.cast(K.clip(x,0,0), dtype=\"int32\"))\n",
    "    bin_clip = WeightClip(0.0000,1.0000)\n",
    "    \n",
    "    skill_d_ws = Embedding(1 , row_w, name=\"skill_diffs\", embeddings_initializer=RandomNormal(0, stddev=0.1))\n",
    "#   a0 = 5\n",
    "    qn_mx = Embedding(n_questions , row_w, name=\"qn_embedding\", \n",
    "#                        embeddings_constraint=WeightClip(0, 1), \n",
    "                       embeddings_initializer=RandomUniform(0.99,1),\n",
    "#                        activity_regularizer=\"l1\" if (\"l1\" in reg) else None,\n",
    "                     )\n",
    "    \n",
    "    gamma_row = Embedding(1, row_w, name=\"gammas\",\n",
    "#                     embeddings_initializer=RandomNormal(0),\n",
    "                    )(zer0(psi_sel))\n",
    "    a0 = Embedding(n_students, 1, name=\"alphas\", \n",
    "                  embeddings_initializer=RandomNormal(0, stddev=0.1),\n",
    "                  embeddings_regularizer= L2(1.45e-05) if (\"l2\" in reg) else None,\n",
    "                  )(psi_sel)\n",
    "\n",
    "    etas = Flatten()( skill_d_ws(zer0(qn_sel)) ) \n",
    "    \n",
    "    q_mask = Flatten()( bin_clip(qn_mx(qn_sel)) )\n",
    "\n",
    "    gamma_row = Flatten()(gamma_row)\n",
    "    print(\"shape kc-gammas\", gamma_row.shape)\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(hit_counter)\n",
    "    print(\"shape kc-practice\", kc_practice.shape)\n",
    "    prac_modifier = Multiply()([kc_practice, gamma_row])\n",
    "\n",
    "    difs = subtract([prac_modifier, etas])\n",
    "    difs = Multiply()([difs, q_mask]) # mask off irrelevant KCs\n",
    "    \n",
    "    print(\"Difs shape\", difs.shape)\n",
    "    summed = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True), name=\"lambda_sums\")(difs)\n",
    "    print(\"Summed shape\", summed.shape)\n",
    "    \n",
    "    a0 = Flatten()(a0)\n",
    "    logit = Add()([a0, summed]) #in AFM we add a0 after the subtraction and masking\n",
    "        \n",
    "    print(\"logit shape\", logit.shape)\n",
    "    score = Lambda(lambda z: K.sigmoid(z))(logit)\n",
    "    \n",
    "    # p_LFA = σ(a_s + Σ k ∊ skills(q): 𝜸_k*n_sk - d_k)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    from keras.optimizers import SGD, RMSprop, Nadam, Adam\n",
    "    #   optr = SGD(learning_rate=1.0)#, momentum=0.01, nesterov=True)\n",
    "    #   optr = RMSprop()\n",
    "    optr = Adam()\n",
    "    model.compile(optimizer=optr, loss=loss, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def create_AFMg_orig_model(n_questions, n_students, row_w, loss=\"binary_crossentropy\", metrics=None, reg=None):\n",
    "    print(\"Using AFMg model!\")\n",
    "\n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.layers import Add, Reshape, Multiply\n",
    "    from keras.constraints import NonNeg\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.regularizers import L2\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    zer0 = Lambda(lambda x: K.cast(K.clip(x,0,0), dtype=\"int32\"))\n",
    "    bin_clip = WeightClip(0.0000,1.0000)\n",
    "\n",
    "    q_row = Flatten()(bin_clip(Embedding(n_questions , row_w, name=\"qn_embedding\", \n",
    "                                         embeddings_initializer=RandomUniform(.99,1),\n",
    "                                         activity_regularizer= \"l1\" if (\"l1\" in reg) else None)(qn_sel)))\n",
    "\n",
    "    skill_d_ws = Embedding(1 , row_w, name=\"skill_diffs\")\n",
    "    base_deltas = Flatten()(skill_d_ws(zer0(qn_sel)))\n",
    "#     masked_deltas = multiply([q_row, base_deltas])\n",
    "#     delta = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True), name=\"sum_deltas\")(masked_deltas)\n",
    "\n",
    "    \n",
    "    gamma_row = Flatten()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel))\n",
    "    \n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(hit_counter)\n",
    "    prac_kc_mods = multiply([kc_practice, gamma_row])\n",
    "#     masked_kc_mods = multiply([prac_kc_mods, q_row])\n",
    "#     practice = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True), name=\"sum_kc_pracs\")(masked_kc_mods)\n",
    "    \n",
    "    kcwise_difs = subtract([prac_kc_mods, base_deltas])\n",
    "    masked_kcwise_difs = multiply([kcwise_difs, q_row])\n",
    "    dif = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True), name=\"sum_kc_pracs\")(masked_kcwise_difs)\n",
    "    \n",
    "    a0 = Flatten()(Embedding(n_students, 1, name=\"alphas\",          \n",
    "#                             embeddings_regularizer=L2(1/n_students) if (\"l2\" in reg) else None,\n",
    "                            embeddings_regularizer=L2(1.45e-05) if (\"l2\" in reg) else None,\n",
    "                            )(psi_sel))\n",
    "    logit_dif = add([a0, dif])\n",
    "\n",
    "    score = Lambda(lambda z: K.sigmoid(z))(logit_dif)\n",
    "    \n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    optr = Adam()\n",
    "    model.compile(optimizer=optr, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_AFMg_model(n_questions, n_students, row_w, loss=\"binary_crossentropy\", metrics=None, reg=None):\n",
    "    print(\"Using AFMg+ model!\")\n",
    "\n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.layers import Add, Reshape, Multiply\n",
    "    from keras.constraints import NonNeg\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.regularizers import L2\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    zer0 = Lambda(lambda x: K.cast(K.clip(x,0,0), dtype=\"int32\"))\n",
    "    bin_clip = WeightClip(0.0000,1.0000)\n",
    "    pos_clip = WeightClip(0, math.inf)\n",
    "\n",
    "    sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "    \n",
    "    q_row = Flatten()(bin_clip(Embedding(n_questions , row_w, name=\"qn_embedding\", \n",
    "                                         embeddings_initializer=RandomUniform(.99,1),\n",
    "                                        )(qn_sel)))\n",
    "#     if reg:\n",
    "    q_row = tensorflow.keras.layers.ActivityRegularization(l1=0.1/row_w)(q_row)\n",
    "\n",
    "    skill_d_ws = Embedding(1 , row_w, name=\"skill_diffs\", embeddings_initializer=RandomNormal(0))\n",
    "    base_deltas = Flatten()(skill_d_ws(zer0(qn_sel)))\n",
    "#     masked_deltas = multiply([q_row, base_deltas])\n",
    "#     delta = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True), name=\"sum_deltas\")(masked_deltas)\n",
    "\n",
    "    gamma_row = Flatten()(pos_clip(Embedding(n_students, row_w, name=\"gammas\", embeddings_initializer=RandomNormal(1))(psi_sel)))\n",
    "    \n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False, kernel_constraint=NonNeg())(hit_counter)\n",
    "    prac_kc_mods = multiply([kc_practice, gamma_row])\n",
    "#     masked_kc_mods = multiply([prac_kc_mods, q_row])\n",
    "#     practice = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True), name=\"sum_kc_pracs\")(masked_kc_mods)\n",
    "    a0 = Flatten()(Embedding(n_students, row_w, name=\"alphas\",      \n",
    "                             embeddings_initializer=RandomNormal(sp),\n",
    "#                             embeddings_regularizer=L2(1/n_students) if (\"l2\" in reg) else None,\n",
    "#                              embeddings_regularizer=L2(1.45e-05) if (\"l2\" in reg) else None,\n",
    "                            )(psi_sel))\n",
    "    psi_row = add([a0, prac_kc_mods])\n",
    "    \n",
    "    kcwise_difs = subtract([psi_row, base_deltas])\n",
    "    Prs = Lambda(lambda z: K.sigmoid(z))(kcwise_difs)\n",
    "    \n",
    "#     masked_kcwise_difs = multiply([kcwise_difs, Pr])\n",
    "    Prs = Lambda(lambda ps: ps[0]*ps[1])([Prs, q_row])\n",
    "#     Prs = Lambda(lambda ps: K.pow(ps[0], ps[1]))([Prs, q_row])\n",
    "#     Prs = Lambda(lambda ps: ps[0]*ps[1] + (1-ps[1]) )([Prs, q_row])\n",
    "#     dif = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True), name=\"sum_kc_pracs\")(masked_kcwise_difs)\n",
    "  \n",
    "#     h = Dense(3, activation=\"relu\")(Prs)\n",
    "#     h = Dense(3, activation=\"relu\")(h)\n",
    "#     score = Dense(1, activation=\"sigmoid\")(h)\n",
    "\n",
    "    score = Lambda(lambda ps: K.prod(ps, axis=1, keepdims=True), name=\"score\")(Prs)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    optr = Adam()\n",
    "    model.compile(optimizer=optr, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RASCH_model(n_questions, n_students, loss=\"binary_crossentropy\", metrics=None, reg=None):\n",
    "    print(\"Using univariate Rasch model!\")\n",
    "\n",
    "    from keras.initializers import RandomNormal, RandomUniform, Constant\n",
    "    from keras.layers import Add, Reshape, Multiply\n",
    "    from keras.constraints import NonNeg\n",
    "    from keras.regularizers import L2\n",
    "    from keras.optimizers import Adam\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "#     if reg:\n",
    "#         rw = reg\n",
    "#     else:\n",
    "#         rw = 0.0001\n",
    "    \n",
    "    delta = Flatten()(Embedding(n_questions , 1, name=\"qn_embedding\")(qn_sel))\n",
    "    gamma_row = Flatten()(Embedding(n_students, 1, name=\"gammas\")(psi_sel))\n",
    "    a0 = Flatten()(Embedding(n_students, 1, \n",
    "#                              embeddings_regularizer = L2(rw),\n",
    "                             name=\"alphas\")(psi_sel))\n",
    "    \n",
    "#     log_hits_plus_one = hit_counter\n",
    "#     hcp1 = Lambda(lambda x: x)(hit_counter)\n",
    "#     kc_practice = Dense(10, use_bias=True)(hit_counter)\n",
    "    kc_practice = Dense(1, name=\"qk_loadings\", use_bias=False)(hit_counter)\n",
    "#     kc_practice = Lambda(lambda x: K.log(x+1))(kc_practice)\n",
    "\n",
    "    alpha = add([a0, multiply([kc_practice, gamma_row])])\n",
    "\n",
    "    logit_dif = subtract([alpha, delta])\n",
    "\n",
    "    score = Lambda(lambda z: K.sigmoid(z))(logit_dif)\n",
    "    \n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    optr = Adam()\n",
    "    model.compile(optimizer=optr, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_DEEPGAMMA_model(n_questions, n_students, row_w, ptqs=None, loss=f1_loss, non_neg=False,\n",
    "                       metrics=None, deep=False, concat=False, reg=None, reg_w=None):\n",
    "    print(\"MLP model\")\n",
    "    if reg==\"l2\":\n",
    "        print(\"L2 reg'n\", reg)\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "\n",
    "#     q_init = RandomNormal(mean=0) if init50 else \"uniform\"\n",
    "    qn_emb = Embedding(n_questions, row_w, name=\"qn_embedding\", embeddings_initializer=RandomNormal(0))\n",
    "    qn_row = Flatten()(qn_emb(qn_sel))\n",
    "\n",
    "    l2_w = reg_w if (reg_w is not None) else 0.1\n",
    "    \n",
    "    from keras.regularizers import L2\n",
    "    #embeddings_initializer=RandomNormal(mean=1+sp)\n",
    "#     s_init = RandomNormal(mean=sp) #if init50 else \"uniform\"\n",
    "    gamma_row = Flatten()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel))\n",
    "    alpha_row = Flatten()(Embedding(n_students, row_w, name=\"alphas\",\n",
    "                                embeddings_initializer=RandomNormal(sp),\n",
    "#                                 embeddings_regularizer=L2(l2_w/(n_students*row_w)) if reg==\"l2\" else None,\n",
    "#                                 embeddings_regularizer=L2(0.00001/(n_students*row_w)),# if reg==\"l2\" else None, \n",
    "                                )(psi_sel))\n",
    "#     alpha_row = tensorflow.keras.layers.ActivityRegularization(l2=0.01/row_w)(alpha_row)\n",
    "\n",
    "\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\")(hit_counter)\n",
    "    learnage = Dense(row_w, activation=\"relu\")(concatenate([gamma_row, kc_practice]))\n",
    "#     learnage = Dense(row_w)(learnage)\n",
    "        \n",
    "#     kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False, activation=\"relu\")(hit_counter)\n",
    "#     kc_practice = Lambda(lambda x: K.log(x+1))(kc_practice)\n",
    "#     log_hits_plus_one = Lambda(lambda x: K.log(x+1))(hit_counter)\n",
    "#     kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(log_hits_plus_one)\n",
    "#     print(\"shape kc-practice\", kc_practice.shape)\n",
    "\n",
    "    psi_row = add( [alpha_row, learnage])\n",
    "#     psi_row = Dense(row_w, activation=\"relu\")(concatenate([alpha_row, learnage]))\n",
    "    \n",
    "    difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "#     difs = L2(0.001)(difs)\n",
    "    \n",
    "    Prs = difs\n",
    "#     Prs = Lambda(lambda z: K.sigmoid(z))(difs)\n",
    "    \n",
    "#     logs = Lambda(lambda ps: K.log(ps), name=\"log_step\")(Prs)\n",
    "#     summed_logs = Lambda(lambda ps: K.sum(ps, axis=-1, keepdims=True), name=\"sum_step\")(logs)\n",
    "#     score = Lambda(lambda ps: K.exp(ps), name=\"exp_step\")(summed_logs)\n",
    "\n",
    "#     score = Lambda(lambda prs: K.prod(prs, axis=-1, keepdims=True))(Prs)\n",
    "    Prs = Dense(5, activation=\"relu\")(Prs)\n",
    "    score = Dense(1, activation=\"sigmoid\")(Prs)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MLPraw_model(n_questions, n_students, row_w, ptqs=None, loss=f1_loss, non_neg=False,\n",
    "                       metrics=None, deep=False, concat=False, reg=None, reg_w=None, inc_dif=False):\n",
    "    print(\"MLP model\")\n",
    "    if reg==\"l2\":\n",
    "        print(\"L2 reg'n\", reg)\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    qn_emb = Embedding(n_questions, row_w, name=\"qn_embedding\",\n",
    "#                        embeddings_initializer=RandomNormal(0)\n",
    "                      )\n",
    "    qn_row = Flatten()(qn_emb(qn_sel))\n",
    "#     qn_row = Dropout(0.5)(qn_row)\n",
    "\n",
    "    l2_w = reg_w if (reg_w is not None) else 0.1\n",
    "    \n",
    "    from keras.regularizers import L2\n",
    "    #embeddings_initializer=RandomNormal(mean=1+sp)\n",
    "#     s_init = RandomNormal(mean=sp) #if init50 else \"uniform\"\n",
    "    gamma_row = Flatten()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel))\n",
    "    alpha_row = Flatten()(Embedding(n_students, row_w, name=\"alphas\",\n",
    "#                                 embeddings_initializer=RandomNormal(sp),\n",
    "#                                 embeddings_regularizer=L2(l2_w/(n_students*row_w)) if reg==\"l2\" else None,\n",
    "#                                 embeddings_regularizer=L2(5e-5/row_w),# if reg==\"l2\" else None, \n",
    "                                )(psi_sel))\n",
    "\n",
    "#     kch = Dropout(0.1)(hit_counter)\n",
    "    kch = hit_counter\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(kch)\n",
    "#     kc_practice = Dropout(0.5)(kc_practice)\n",
    "    print(\"shape kc-practice\", kc_practice.shape)\n",
    "    \n",
    "    psi_row = add( [alpha_row, multiply([kc_practice, gamma_row])])\n",
    "#     psi_row = Dropout(0.5)(psi_row)\n",
    "\n",
    "#     if deep:\n",
    "#         h = Dense(max(2,row_w//20), activation=\"relu\")(difs)\n",
    "# #         h = Dense(5, activation=\"relu\")(h)\n",
    "#     else:\n",
    "#     h = difs\n",
    "\n",
    "    hw = max(min(row_w,2),row_w//5)\n",
    "    print(\"hidden w is\", hw)\n",
    "#     h_act = \"sigmoid\"\n",
    "\n",
    "    difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "    if inc_dif==\"DenP\":\n",
    "#         ha = Dense(row_w)(psi_row)\n",
    "#         hd = Dense(row_w)(qn_row)\n",
    "#         h = concatenate([ha, hd], axis=1, name=\"concat_h\")\n",
    "        h = Dense(row_w)(difs)\n",
    "#         h = Dropout(0.75)(h)\n",
    "        score = Dense(1, activation=\"sigmoid\")(h)\n",
    "    elif inc_dif==\"Dense\":\n",
    "        ha = Dense(row_w)(psi_row)\n",
    "        hd = Dense(row_w)(qn_row)\n",
    "        h = concatenate([ha, hd], axis=1, name=\"concat_h\")\n",
    "#         h = Dropout(0.75)(h)\n",
    "        score = Dense(1, activation=\"sigmoid\")(h)\n",
    "    elif inc_dif==\"dif\":\n",
    "        h = difs\n",
    "#         h = Dense(hw, activation=h_act)(difs)\n",
    "        h = Dropout(0.75)(difs)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "        score = Dense(1, activation=\"sigmoid\")(h)\n",
    "    elif inc_dif==\"AD\":\n",
    "        del difs\n",
    "        h = concatenate([psi_row, qn_row], axis=1, name=\"concat_h\")\n",
    "        h = Dropout(0.75)(h)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "        score = Dense(1, activation=\"sigmoid\")(h)\n",
    "    elif inc_dif==\"AD+dif\":\n",
    "#         difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "        h = concatenate([psi_row, qn_row, difs], axis=1, name=\"concat_h\")\n",
    "        h = Dropout(0.75)(h)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "#         h = Dense(hw, activation=h_act)(h)\n",
    "        score = Dense(1, activation=\"sigmoid\")(h)\n",
    "    else:\n",
    "        raise Exception(\"invalid concat model in MLPraw model gen:\", inc_dif)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MLP_model(n_questions, n_students, row_w, ptqs=None, loss=f1_loss, non_neg=False,\n",
    "                       metrics=None, deep=False, concat=False, reg=None, reg_w=None):\n",
    "    print(\"MLP model\")\n",
    "    if reg==\"l2\":\n",
    "        print(\"L2 reg'n\", reg)\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "    sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "\n",
    "#     q_init = RandomNormal(mean=0) if init50 else \"uniform\"\n",
    "    qn_emb = Embedding(n_questions, row_w, name=\"qn_embedding\", embeddings_initializer=RandomNormal(0))\n",
    "    qn_row = Flatten()(qn_emb(qn_sel))\n",
    "\n",
    "    l2_w = reg_w if (reg_w is not None) else 0.1\n",
    "    \n",
    "    from keras.regularizers import L2\n",
    "    #embeddings_initializer=RandomNormal(mean=1+sp)\n",
    "#     s_init = RandomNormal(mean=sp) #if init50 else \"uniform\"\n",
    "    gamma_row = Flatten()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel))\n",
    "    alpha_row = Flatten()(Embedding(n_students, row_w, name=\"alphas\",\n",
    "                                embeddings_initializer=RandomNormal(sp),\n",
    "#                                 embeddings_regularizer=L2(l2_w/(n_students*row_w)) if reg==\"l2\" else None,\n",
    "#                                 embeddings_regularizer=L2(5e-5/row_w),# if reg==\"l2\" else None, \n",
    "                                )(psi_sel))\n",
    "    alpha_row = tensorflow.keras.layers.ActivityRegularization(l2=0.01/row_w)(alpha_row)\n",
    "\n",
    "\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(hit_counter)\n",
    "\n",
    "#     kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False, activation=\"relu\")(hit_counter)\n",
    "#     kc_practice = Lambda(lambda x: K.log(x+1))(kc_practice)\n",
    "#     log_hits_plus_one = Lambda(lambda x: K.log(x+1))(hit_counter)\n",
    "#     kc_practice = Dense(row_w, name=\"qk_loadings\", use_bias=False)(log_hits_plus_one)\n",
    "#     print(\"shape kc-practice\", kc_practice.shape)\n",
    "    \n",
    "    psi_row = add( [alpha_row, multiply([kc_practice, gamma_row])])\n",
    "\n",
    "    difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "#     difs = L2(0.001)(difs)\n",
    "    \n",
    "    score = Dense(1, activation=\"sigmoid\")(difs)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MLPd_model(n_questions, n_students, row_w, ptqs=None, loss=f1_loss, non_neg=False,\n",
    "                       metrics=None, deep=False, concat=False, reg=None):\n",
    "    print(\"MLP DEEP model\")\n",
    "    if reg==\"l2\":\n",
    "        print(\"L2 reg'n\")\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "#     sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "\n",
    "#     long_clip = WeightClip(-100,100)\n",
    "\n",
    "#     q_init = RandomNormal(mean=0) if init50 else \"uniform\"\n",
    "    qn_emb = Embedding(n_questions, row_w, name=\"qn_embedding\")\n",
    "    qn_row = Flatten()(qn_emb(qn_sel))\n",
    "\n",
    "    from keras.regularizers import L2\n",
    "    from keras.layers import Dropout\n",
    "    gamma_row = Flatten()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel))\n",
    "    alpha_row = Flatten()(Embedding(n_students, row_w, name=\"alphas\",\n",
    "                                   embeddings_initializer=RandomNormal(1),\n",
    "                                   embeddings_regularizer=L2(1.0/(n_students*row_w)) if reg==\"l2\" else None )(psi_sel))\n",
    "\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\")(hit_counter)\n",
    "    print(\"shape kc-practice\", kc_practice.shape)\n",
    "    \n",
    "    psi_row = add( [alpha_row, multiply([kc_practice, gamma_row])])\n",
    "\n",
    "    difs = subtract([psi_row, qn_row], name=\"difs\")\n",
    "    h = Dense(row_w/2, activation=\"relu\")(difs)\n",
    "#     h = Dropout(0.2)(h)\n",
    "    h = Dense(4, activation=\"linear\")(h)\n",
    "#     h = Dropout(0.2)(h)\n",
    "    score = Dense(1, activation=\"sigmoid\")(h)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_CONC_model(n_questions, n_students, row_w, ptqs=None, loss=f1_loss, non_neg=False,\n",
    "                       metrics=None, deep=False, concat=False, reg=None):\n",
    "    print(\"MLP CONC model\")\n",
    "    if reg==\"l2\":\n",
    "        print(\"L2 reg'n\")\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    hit_counter = Input(shape=(n_questions, ), name=\"hit_counter\", dtype=\"float32\")\n",
    "\n",
    "#     sp = pr_to_spread(.5, row_w, as_A_and_D=False)\n",
    "\n",
    "    long_clip = WeightClip(-100,100)\n",
    "\n",
    "#     q_init = RandomNormal(mean=0) if init50 else \"uniform\"\n",
    "    qn_emb = Embedding(n_questions, row_w, name=\"qn_embedding\")\n",
    "    qn_row = Flatten()(long_clip(qn_emb(qn_sel)))\n",
    "\n",
    "    from keras.regularizers import L2\n",
    "    from keras.layers import Dropout, concatenate\n",
    "    gamma_row = Flatten()(Embedding(n_students, row_w, name=\"gammas\")(psi_sel))\n",
    "    alpha_row = Flatten()(Embedding(n_students, row_w, name=\"alphas\",\n",
    "                                   embeddings_initializer=RandomNormal(1),\n",
    "                                   embeddings_regularizer=L2(1/(n_students*row_w)) if reg==\"l2\" else None )(psi_sel))\n",
    "\n",
    "    kc_practice = Dense(row_w, name=\"qk_loadings\")(hit_counter)\n",
    "    print(\"shape kc-practice\", kc_practice.shape)\n",
    "    \n",
    "    psi_row = add( [alpha_row, multiply([kc_practice, gamma_row])])\n",
    "\n",
    "    conc = concatenate([psi_row, qn_row], name=\"conc\")\n",
    "#     h = Dense(10, activation=\"relu\")(conc)\n",
    "#     h = Dropout(0.2)(h)\n",
    "#     h = Dense(4, activation=\"relu\")(h)\n",
    "#     h = Dropout(0.2)(h)\n",
    "    score = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "    model = Model(inputs=[qn_sel, psi_sel, hit_counter], outputs=score)\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents\n",
    "\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "\n",
    "\n",
    "def getsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FdR1WiKecC8g",
    "outputId": "447bf9bb-72bb-4e31-e3f2-2667c0c0ae88",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset 5 : [[1.4645131]] 3.1089039466440367 1.4084517039946103\n",
      "[[ 1.37173388 -1.02864352  7.55703414 ... -1.49886535  1.53442336\n",
      "   1.55596703]\n",
      " [ 2.4635658   0.53089028 -5.45221188 ... -0.74608016  2.82944632\n",
      "   1.92081998]\n",
      " [ 1.55326451 -3.58004045 -1.89803685 ... -0.54779934  1.07594026\n",
      "  -1.57406956]\n",
      " ...\n",
      " [ 2.1023064   2.8166152  -0.4222581  ...  2.81755714 -6.81089099\n",
      "  -5.47685088]\n",
      " [-3.94892705 -1.47331223  1.72161864 ...  5.54785844  0.01453553\n",
      "  -1.07487148]\n",
      " [-2.68058906  0.55106707  0.27516104 ... -0.01492254  0.32854899\n",
      "  -0.09848295]]\n",
      "[[-10.         -10.         -10.         ... -10.         -10.\n",
      "  -10.        ]\n",
      " [-10.         -10.          -2.23522303 ... -10.         -10.\n",
      "  -10.        ]\n",
      " [-10.         -10.         -10.         ... -10.         -10.\n",
      "  -10.        ]\n",
      " ...\n",
      " [-10.         -10.         -10.         ... -10.         -10.\n",
      "  -10.        ]\n",
      " [-10.         -10.         -10.         ... -10.         -10.\n",
      "  -10.        ]\n",
      " [-10.         -10.         -10.         ... -10.         -10.\n",
      "  -10.        ]]\n"
     ]
    }
   ],
   "source": [
    "emb_w = 2\n",
    "import gc, zlib\n",
    "\n",
    "from collections import Counter\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, LambdaCallback\n",
    "data_to_run = [5,]\n",
    "c= Counter()\n",
    "for a in data_to_run:\n",
    "    (tw,a0,a1, students_temp, qz_temp) = pickle.load(open(home+\"/synth_data/MLTM_10000_1000_(100_1_5)_{}.p\".format(a), \"rb\"))\n",
    "    print(\"loaded dataset\",a,\":\", a0,a1,tw)             \n",
    "    \n",
    "    n_students = 1000 # len(students2)\n",
    "    n_questions = 1000 #len(questions)\n",
    "    spars = 0.1\n",
    "\n",
    "    # from keras.models import load_model\n",
    "    fname = \"MLTM_1000_1000_(100_1_5)_sp100_5_0\"\n",
    "    #   m = load_model(home+\"/models/\" + fname, custom_objects={'WeightClip': WeightClip})\n",
    "    \n",
    "    print(students_temp)\n",
    "    print(qz_temp)\n",
    "    \n",
    "    \n",
    "#     c[a] += 1\n",
    "\n",
    "#     n_students = 500 # len(students2)\n",
    "#     n_questions = 500 #len(questions)\n",
    "#     students2 = students_temp[0:n_students]\n",
    "#     questions = qz_temp[0:n_questions]\n",
    "\n",
    "#     curr_min = numpy.min(students2)\n",
    "#     start = curr_min - .1\n",
    "\n",
    "#     #   pre_trained_qns = m.get_weights()[1]\n",
    "#     #   print(pre_trained_qns.shape)\n",
    "#     m = None\n",
    "\n",
    "#     print(0.01**(1/3))\n",
    "#     # p = 1/(1+e-z)\n",
    "#     print(pr_to_spread(0.215, as_A_and_D=False))#  -1.295\n",
    "#     # print(a0)\n",
    "\n",
    "#     longitude = 12 # number of steps we assume students have been in play\n",
    "#     # for s in students2:\n",
    "#     #   print((s-start)/longitude)\n",
    "\n",
    "#     students_start = numpy.zeros_like(students2) + start\n",
    "#     # gammas = (students2 - start)/longitude\n",
    "#     gammas = numpy.random.uniform(low=0.01, high=2.4, size=(n_students, emb_w))\n",
    "#     print(\"Gammas:\", numpy.min(gammas), numpy.max(gammas), numpy.mean(gammas), numpy.median(gammas))\n",
    "\n",
    "#     fname = \"Longitudinal_{}_{}_(100_1_5)_run={}\".format(n_students, n_questions, a)\n",
    "#     # try:\n",
    "\n",
    "#     # try:\n",
    "#     #   o_hits\n",
    "#     # except NameError:\n",
    "# #     if not o_hits:\n",
    "# #     (sixs, qixs, hits, hout) = pickle.load(open(home+\"/synth_data/\" + fname + \".p\", \"rb\"))\n",
    "# #     (sixs, qixs, hout) = pickle.load(open(home+\"/real_data/XL1041.p\", \"rb\"))\n",
    "#     # render_student_histories(sixs, qixs, hits, hout)\n",
    "#     questions = None\n",
    "#     students2 = None\n",
    "#     students_temp = None\n",
    "#     qz_temp = None\n",
    "\n",
    "#     # pre_trained_qns = None\n",
    "#     gc.collect()\n",
    "#     o_hits=[]\n",
    "#     t_hits=[]\n",
    "\n",
    "#     odata, vdata, tdata, sid_six_lookup, qid_qix_lookup = split_next_step(sixs, qixs, hout, \n",
    "#                                                                           max_students = 100000,\n",
    "#                                                                           min_hist = 40,\n",
    "#                                                                           max_hist = None)#, alternate=True, balance_training=False)\n",
    "#     (o_sixs, o_qixs, o_hits, o_out), (v_sixs, v_qixs, v_hits, v_out), (t_sixs, t_qixs, t_hits, t_out) = (odata, vdata, tdata)\n",
    "#     print(\"len o_sixes\", len(o_sixs))\n",
    "\n",
    "#     n_questions = len(set(qixs))\n",
    "#     n_students = len(set(sixs))\n",
    "\n",
    "#     # raise Exception(\"DELIBERATE EXCEPTION CALLED\")\n",
    "\n",
    "# #     def uncomp(chits):\n",
    "# #         for hix, chrow in enumerate(chits):\n",
    "# #             chits[hix] = pickle.loads(zlib.decompress(chrow))\n",
    "# #         chits = numpy.array(chits, dtype=\"uint8\")\n",
    "# #         return chits\n",
    "\n",
    "# #     print(\"uncomping\")\n",
    "# #     o_hits = uncomp(o_chits)\n",
    "# #     v_hits = uncomp(v_chits)\n",
    "# #     t_hits = uncomp(t_chits)\n",
    "# #     print(\"straight outta comp-ton\")\n",
    "\n",
    "#   # o_chits, v_chits, t_chits = None, None, None\n",
    "\n",
    "#   # except:\n",
    "#   # # if True:\n",
    "#   #   av_sc, sixs, qixs, hits, hout = run_data(students_start, questions, gammas, model_to_train=None)\n",
    "#   #   #   if s > 100:\n",
    "#   #   #     break\n",
    "#   #     # print(h)\n",
    "#   #     # print(r)\n",
    "#   #     # print(\"***\")\n",
    "\n",
    "#   #   gc.collect()\n",
    "#   #   sixs = numpy.array(sixs, dtype=\"uint16\")\n",
    "#   #   qixs = numpy.array(qixs, dtype=\"uint16\")\n",
    "#   #   hits = numpy.array(hits, dtype=\"uint8\")\n",
    "#   #   for hix, hrow in enumerate(hits):\n",
    "#   #     compd = zlib.compress(pickle.dumps(hrow))\n",
    "#   #     chits[hix] = compd\n",
    "#   #   hout = numpy.array(hout, dtype=\"uint8\")\n",
    "#   #   pickle.dump((sixs, qixs, chits, hout), open(home+\"/synth_data/\" + fname + \".p\", \"wb\"))\n",
    "#   #   chits = None\n",
    "\n",
    "#   # for h in hits[0:10]:\n",
    "#   #     print(h)\n",
    "\n",
    "#   # raise Exception(\"GAR\")\n",
    "\n",
    "#   # for s,q,h,r in zip(sixs, qixs, hits, hout):\n",
    "#   #   print(s,q, r)\n",
    "#   # print(hout)\n",
    "#   # print(int(sum(hout)))\n",
    "#   # print(len(hout))\n",
    "#   # raise Exception(\"DELIBERATE EXCEPTION CALLED\")\n",
    "\n",
    "#   # qlayer = m.get_layer(\"qn_embedding\")\n",
    "#   # print(qlayer.shape)\n",
    "#   # m.get_layer(\"qn_embedding\").set_weights(pre_trained_qns)\n",
    "#   # m.get_layer(\"qn_embedding\").trainable=False\n",
    "\n",
    "\n",
    "#   # hin2 = hin #numpy.array(hin).reshape(-1,(1,1,n_questions))\n",
    "#   # hout2 = numpy.array(hout).reshape(-1,1)\n",
    "\n",
    "#     n_to_keep = 10000\n",
    "\n",
    "#   # qixs = qixs[0:n_to_keep]\n",
    "#   # sixs = sixs[0:n_to_keep]  \n",
    "#   # hits = hits[0:n_to_keep]\n",
    "#   # hout = hout[0:n_to_keep]\n",
    "\n",
    "#   # n_questions = len(numpy.unique(o_qixs))\n",
    "#   # n_students  = len(numpy.unique(o_sixs))\n",
    "\n",
    "\n",
    "\n",
    "#   # n_questions = max(max(o_qixs),max(v_qixs),max(t_qixs))+1\n",
    "#   # n_students = max(max(o_sixs),max(v_sixs),max(t_sixs))+1\n",
    "\n",
    "\n",
    "\n",
    "#   # m = generate_longitudinal_model(n_questions, n_students, emb_w, None) #pre_trained_qns[0:n_questions])\n",
    "\n",
    "#     n_to_test = 1000 #len(hout)//10\n",
    "#     test_choices = numpy.random.choice(range(len(hout)), size=n_to_test)\n",
    "#   # t_in = hin2[test_choices, :]\n",
    "\n",
    "#   # t_hits = hits[test_choices]\n",
    "#   # o_hits = numpy.delete(hits, test_choices, axis=0)\n",
    "\n",
    "#   # qs_in_trimmed_data =  numpy.unique(qixs)\n",
    "#   # t_hits = numpy.array([hits[ix] for ix in test_choices])\n",
    "#   # o_hits = numpy.delete(hits, test_choices, axis=0)\n",
    "#   # hits=None\n",
    "#   # t_hits = t_hits[:, qs_in_trimmed_data]\n",
    "#   # t_hits = t_hits.reshape(-1, len(qs_in_trimmed_data))\n",
    "#   # o_hits = o_hits[:, qs_in_trimmed_data]\n",
    "#   # o_hits = o_hits.reshape(-1, len(qs_in_trimmed_data))\n",
    "\n",
    "#     gc.collect()\n",
    "\n",
    "#   # t_out = hout[test_choices, :]\n",
    "#   # t_out = numpy.array([hout[ix] for ix in test_choices]).reshape(-1,1)\n",
    "#   # o_out = numpy.delete(hout, test_choices, axis=0).reshape(-1,1)\n",
    "#   # hout=None\n",
    "\n",
    "\n",
    "#   # t_sixs = numpy.array([sixs[ix] for ix in test_choices]).reshape(-1,1)\n",
    "#   # # t_sixs = sixs[test_choices, :]\n",
    "#   # o_sixs = numpy.delete(sixs, test_choices, axis=0).reshape(-1,1)\n",
    "#   # sixs=None\n",
    "\n",
    "#   # t_qixs = numpy.array([qixs[ix] for ix in test_choices]).reshape(-1,1)\n",
    "#   # # t_qixs = qixs[test_choices, :]\n",
    "#   # o_qixs = numpy.delete(qixs, test_choices, axis=0).reshape(-1,1)\n",
    "\n",
    "#     print(\"MM\", numpy.min(o_qixs), numpy.max(o_qixs))\n",
    "#     qixs=None\n",
    "  \n",
    "#   # o_in  = numpy.delete(hin2, test_choices, axis=0)\n",
    "  \n",
    "#   # hazard_model = Model(inputs=m.input,\n",
    "#   #                         outputs=m.get_layer(\"alphas\").output)\n",
    "# #         intermediate_output = intermediate_layer_model.predict([qz,sz])\n",
    "       \n",
    "    \n",
    "    \n",
    "# #         print_prs = LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "# # #                                        print(numpy.min(intermediate_layer_model.predict([qz,sz])),\n",
    "# # #                                              numpy.max(intermediate_layer_model.predict([qz,sz]))))\n",
    "# #                                        print(prs_model.predict([qz[0:10],sz[0:10]])))\n",
    "\n",
    "#   # ixs = o_out > 0.5\n",
    "#     ixs = [True if o_out[n]>=0.5 else False for n in range(len(o_out))]\n",
    "#   # print(ixs)\n",
    "#   # print(o_out[ixs])\n",
    "#   # print(o_qixs[ixs])\n",
    "#   # print(o_sixs[ixs])\n",
    "#   # print(o_hits[ixs])\n",
    "#     print_hazard = LambdaCallback(on_epoch_end=lambda batch, logs:\n",
    "#                                   # print(hazard_model.predict([o_qixs[ixs], o_sixs[ixs], o_hits[ixs]])))\n",
    "#                                   print(m.predict([o_qixs[ixs], o_sixs[ixs], o_hits[ixs]]), o_out[ixs]))\n",
    "\n",
    "#         # print_zmask = LambdaCallback(on_epoch_end=lambda batch, logs: \n",
    "#         #                                print(z_model.predict([qz[0:10],sz[0:10]])))\n",
    "\n",
    "#   # n_ones  = int(numpy.sum(o_out, axis=0))\n",
    "#   # n_zeros = len(o_out) - n_ones\n",
    "\n",
    "#   # n_ones =  sum([1 if o_out[n]>=0.5 else 0 for n in range(len(o_out))])\n",
    "#   # n_zeros = sum([1 if o_out[n]<0.5 else 0 for n in range(len(o_out))])\n",
    "\n",
    "# #   geschichte = m.fit([o_qixs, o_sixs, o_hits], o_out, epochs=10000, validation_split=0.01, callbacks=[es], shuffle=True, class_weight=class_weightz)\n",
    "\n",
    "# print(type(o_sixs))\n",
    "# print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iOhg-f9pbesM",
    "outputId": "10322f14-0681-4aad-e50f-cce06b8e3c60",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.metrics import binary_accuracy\n",
    "def gen_and_train(odata, vdata, t_data, emb_w=10, draw=False, cog_model=\"MLP\", q_weight=None, \n",
    "                  monitor=None, balance_classes=True, \n",
    "                  loss=None, metrics=None, reg_w=None):\n",
    "    from keras.callbacks import EarlyStopping, LambdaCallback\n",
    "\n",
    "    reg=\"\"\n",
    "    \n",
    "    (o_sixs, o_qixs, o_hits, o_out), (v_sixs, v_qixs, v_hits, v_out) = (odata, vdata)\n",
    "    \n",
    "#     emb_w = 4\n",
    "    m = None\n",
    "    \n",
    "    config_dict = {}    \n",
    "    config_dict[\"cog_model\"] = cog_model\n",
    "    config_dict[\"emb_w\"]     = emb_w\n",
    "    \n",
    "#     n_ones = int(sum(numpy.ravel(numpy.round(o_out))))\n",
    "#     n_zeros = len(o_out) - n_ones\n",
    "#     print(len(o_out))\n",
    "#     print(\"1s:\", n_ones)\n",
    "#     print(\"0s:\", n_zeros)\n",
    "\n",
    "# #     # minority_w = .75\n",
    "#     if n_zeros > n_ones:\n",
    "#         zero_w = 1.0\n",
    "#         one_w = n_zeros/n_ones\n",
    "#     else:\n",
    "#         zero_w = n_ones/n_zeros\n",
    "#         one_w = 1.0\n",
    "\n",
    "#     class_weightz0 = {\n",
    "#         0: zero_w,\n",
    "#         1: one_w,\n",
    "#     }\n",
    "    \n",
    "#     print(\"cw0\")\n",
    "#     print(class_weightz0)\n",
    "\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weightz = compute_class_weight(\"balanced\", [0,1], o_out)\n",
    "    class_weightz = class_weightz / min(class_weightz)\n",
    "    print(\"class weights:\", class_weightz)\n",
    "    cw0 = {}\n",
    "    for cwix,cw in enumerate(class_weightz):\n",
    "        cw0[cwix] = cw\n",
    "    class_weightz = cw0\n",
    "    print(\"class weights (dict):\", class_weightz)\n",
    "    \n",
    "    # o_out = o_out.reshape(-1,1)\n",
    "    o_out = o_out.astype(float)\n",
    "\n",
    "    n_questions = max(max(o_qixs),max(v_qixs),max(t_qixs))+1\n",
    "    n_students = max(max(o_sixs),max(v_sixs),max(t_sixs))+1\n",
    "\n",
    "#     n_questions = int(o_hits.shape[1])\n",
    "#     n_students = int(max(o_sixs)+1)\n",
    "    print(\"nq, ns\")\n",
    "    print(n_questions, n_students)\n",
    "    \n",
    "    if metrics is None:\n",
    "        metrics = [binary_crossentropy, binary_accuracy, mean_absolute_error, mean_squared_error, f1_loss]\n",
    "#     lozz = \"binary_crossentropy\"\n",
    "    if loss==\"f1_loss\":\n",
    "        loss = f1_loss \n",
    "#     elif loss ==\"f1_loss_micro\":\n",
    "#         loss = f1_loss_micro\n",
    "    if cog_model==\"MLPraw\":\n",
    "        m = generate_MLPraw_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, \n",
    "                                   metrics=metrics, deep=False, reg=reg, reg_w=reg_w, inc_dif=\"dif\")\n",
    "    elif cog_model==\"MLPrawAD\":\n",
    "        m = generate_MLPraw_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, \n",
    "                                   metrics=metrics, deep=False, reg=reg, reg_w=reg_w, inc_dif=\"AD\")\n",
    "    elif cog_model==\"MLPrawADD\":\n",
    "        m = generate_MLPraw_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, \n",
    "                                   metrics=metrics, deep=False, reg=reg, reg_w=reg_w, inc_dif=\"AD+dif\")\n",
    "    elif cog_model==\"MLPrawDen\":\n",
    "        m = generate_MLPraw_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, \n",
    "                               metrics=metrics, deep=False, reg=reg, reg_w=reg_w, inc_dif=\"Dense\")\n",
    "    elif cog_model==\"MLPrawDP\":\n",
    "        m = generate_MLPraw_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, \n",
    "                               metrics=metrics, deep=False, reg=reg, reg_w=reg_w, inc_dif=\"DenP\")\n",
    "    elif cog_model==\"DEEPGAMMA\":\n",
    "        m = generate_DEEPGAMMA_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, \n",
    "                               metrics=metrics, deep=False, reg=reg, reg_w=reg_w)\n",
    "    elif cog_model[0:3]==\"CFM\":\n",
    "        sfoc = False\n",
    "        reg = \"\"\n",
    "        rw  = None\n",
    "        if len(cog_model)==4:\n",
    "            if cog_model[3] == \"z\":\n",
    "                reg = \"l2\"\n",
    "                rw = reg_w\n",
    "            elif cog_model[3] == \"l\":\n",
    "                reg = \"l1\"\n",
    "                rw = reg_w\n",
    "            else:\n",
    "                reg = \"\"\n",
    "                rw  = None\n",
    "        m = create_CFM_model(n_questions, n_students, emb_w, loss=loss, sfocus=sfoc, metrics=metrics, reg=reg, reg_w=rw)\n",
    "#     elif cog_model[0:5]==\"AFMsg\":\n",
    "#         m = create_AFMsg_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics)\n",
    "    elif cog_model==\"RASCHz\":\n",
    "        rw = 5e-8\n",
    "        m = create_RASCH_model(n_questions, n_students, loss=loss, metrics=metrics, reg=rw)\n",
    "    elif cog_model==\"RASCH\":\n",
    "        m = create_RASCH_model(n_questions, n_students, loss=loss, metrics=metrics)\n",
    "    elif cog_model.startswith(\"AFMx\"):\n",
    "        if len(cog_model)==5:\n",
    "            if cog_model[4]==\"z\":\n",
    "                reg=\"l2\"\n",
    "            elif cog_model[4]==\"l\":\n",
    "                reg=\"l1\"\n",
    "            else:\n",
    "                reg=None\n",
    "        m = create_AFMx_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics, reg=reg)\n",
    "    elif cog_model.startswith(\"AFMg\"):\n",
    "        if len(cog_model)==5:\n",
    "            if cog_model[4]==\"z\":\n",
    "                reg=\"l2\"\n",
    "            elif cog_model[4]==\"l\":\n",
    "                reg=\"l1\"\n",
    "            else:\n",
    "                reg=None\n",
    "        m = create_AFMg_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics, reg=reg)\n",
    "    elif cog_model.startswith(\"AFM\"):\n",
    "        if len(cog_model)==4:\n",
    "            if cog_model[3]==\"z\":\n",
    "                reg=\"l2\"\n",
    "            elif cog_model[3]==\"l\":\n",
    "                reg=\"l1\"\n",
    "            else:\n",
    "                reg=None\n",
    "        m = create_AFM_model(n_questions, n_students, emb_w, loss=loss, sfocus=False, metrics=metrics, reg=reg)\n",
    "\n",
    "    elif cog_model==\"MLTM0z\":\n",
    "        m = generate_MLTM0_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics, l2=True)\n",
    "    elif cog_model==\"MLTM0\":\n",
    "        m = generate_MLTM0_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics, l2=False)\n",
    "    elif cog_model==\"MLTMz\":\n",
    "        m = generate_MLTM_raw_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics, reg=\"l2\", reg_w=reg_w)\n",
    "    elif cog_model==\"MLTMl\":\n",
    "        m = generate_MLTM_raw_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics, reg=\"l1\")\n",
    "    elif cog_model==\"MLTMp\":\n",
    "        print(\"TARTOLA\")\n",
    "        m = generate_MLTMp_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics)    \n",
    "    elif cog_model==\"MLTMa\":\n",
    "        m = generate_MLTMa_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics)\n",
    "    elif cog_model.startswith(\"MLTMb\"):\n",
    "        print(\"KOG MOD\", cog_model)\n",
    "        print(cog_model[-1])\n",
    "        reg = \"l2\" if cog_model[-1]=='z' else (\"l1\" if cog_model[-1]=='l' else None)\n",
    "        print(\"REGG:\", reg)\n",
    "        m = generate_MLTMb_model(n_questions, n_students, emb_w, loss=loss, metrics=metrics, \n",
    "                                 reg=reg, reg_w=reg_w)\n",
    "    elif cog_model==\"MLTM\":\n",
    "        print(\"WAnkOPHONE\")\n",
    "        print(\"RAW w init50\")\n",
    "        m = generate_MLTM_raw_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, metrics=metrics, \n",
    "                                    init50=True, reg=None)\n",
    "    elif cog_model.startswith(\"CONC\"):\n",
    "        if cog_model[-1]==\"z\":\n",
    "            reg=\"l2\"\n",
    "        else:\n",
    "            reg=None\n",
    "        m = generate_CONC_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, metrics=metrics, reg=reg)\n",
    "    elif cog_model.startswith(\"MLP\"):\n",
    "        if cog_model[-1]==\"z\":\n",
    "            reg=\"l2\"\n",
    "        else:\n",
    "            reg=None\n",
    "        if cog_model.startswith(\"MLPd\"):\n",
    "            m = generate_MLPd_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, metrics=metrics, reg=reg)\n",
    "#         elif cog_model.startswith(\"MLPs\"):\n",
    "#             print(\"MLPS MODELSSQQQ\")\n",
    "#             m = generate_MLP2_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, metrics=metrics, reg=reg)\n",
    "        else:\n",
    "            m = generate_MLP_model(n_questions, n_students, emb_w, ptqs=None, loss=loss, non_neg=False, \n",
    "                                   metrics=metrics, deep=False, reg=reg, reg_w=reg_w)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Unknown cognitive model {}\".format(cog_model))\n",
    "\n",
    "    # t_hits = t_hits[:, 0:n_questions]\n",
    "\n",
    "    print(\"TRAINING:\")\n",
    "    print(\"Unique students:\", n_students)\n",
    "    print(\"Unique questions:\", n_questions)\n",
    "    print(\"Total activity:\", len(o_out), \"(\",numpy.sum(o_out),\")\")\n",
    "\n",
    "    print(\"ov shape\", o_hits.shape, v_hits.shape)\n",
    "\n",
    "    monitor = \"loss\"\n",
    "    mon_mode=\"min\"\n",
    "    bl = math.inf\n",
    "    if monitor==\"val_accuracy\":\n",
    "        mon_mode = \"max\"\n",
    "        bl = -math.inf\n",
    "    elif monitor ==\"val_f1_metric\":\n",
    "        mon_mode = \"max\"\n",
    "        bl = -math.inf\n",
    "    elif monitor[-5:] == \"error\":\n",
    "        mon_mode = \"min\"\n",
    "        bl = math.inf\n",
    "    elif monitor[-4:] ==\"loss\":\n",
    "        mon_mode = \"min\"\n",
    "        bl = math.inf\n",
    "    elif monitor == \"binary_crossentropy\":\n",
    "        mon_mode = \"min\"\n",
    "        bl = math.inf\n",
    "        \n",
    "    print(\"monitoring info\", monitor, mon_mode)\n",
    "#     es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, baseline=math.inf)\n",
    "    \n",
    "#     es = EarlyStopping(monitor=monitor, patience=15, restore_best_weights=True, mode=mon_mode, baseline=bl)\n",
    "    es = EarlyStopping(monitor=\"loss\", patience=15, restore_best_weights=True, mode=\"min\", baseline=math.inf)\n",
    "    \n",
    "#     es = EarlyStopping(monitor=\"val_accuracy\", patience=10, restore_best_weights=True, baseline=-math.inf)\n",
    "#     es = EarlyStopping(monitor=\"val_f1_m\", patience=10, restore_best_weights=True, mode=\"max\")\n",
    "\n",
    "#     print(\"check assertions\")\n",
    "#     assert not numpy.any(numpy.isnan(o_qixs))\n",
    "#     assert not numpy.any(numpy.isnan(o_sixs))\n",
    "#     assert not numpy.any(numpy.isnan(o_hits))\n",
    "#     assert not numpy.any(numpy.isnan(o_out))\n",
    "\n",
    "    bs = len(o_out)\n",
    "    \n",
    "#     from keras.utils import plot_model\n",
    "#     if draw:\n",
    "#         print(\"plotting model\")\n",
    "#         plot_model(m, to_file=cog_model+str(emb_w)+\".png\", show_shapes=True, show_layer_names=True)\n",
    "#         return m, None, config_dict\n",
    "    \n",
    "\n",
    "    o_qixs = o_qixs.reshape(-1,1)\n",
    "    o_sixs = o_sixs.reshape(-1,1)\n",
    "    o_hits = o_hits.reshape(-1, n_questions)\n",
    "    o_out = o_out.reshape(-1,1)\n",
    "\n",
    "    v_qixs = v_qixs.reshape(-1,1)\n",
    "    v_sixs = v_sixs.reshape(-1,1)\n",
    "    v_hits = v_hits.reshape(-1, n_questions)\n",
    "    v_out = v_out.reshape(-1,1)\n",
    "\n",
    "    \n",
    "    lcb = keras.callbacks.LambdaCallback(\n",
    "#         on_epoch_begin= lambda e,l: print(\"Begin\", m.get_layer(\"qn_embedding\").get_weights()[0]),\n",
    "        on_epoch_end= lambda e,l: print(\"Begin\", m.get_layer(\"qn_embedding\").get_weights()[0]),\n",
    "    )\n",
    "    \n",
    "    print(m.summary())\n",
    "    print(\"fitting\")\n",
    "\n",
    "    assert class_weightz is not None\n",
    "    assert o_qixs is not None\n",
    "    assert o_sixs is not None\n",
    "    assert o_hits is not None\n",
    "    assert o_out is not None\n",
    "    assert v_qixs is not None\n",
    "    assert v_sixs is not None\n",
    "    assert v_hits is not None\n",
    "    assert v_out is not None\n",
    "    assert es is not None\n",
    "    \n",
    "    geschichte = m.fit([o_qixs, o_sixs, o_hits], o_out, \n",
    "                       verbose=1,\n",
    "#                        batch_size=320, epochs=10000, \n",
    "                       batch_size=320, epochs=100,\n",
    "#                        validation_split=0.1,\n",
    "                       validation_data=((v_qixs, v_sixs, v_hits), v_out), \n",
    "#                        callbacks=[es], \n",
    "                       shuffle=True,\n",
    "                       class_weight=(class_weightz if balance_classes else None))\n",
    "    print(\"fertig\", cog_model, emb_w, loss, monitor)\n",
    "    return m, geschichte, config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.layer_utils import count_params\n",
    "from sklearn.metrics import log_loss\n",
    "def AIC(y, y_hat, n_params, n_obs=1):\n",
    "#     y_hat = model.predict(X)\n",
    "#     resid = y - y_hat\n",
    "#     sse = numpy.sum(numpy.power(resid,2)) / n_obs\n",
    "# y_true = np.array([0, 1, 1])\n",
    "# y_pred = np.array([0.1, 0.2, 0.9])\n",
    "\n",
    "#     print(y)\n",
    "#     print(y_hat)\n",
    "\n",
    "    ll = -log_loss(y, y_hat)\n",
    "    # 0.60671964791658428\n",
    "#     print(\"LL\", ll)\n",
    "    k   = n_params\n",
    "    aic = 2*k - 2* math.log(ll)\n",
    "    return aic\n",
    "\n",
    "def run_acc_mae_test(m, o_data, t_data, config_dict, print_clfn_report=False):\n",
    "    from sklearn.metrics import accuracy_score, mean_absolute_error, f1_score\n",
    "    print(config_dict[\"cog_model\"], \"£MB_W\", config_dict[\"emb_w\"])\n",
    "    t_sixs, t_qixs, t_hits, _ = t_data\n",
    "    o_sixs, o_qixs, o_hits, _ = o_data\n",
    "    p_hats = numpy.round( m.predict( [t_qixs, t_sixs, t_hits] ) )\n",
    "    p_trues = t_out\n",
    "    t_f1 = f1_score(p_trues, p_hats, average=\"macro\")\n",
    "    f1_micro = f1_score(p_trues, p_hats, average=\"micro\")\n",
    "    t_acc = accuracy_score(p_trues, p_hats)\n",
    "    t_mae = mean_absolute_error(p_trues, p_hats)\n",
    "    n_params = count_params(m.trainable_weights)\n",
    "    aic = 0 #AIC(p_trues, p_hats, n_params)\n",
    "    print(\"macro\", t_f1  )\n",
    "    print(\"micro\", f1_micro)\n",
    "    print( t_acc )\n",
    "    print( t_mae )\n",
    "    if print_clfn_report:\n",
    "        from sklearn.metrics import classification_report\n",
    "        print(classification_report(p_trues, p_hats))\n",
    "    return t_f1, t_acc, t_mae, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# def distance(a,b_list, cosine=False):\n",
    "# #     return numpy.sqrt(numpy.sum(numpy.power(a-b,2)))\n",
    "#     a = numpy.array(a).reshape(1,-1)\n",
    "#     if not cosine:\n",
    "#         #return scipy.spatial.distance.euclidean(a,b)\n",
    "#         return scipy.spatial.distance.cdist(a,b_list, metric=\"euclidean\")\n",
    "#     else:\n",
    "#         dasErgebnis = scipy.spatial.distance.cdist(a,b_list, metric=\"cosine\")\n",
    "# #         for x in reswlt.flatten():\n",
    "# #             if math.isnan(x):\n",
    "# #                 print(\"Nan is cosine distance result\")\n",
    "# #                 print(a)\n",
    "# #                 print(list(b_list))\n",
    "# #                 raise Exception(\"NAN in cos distance\")\n",
    "#         if numpy.isnan(numpy.sum(dasErgebnis)):\n",
    "#             dasErgebnis = numpy.nan_to_num(dasErgebnis, copy=False, nan=1.0, posinf=None, neginf=None)\n",
    "#         return dasErgebnis\n",
    "\n",
    "    \n",
    "def distance(a, b_list):\n",
    "    a = numpy.array(a).reshape(1,-1)\n",
    "    b_list = numpy.array(b_list).reshape(-1,a.shape[1]) # len(b_list) x width(a)\n",
    "    return scipy.spatial.distance.cdist(a,b_list, metric=\"euclidean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def build_adjacency_matrix(points_list, cosine=False):\n",
    "    dim = len(points_list) # num of points is the dim of the adj_mx\n",
    "#     print(\"dim is\", dim)\n",
    "    flat_dmx = [] # numpy.zeros((dim,dim)) # empty mx\n",
    "    \n",
    "    for a_ix in range(dim-1):\n",
    "        a = points_list[a_ix]\n",
    "#         print(a_ix, \"a\\n\",a)\n",
    "        to_comp = points_list[a_ix+1:]\n",
    "#         print(\"# to comp\")\n",
    "#         print(len(to_comp))\n",
    "#         print(to_comp)\n",
    "        ds = distance(a, to_comp).ravel()\n",
    "#         print(\"# little ds\", len(ds))\n",
    "#         print(ds)\n",
    "        flat_dmx.extend(list(ds))\n",
    "#     flat_dmx = list(numpy.array(flat_dmx).ravel())\n",
    "    \n",
    "    \n",
    "#     for ax,a in enumerate(points_list):\n",
    "#         for bx,b in enumerate(points_list):\n",
    "#             if ax<bx: #only fill in the top right triangle of the matrix\n",
    "#                 flat_dmx.append(distance(a,b, cosine=cosine))\n",
    "# #                 adj_mx[ax,bx] = distance(a,b)\n",
    "    print(\"flat dmx length is \", len(flat_dmx))\n",
    "    return flat_dmx\n",
    "\n",
    "\n",
    "def find_pairwise_rbo_in_adj_mx_list(adj_mx_list):\n",
    "    ranking_list = []\n",
    "    for amx in adj_mx_list:\n",
    "#         rankings = list(numpy.argsort(amx))\n",
    "        rankings = amx\n",
    "        ranking_list.append(rankings)\n",
    "    \n",
    "    rbos = []\n",
    "    seen = set()\n",
    "    for ix,r1 in enumerate(ranking_list):\n",
    "        for jx,r2 in enumerate(ranking_list):\n",
    "            if ix!=jx:\n",
    "                if ((ix,jx) not in seen) and ((jx,ix) not in seen):\n",
    "#                     print(\"r1\", r1)\n",
    "#                     print(\"r2\", r2)\n",
    "                    this_rbo = spearmanr(r1, r2)[0]\n",
    "#                     this_rbo = rbo_score(r1, r2, p=0.98)\n",
    "                    rbos.append(this_rbo)\n",
    "                    seen.add((ix,jx))\n",
    "                    seen.add((jx,ix))\n",
    "\n",
    "    print(\"correlations\", rbos)\n",
    "    mean_rbo = numpy.mean(rbos)\n",
    "#     median_rbo = numpy.median(rbos)\n",
    "    sd_rbo = numpy.std(rbos)\n",
    "    return mean_rbo, sd_rbo\n",
    "\n",
    "\n",
    "def find_pairwise_std_in_adj_mx_list(adj_mx_list):\n",
    "#     for a in adj_mx_list:\n",
    "#         plt.hist(a)\n",
    "    plt.show()\n",
    "    \n",
    "    mean_dist = numpy.mean(adj_mx_list)\n",
    "    \n",
    "    adj_mx_list = numpy.array(adj_mx_list)\n",
    "#     mean_distances = numpy.mean(adj_mx_list, axis=1).reshape(-1,1)\n",
    "#     min_distances = numpy.min(adj_mx_list, axis=1).reshape(-1,1)\n",
    "    n_adj_mx_list = adj_mx_list / mean_dist\n",
    "    vr = numpy.std(adj_mx_list, axis=0)\n",
    "    n_vr = numpy.std(n_adj_mx_list, axis=0) \n",
    "#     plt.hist(vr)\n",
    "#     plt.show()\n",
    "#     plt.hist(n_vr)\n",
    "#     plt.show()\n",
    "#     print(vr)\n",
    "#     print(n_vr)\n",
    "#     print(mean_distances)\n",
    "    vr   = numpy.mean(vr)\n",
    "    n_vr = numpy.mean(n_vr)\n",
    "    return vr, n_vr\n",
    "    \n",
    "flax = [\n",
    "    [1,2,3],\n",
    "    [1,2,3],\n",
    "    [1,3,10]\n",
    "]\n",
    "find_pairwise_std_in_adj_mx_list(flax)\n",
    "\n",
    "\n",
    "flax2 = [\n",
    "    [1,2,5],\n",
    "    [1,5,3],\n",
    "    [5,3,10]\n",
    "]\n",
    "find_pairwise_std_in_adj_mx_list(flax2)\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import sample\n",
    "from numpy.random import uniform\n",
    "import numpy as np\n",
    "from math import isnan\n",
    " \n",
    "# def hopkins(X):\n",
    "#     d = X.shape[1]\n",
    "#     #d = len(vars) # columns\n",
    "#     n = len(X) # rows\n",
    "#     m = int(0.1 * n) # heuristic from article [1]\n",
    "#     nbrs = NearestNeighbors(n_neighbors=1).fit(X)\n",
    " \n",
    "#     rand_X = sample(range(0, n, 1), m)\n",
    " \n",
    "#     ujd = []\n",
    "#     wjd = []\n",
    "#     for j in range(0, m):\n",
    "#         u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n",
    "#         ujd.append(u_dist[0][1])\n",
    "#         w_dist, _ = nbrs.kneighbors(X[rand_X[j]].reshape(1, -1), 2, return_distance=True)\n",
    "#         wjd.append(w_dist[0][1])\n",
    " \n",
    "#     H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
    "#     if isnan(H):\n",
    "#         print (ujd, wjd)\n",
    "#         H = 0\n",
    " \n",
    "#     return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def compare_adj_matrices(adj_mcs, handle=None):\n",
    "    \n",
    "#     vr, n_vr = find_pairwise_std_in_adj_mx_list(adj_mcs)\n",
    "    vr, sd = find_pairwise_rbo_in_adj_mx_list(adj_mcs)\n",
    "    \n",
    "    max_val=0\n",
    "    for m in adj_mcs:\n",
    "        this_max = numpy.amax(m)\n",
    "        if this_max>max_val:\n",
    "            max_val = this_max\n",
    "    if max_val == 0:\n",
    "        raise Exception(\"Distance matrix is all zeros\")\n",
    "            \n",
    "    flattened_mxs = adj_mcs\n",
    "#     mean_dist = numpy.mean(adj_mcs)\n",
    "    \n",
    "    if handle:\n",
    "        print(\"For\", handle)\n",
    "    print(\"number of flattened adj mxs = \", len(flattened_mxs))\n",
    "    print(\"number of elements per flattened mx = \", len(flattened_mxs[0]))\n",
    "    print(\"distances min/max/mu/med:\", numpy.min(adj_mcs), numpy.max(adj_mcs), numpy.mean(adj_mcs), numpy.median(adj_mcs))\n",
    "#     print(\"stdev for technique\", numpy.std(adj_mcs))\n",
    "#     print(\"stdev/mu\", numpy.std(adj_mcs)/ mean_dist)\n",
    "    \n",
    "#     if normalise:\n",
    "    \n",
    "#     sc = MinMaxScaler()\n",
    "#     norm_flattened_mxs = sc.fit_transform(flattened_mxs)\n",
    "\n",
    "#     norm_flattened_mxs = []\n",
    "#     for mx in flattened_mxs:\n",
    "#         mxn = numpy.array(mx) / mean_dist\n",
    "#         norm_flattened_mxs.append(mxn)\n",
    "\n",
    "#     corr =0\n",
    "#     cnt  =0\n",
    "#     seen=set()\n",
    "#     for ix,src_mx in enumerate(flattened_mxs):\n",
    "#         for jx,des_mx in enumerate(flattened_mxs):\n",
    "#             print(\"ixjx\",ix,jx)\n",
    "#             if ix!=jx and (ix,jx) not in seen and (jx,ix) not in seen:\n",
    "#                 seen.add((ix,jx))\n",
    "#                 seen.add((jx,ix))\n",
    "#                 cnt  += 1\n",
    "#                 this_corr = spearmanr(src_mx, des_mx, axis=0)[0]\n",
    "#                 print(\"raw corr=\", this_corr)\n",
    "#                 corr += this_corr\n",
    "#             else:\n",
    "#                 print(\"seen\", ix,jx)\n",
    "\n",
    "#     print(\"corr=\",corr,\"cnt=\",cnt)\n",
    "#     corr = corr/cnt\n",
    "    \n",
    "#     n_corr =0\n",
    "#     cnt    =0\n",
    "#     seen=set()\n",
    "#     for ix,src_mx in enumerate(norm_flattened_mxs):\n",
    "#         for jx,des_mx in enumerate(norm_flattened_mxs):\n",
    "#             print(\"n ixjx\",ix,jx)\n",
    "#             if ix!=jx and (ix,jx) not in seen and (jx,ix) not in seen:\n",
    "#                 seen.add((ix,jx))\n",
    "#                 seen.add((jx,ix))\n",
    "#                 cnt  += 1\n",
    "#                 this_corr = spearmanr(src_mx, des_mx, axis=0)[0]\n",
    "#                 print(\"normed corr=\", this_corr)\n",
    "#                 n_corr += this_corr\n",
    "#             else:\n",
    "#                 print(\"seen\", ix,jx)\n",
    "#     print(\"n_corr=\",n_corr,\"ncnt=\",cnt)\n",
    "#     n_corr = n_corr/cnt\n",
    "    \n",
    "#     mu = numpy.mean(flattened_mxs, axis=0)\n",
    "#     s2 = numpy.var(flattened_mxs, axis=0)\n",
    "\n",
    "#     n_mu = numpy.mean(norm_flattened_mxs, axis=0)\n",
    "#     n_s2 = numpy.var(norm_flattened_mxs, axis=0)\n",
    "    \n",
    "#     print(\"Correlation=\", corr)\n",
    "#     print(\"Norm Corr/n=\", n_corr)\n",
    "    print(\"Average var       =\", vr, \"({})\".format(sd))\n",
    "#     print(\"Norm Av var       =\", n_vr)\n",
    "#             print(\"Norm/d corr/n Med =\", correltn_md)\n",
    "#             print(\"Norm/d corr/n Mean=\", correltn_mn)\n",
    "    return vr, sd, 0, 0 #TODO deprecate these zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat dmx length is  6\n",
      "flat dmx length is  6\n",
      "ad1 [2.8284271247461903, 2.23606797749979, 2.23606797749979, 5.0, 5.0, 0.0]\n",
      "ad2 [2.8284271247461903, 2.23606797749979, 2.23606797749979, 5.0, 5.0, 0.0]\n",
      "correlations [0.9999999999999999]\n",
      "number of flattened adj mxs =  2\n",
      "number of elements per flattened mx =  6\n",
      "distances min/max/mu/med: 0.0 5.0 2.8834271799576285 2.53224755112299\n",
      "Average var       = 0.9999999999999999 (0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9999999999999999, 0.0, 0, 0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mx1 = [ [3, 3], [3, 5], [3,3], [5,8] ]\n",
    "mx1 = [ [2, 3], [4, 5], [1,1], [1,1] ]\n",
    "mx2 = [ [2, 3], [4, 5], [1,1], [1,1] ]\n",
    "\n",
    "# mx1 = [[4],[3],[2],[1],[0]]\n",
    "# mx2 = [[0],[1],[1],[1],[4]]\n",
    "\n",
    "ad1 = build_adjacency_matrix(mx1)\n",
    "ad2 = build_adjacency_matrix(mx2)\n",
    "\n",
    "# ad1 = [[0],[2],[1]]\n",
    "# ad2 = [[2],[1],[0]]\n",
    "      \n",
    "print(\"ad1\", ad1)\n",
    "print(\"ad2\", ad2)\n",
    "\n",
    "compare_adj_matrices( [ad1, ad2] )\n",
    "\n",
    "# list1 = ['a','b','c','d','e']\n",
    "# list2 = ['b','a','c','d','e']\n",
    "# list3 = ['a','b','c','e','d']\n",
    "    \n",
    "# score1 = rbo_score(list1, list2)\n",
    "# print(score1)\n",
    "# # assert score1 == 0.8\n",
    "# score2 = rbo_score(list1, list3)\n",
    "# print(score2)\n",
    "# # assert score2 == 0.95\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig\n",
      "[[ 2 45]\n",
      " [30 62]]\n",
      "samez:\n",
      " SpearmanrResult(correlation=array([[nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan]]), pvalue=array([[nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan]]))\n",
      "(4, 4)\n",
      "randz:\n",
      " SpearmanrResult(correlation=array([[ 1.        ,  0.00834949, -0.05825257,  0.03508272],\n",
      "       [ 0.00834949,  1.        , -0.02431038, -0.01282159],\n",
      "       [-0.05825257, -0.02431038,  1.        ,  0.13143306],\n",
      "       [ 0.03508272, -0.01282159,  0.13143306,  1.        ]]), pvalue=array([[0.        , 0.93429159, 0.56482397, 0.72894962],\n",
      "       [0.93429159, 0.        , 0.81026602, 0.89924979],\n",
      "       [0.56482397, 0.81026602, 0.        , 0.19241477],\n",
      "       [0.72894962, 0.89924979, 0.19241477, 0.        ]]))\n",
      "(4, 4)\n",
      "scalz:\n",
      " SpearmanrResult(correlation=array([[1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1.]]), pvalue=array([[0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0.]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjm49/.venvs/isaac/lib/python3.6/site-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(666)\n",
    "n_to_comp = 100\n",
    "mx_side = 2\n",
    "orig  = numpy.random.randint(0,100, size=(mx_side, mx_side))\n",
    "samez = [ orig ] * n_to_comp\n",
    "randz = [ orig ] + [ numpy.random.randint(0,100, size=(mx_side, mx_side)) for _ in range(n_to_comp-1) ]\n",
    "scalz = [ orig*(i+1) for i in range(n_to_comp) ]\n",
    "\n",
    "print(\"orig\")\n",
    "print(orig)\n",
    "\n",
    "# print(\"random\")\n",
    "# print(randz)\n",
    "\n",
    "# print(\"scaled\")\n",
    "# print(scalz)\n",
    "\n",
    "samez_flat = [numpy.ravel(s) for s in samez]\n",
    "# print(samez_flat)\n",
    "sp_r = spearmanr( samez_flat, axis=0 )\n",
    "print(\"samez:\\n\",sp_r)\n",
    "print(sp_r[0].shape)\n",
    "\n",
    "randz_flat = [numpy.ravel(r) for r in randz]\n",
    "# print(randz_flat)\n",
    "sp_r = spearmanr(randz_flat, axis=0)\n",
    "print(\"randz:\\n\", sp_r)\n",
    "print(sp_r[0].shape)\n",
    "\n",
    "scalz_flat = [numpy.ravel(c) for c in scalz]\n",
    "# print(scalz_flat)\n",
    "sp_r = spearmanr( scalz_flat, axis=0)\n",
    "print(\"scalz:\\n\",sp_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_history_results(history_results, o_data, t_data):\n",
    "    import copy \n",
    "    rankin = []\n",
    "    max_acc = -math.inf\n",
    "    \n",
    "    for item in history_results:\n",
    "#     config_dict, m, h = item\n",
    "        config_dict, m, h = item\n",
    "        config_dict = copy.copy(config_dict)\n",
    "        cog_model = config_dict[\"cog_model\"]\n",
    "        emb_w = config_dict[\"emb_w\"]\n",
    "        try:\n",
    "            q_weight = config_dict[\"q_weight\"]\n",
    "            config_dict[\"cog_model\"] = config_dict[\"cog_model\"] + \" \" + str(emb_w) + \" \" + str(q_weight)\n",
    "        except:\n",
    "            pass\n",
    "#             raise Exception(\"No such key: q_weight\")\n",
    "\n",
    "        v_loss = h.history[\"val_loss\"]\n",
    "        v_acc  = h.history[\"val_accuracy\"]\n",
    "        v_mse   = h.history[\"val_mean_absolute_error\"]\n",
    "        o_loss   = h.history[\"loss\"]\n",
    "        o_acc    = h.history[\"accuracy\"]\n",
    "        o_mse    = h.history[\"mean_absolute_error\"]\n",
    "        plot_acc = v_acc#[0:-10]\n",
    "        plot_loss = v_loss#[0:-10]\n",
    "        plot_mse = v_mse#[0:-10]\n",
    "\n",
    "        t_acc, t_mae = run_acc_mae_test(m, o_data, t_data, config_dict)\n",
    "\n",
    "        mod_name = cog_model +\" \"+ str(emb_w)\n",
    "        try:\n",
    "            mod_name = mod_name + \" \"+ str(q_weight)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        tup = (t_mae, t_acc, min(v_mse), max(v_acc), mod_name)\n",
    "        rankin.append( tup ) \n",
    "        if max_acc < max(v_acc):\n",
    "            max_acc = max(v_acc)\n",
    "            max_mod = cog_model +\" \"+ str(emb_w)\n",
    "            min_mse = min(v_mse)\n",
    "            min_loss = min(v_loss)\n",
    "            best_m = m\n",
    "        \n",
    "    print(\"**\", max_mod, max_acc, min_loss, min_mse)\n",
    "    m = best_m\n",
    "    \n",
    "    rankin = sorted(rankin)\n",
    "    for r in rankin:\n",
    "               print(r[-1],\"&\", numpy.round(r[1],2),\"&\", numpy.round(r[0],2),\"\\\\\\\\\")\n",
    "#         print(r[-1],\"&\", numpy.round(r[1],2),\"({})\".format(numpy.round(r[3],2)),\"&\", numpy.round(r[0],2), \"({})\".format(numpy.round(r[2],2)),\"\\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####\n",
    "# ## NEXT FEW CELLS: NeurIPS Compo 2020 dataset\n",
    "# #####\n",
    "\n",
    "# test_df = pandas.DataFrame.from_csv(\"./starter_kit/submission_templates/submission_task_1_2.csv\", index_col=\"QuestionId\")\n",
    "# sids = test_df[\"UserId\"]\n",
    "# qids = test_df.index\n",
    "\n",
    "# test_sids = set(sids)\n",
    "# test_qids = set(qids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_sixs = numpy.array([uniq_sids.index(s) for s in sids]).reshape(-1,1)\n",
    "# t_qixs = numpy.array([uniq_qids.index(q) for q in qids]).reshape(-1,1)\n",
    "\n",
    "# t_hits = []\n",
    "# for six,qix in zip(t_sixs,t_qixs):\n",
    "#     print(six,qix)\n",
    "#     zs = last_h[six]\n",
    "#     chits.append(zs)\n",
    "#     zs[qix] += 1\n",
    "#     print(sum(zs))\n",
    "# t_hits = numpy.array(t_hits)\n",
    "# t_hits = pca.transform(t_hits)\n",
    "\n",
    "# fnm = home+\"/models/\" + handle.replace(\"/\",\"~\") + \"_\" + str(rep)\n",
    "# m = keras.models.load_model(fnm, custom_objects={'WeightClip': WeightClip}, compile=False)\n",
    "# results = m.predict([t_qixs, t_sixs, t_hits])\n",
    "\n",
    "# print(\"----\")\n",
    "# for r in results:\n",
    "#     print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df = pandas.DataFrame.from_csv(\"./starter_kit/data/train_data/train_task_1_2.csv\", index_col=\"QuestionId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_sids)\n",
    "# print(raw_df[\"UserId\"].isin(test_sids))\n",
    "# print(raw_df.index.isin(test_qids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_relevant = raw_df.loc[ (raw_df[\"UserId\"] in test_sids & raw_df.index in test_qids) ]\n",
    "# print(len(test_relevant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sids = sids\n",
    "# test_qids = qids\n",
    "\n",
    "# indices = numpy.random.choice(len(raw_df), size=50000, replace=False)\n",
    "\n",
    "\n",
    "# sids = raw_df[\"UserId\"]#.iloc[indices]\n",
    "# qids = raw_df.index#[indices]\n",
    "# hout = raw_df[\"IsCorrect\"]#.iloc[indices]\n",
    "# print(len(sids))\n",
    "# del raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniq_qids = list(numpy.unique(qids))\n",
    "# print(len(uniq_qids))\n",
    "# qixlookup = {}\n",
    "# for ix,uq in enumerate(uniq_qids):\n",
    "#     qixlookup[uq] = ix\n",
    "    \n",
    "# chits = []\n",
    "# last_h = {}\n",
    "\n",
    "# # six_lookup = {}\n",
    "# uniq_sids = list(numpy.unique(sids))\n",
    "# sixlookup={}\n",
    "# for ix,us in enumerate(uniq_sids):\n",
    "#     sixlookup[us] = ix\n",
    "\n",
    "# print(\"built lookups\")\n",
    "    \n",
    "# for sid in uniq_sids:\n",
    "#     six = sixlookup[sid]\n",
    "#     last_h[six] = [0]*len(uniq_qids)\n",
    "\n",
    "# print(\"init'd last_h lookup\")\n",
    "    \n",
    "# v_indices = numpy.random.choice(len(sids), size=1000, replace=False)\n",
    "\n",
    "# sixs = numpy.array([sixlookup[s] for s in sids])\n",
    "# print(\"sixs remap done\")\n",
    "# qixs = numpy.array([qixlookup[q] for q in qids])\n",
    "# print(\"qixs remap done\")\n",
    "# hout = numpy.array(hout)\n",
    "# print(\"EOND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heu = generate_heu_autoencoder(len(uniq_qids), 100)\n",
    "# es = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "        \n",
    "# for six,qix in zip(sixs,qixs):\n",
    "#     print(six,qix)\n",
    "#     zs = last_h[six]\n",
    "#     chits.append(zs)\n",
    "#     zs[qix] += 1\n",
    "#     print(sum(zs))\n",
    "    \n",
    "#     if len(chits > 1000):\n",
    "#         heu.fit(o_hits, o_hits, callbacks=[es], validation_split=0.05, epochs=10000, batch_size=len(chits), shuffle=True)\n",
    "#         chits = []\n",
    "# heu.fit(o_hits, o_hits, callbacks=[es], validation_split=0.05, epochs=10000, batch_size=len(chits), shuffle=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./real_data/examliftb1_LFA_strat_1000000\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(658050, 1130) None\n",
      "(1254, 1130)\n",
      "(1258, 1130)\n"
     ]
    }
   ],
   "source": [
    "seen = None\n",
    "max_s = 1000000\n",
    "# if dataset_handle == \"cmu_geom_steplevel\":\n",
    "#     (sixs, qixs, hout) = pickle.load(open(home+\"/real_data/cmu_geom_steplevel.p\", \"rb\"))\n",
    "#     min_hist = 0\n",
    "# elif dataset_handle == \"examliftb1\":\n",
    "#     (sixs, qixs, hout) = pickle.load(open(home+\"/real_data/XL1041.p\", \"rb\"))\n",
    "#     min_hist = 40\n",
    "# else:\n",
    "#     raise Exception(\"Invalid dataset handle \" + str(dataset_handle))\n",
    "\n",
    "# dataset_handle = \"isaac\" \n",
    "dataset_handle = \"examliftb1\" \n",
    "# dataset_handle = \"cmu_geom_steplevel\" \n",
    "\n",
    "# dataset_name = \"examliftb1\"+str(max_s)\n",
    "dataset_name = dataset_handle+\"_LFA_strat_\"+str(max_s)#+\"_stepped\"\n",
    "fnm = home+\"/real_data/\" + dataset_name\n",
    "# fnm = home+\"/real_data/\" + dataset_name\n",
    "print(fnm)\n",
    "with open(fnm, 'rb') as f:\n",
    "     data_bundle = pickle.load(f)\n",
    "        \n",
    "# ./real_data/examliftb1100000\n",
    "\n",
    "odata, vdata, tdata, sid_six_lookup, qid_qix_lookup = data_bundle\n",
    "(o_sixs, o_qixs, o_hits, o_out), (v_sixs, v_qixs, v_hits, v_out), (t_sixs, t_qixs, t_hits, t_out) = (odata, vdata, tdata)\n",
    "print(o_hits.shape, print(type(o_hits)))\n",
    "print(v_hits.shape)\n",
    "print(t_hits.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "./real_data/isaac_LFA_strat_110000_stepped\n",
    "<class 'scipy.sparse.csr.csr_matrix'>\n",
    "(110028, 6294) None\n",
    "(110, 6294)\n",
    "(111, 6294)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_s 1000000\n",
      "1254 706\n",
      "1258 751\n",
      "GO FOR RASCH1//(xe/px)#1000000\n",
      "checking for cached file ./lfa_models/RASCH1~~(xe~px)#1000000_0\n",
      "./lfa_models/RASCH1~~(xe~px)#1000000_0 found\n",
      "class weights: [2.67326092 1.        ]\n",
      "class weights (dict): {0: 2.6732609156777154, 1: 1.0}\n",
      "nq, ns\n",
      "1130 2512\n",
      "Using univariate Rasch model!\n",
      "TRAINING:\n",
      "Unique students: 2512\n",
      "Unique questions: 1130\n",
      "Total activity: 658050 ( 478904.0 )\n",
      "ov shape (658050, 1130) (1254, 1130)\n",
      "monitoring info loss min\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "psi_select (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hit_counter (InputLayer)        [(None, 1130)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gammas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "alphas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qk_loadings (Dense)             (None, 1)            1130        hit_counter[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 1)            0           gammas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "q_select (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 1)            0           alphas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1)            0           qk_loadings[0][0]                \n",
      "                                                                 flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qn_embedding (Embedding)        (None, 1, 1)         1130        q_select[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1)            0           flatten_23[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 1)            0           qn_embedding[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)           (None, 1)            0           add_7[0][0]                      \n",
      "                                                                 flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           subtract_7[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,284\n",
      "Trainable params: 7,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "fitting\n",
      "Epoch 1/100\n",
      "2057/2057 [==============================] - 13s 5ms/step - loss: 0.5899 - binary_crossentropy: 0.5899 - binary_accuracy: 0.7018 - mean_absolute_error: 0.4171 - mean_squared_error: 0.2019 - f1_loss: 0.4822 - val_loss: 0.6181 - val_binary_crossentropy: 0.6181 - val_binary_accuracy: 0.6507 - val_mean_absolute_error: 0.3978 - val_mean_squared_error: 0.2144 - val_f1_loss: 0.4272\n",
      "Epoch 2/100\n",
      "2057/2057 [==============================] - 11s 5ms/step - loss: 0.4972 - binary_crossentropy: 0.4972 - binary_accuracy: 0.7645 - mean_absolute_error: 0.3450 - mean_squared_error: 0.1627 - f1_loss: 0.4298 - val_loss: 0.5672 - val_binary_crossentropy: 0.5672 - val_binary_accuracy: 0.6970 - val_mean_absolute_error: 0.3738 - val_mean_squared_error: 0.1934 - val_f1_loss: 0.3945\n",
      "Epoch 3/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.4786 - binary_crossentropy: 0.4786 - binary_accuracy: 0.7745 - mean_absolute_error: 0.3271 - mean_squared_error: 0.1560 - f1_loss: 0.4096 - val_loss: 0.5552 - val_binary_crossentropy: 0.5552 - val_binary_accuracy: 0.7169 - val_mean_absolute_error: 0.3599 - val_mean_squared_error: 0.1874 - val_f1_loss: 0.3783\n",
      "Epoch 4/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4710 - binary_crossentropy: 0.4710 - binary_accuracy: 0.7778 - mean_absolute_error: 0.3169 - mean_squared_error: 0.1534 - f1_loss: 0.3991 - val_loss: 0.5367 - val_binary_crossentropy: 0.5367 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3524 - val_mean_squared_error: 0.1801 - val_f1_loss: 0.3669\n",
      "Epoch 5/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.4678 - binary_crossentropy: 0.4678 - binary_accuracy: 0.7794 - mean_absolute_error: 0.3120 - mean_squared_error: 0.1523 - f1_loss: 0.3932 - val_loss: 0.5386 - val_binary_crossentropy: 0.5386 - val_binary_accuracy: 0.7273 - val_mean_absolute_error: 0.3466 - val_mean_squared_error: 0.1803 - val_f1_loss: 0.3618\n",
      "Epoch 6/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.4662 - binary_crossentropy: 0.4662 - binary_accuracy: 0.7797 - mean_absolute_error: 0.3093 - mean_squared_error: 0.1519 - f1_loss: 0.3895 - val_loss: 0.5349 - val_binary_crossentropy: 0.5349 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3454 - val_mean_squared_error: 0.1790 - val_f1_loss: 0.3592\n",
      "Epoch 7/100\n",
      "2057/2057 [==============================] - 12s 5ms/step - loss: 0.4650 - binary_crossentropy: 0.4650 - binary_accuracy: 0.7807 - mean_absolute_error: 0.3072 - mean_squared_error: 0.1514 - f1_loss: 0.3874 - val_loss: 0.5309 - val_binary_crossentropy: 0.5309 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3436 - val_mean_squared_error: 0.1772 - val_f1_loss: 0.3565\n",
      "Epoch 8/100\n",
      "2057/2057 [==============================] - 13s 5ms/step - loss: 0.4642 - binary_crossentropy: 0.4642 - binary_accuracy: 0.7811 - mean_absolute_error: 0.3059 - mean_squared_error: 0.1512 - f1_loss: 0.3854 - val_loss: 0.5335 - val_binary_crossentropy: 0.5335 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3411 - val_mean_squared_error: 0.1781 - val_f1_loss: 0.3548\n",
      "Epoch 9/100\n",
      "2057/2057 [==============================] - 13s 5ms/step - loss: 0.4627 - binary_crossentropy: 0.4627 - binary_accuracy: 0.7819 - mean_absolute_error: 0.3043 - mean_squared_error: 0.1506 - f1_loss: 0.3842 - val_loss: 0.5389 - val_binary_crossentropy: 0.5389 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3397 - val_mean_squared_error: 0.1797 - val_f1_loss: 0.3545\n",
      "Epoch 10/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4626 - binary_crossentropy: 0.4626 - binary_accuracy: 0.7817 - mean_absolute_error: 0.3037 - mean_squared_error: 0.1506 - f1_loss: 0.3838 - val_loss: 0.5338 - val_binary_crossentropy: 0.5338 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3418 - val_mean_squared_error: 0.1782 - val_f1_loss: 0.3545\n",
      "Epoch 11/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4617 - binary_crossentropy: 0.4617 - binary_accuracy: 0.7823 - mean_absolute_error: 0.3030 - mean_squared_error: 0.1503 - f1_loss: 0.3829 - val_loss: 0.5303 - val_binary_crossentropy: 0.5303 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3396 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4619 - binary_crossentropy: 0.4619 - binary_accuracy: 0.7821 - mean_absolute_error: 0.3029 - mean_squared_error: 0.1504 - f1_loss: 0.3828 - val_loss: 0.5259 - val_binary_crossentropy: 0.5259 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3399 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3513\n",
      "Epoch 13/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4615 - binary_crossentropy: 0.4615 - binary_accuracy: 0.7820 - mean_absolute_error: 0.3025 - mean_squared_error: 0.1503 - f1_loss: 0.3816 - val_loss: 0.5376 - val_binary_crossentropy: 0.5376 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3389 - val_mean_squared_error: 0.1790 - val_f1_loss: 0.3527\n",
      "Epoch 14/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4614 - binary_crossentropy: 0.4614 - binary_accuracy: 0.7821 - mean_absolute_error: 0.3022 - mean_squared_error: 0.1502 - f1_loss: 0.3807 - val_loss: 0.5360 - val_binary_crossentropy: 0.5360 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3384 - val_mean_squared_error: 0.1781 - val_f1_loss: 0.3518\n",
      "Epoch 15/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4614 - binary_crossentropy: 0.4614 - binary_accuracy: 0.7820 - mean_absolute_error: 0.3020 - mean_squared_error: 0.1503 - f1_loss: 0.3807 - val_loss: 0.5333 - val_binary_crossentropy: 0.5333 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3393 - val_mean_squared_error: 0.1772 - val_f1_loss: 0.3518\n",
      "Epoch 16/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4616 - binary_crossentropy: 0.4616 - binary_accuracy: 0.7822 - mean_absolute_error: 0.3019 - mean_squared_error: 0.1503 - f1_loss: 0.3809 - val_loss: 0.5390 - val_binary_crossentropy: 0.5390 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3373 - val_mean_squared_error: 0.1791 - val_f1_loss: 0.3516\n",
      "Epoch 17/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4613 - binary_crossentropy: 0.4613 - binary_accuracy: 0.7826 - mean_absolute_error: 0.3013 - mean_squared_error: 0.1501 - f1_loss: 0.3804 - val_loss: 0.5282 - val_binary_crossentropy: 0.5282 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3382 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3499\n",
      "Epoch 18/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4607 - binary_crossentropy: 0.4607 - binary_accuracy: 0.7823 - mean_absolute_error: 0.3011 - mean_squared_error: 0.1499 - f1_loss: 0.3800 - val_loss: 0.5377 - val_binary_crossentropy: 0.5377 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.1783 - val_f1_loss: 0.3509\n",
      "Epoch 19/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4608 - binary_crossentropy: 0.4608 - binary_accuracy: 0.7829 - mean_absolute_error: 0.3008 - mean_squared_error: 0.1500 - f1_loss: 0.3799 - val_loss: 0.5332 - val_binary_crossentropy: 0.5332 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3370 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3499\n",
      "Epoch 20/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4603 - binary_crossentropy: 0.4603 - binary_accuracy: 0.7827 - mean_absolute_error: 0.3006 - mean_squared_error: 0.1498 - f1_loss: 0.3794 - val_loss: 0.5358 - val_binary_crossentropy: 0.5358 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3374 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3505\n",
      "Epoch 21/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7832 - mean_absolute_error: 0.3000 - mean_squared_error: 0.1495 - f1_loss: 0.3794 - val_loss: 0.5320 - val_binary_crossentropy: 0.5320 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3380 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3501\n",
      "Epoch 22/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4597 - binary_crossentropy: 0.4597 - binary_accuracy: 0.7831 - mean_absolute_error: 0.3000 - mean_squared_error: 0.1495 - f1_loss: 0.3787 - val_loss: 0.5385 - val_binary_crossentropy: 0.5385 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.1782 - val_f1_loss: 0.3505\n",
      "Epoch 23/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4597 - binary_crossentropy: 0.4597 - binary_accuracy: 0.7830 - mean_absolute_error: 0.3001 - mean_squared_error: 0.1497 - f1_loss: 0.3790 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3362 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3496\n",
      "Epoch 24/100\n",
      "2057/2057 [==============================] - 8s 4ms/step - loss: 0.4601 - binary_crossentropy: 0.4601 - binary_accuracy: 0.7826 - mean_absolute_error: 0.3000 - mean_squared_error: 0.1497 - f1_loss: 0.3781 - val_loss: 0.5378 - val_binary_crossentropy: 0.5378 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3367 - val_mean_squared_error: 0.1779 - val_f1_loss: 0.3500\n",
      "Epoch 25/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4592 - binary_crossentropy: 0.4592 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2995 - mean_squared_error: 0.1494 - f1_loss: 0.3784 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3360 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3489\n",
      "Epoch 26/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4598 - binary_crossentropy: 0.4598 - binary_accuracy: 0.7825 - mean_absolute_error: 0.3000 - mean_squared_error: 0.1497 - f1_loss: 0.3783 - val_loss: 0.5369 - val_binary_crossentropy: 0.5369 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3369 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3499\n",
      "Epoch 27/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4591 - binary_crossentropy: 0.4591 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2990 - mean_squared_error: 0.1492 - f1_loss: 0.3782 - val_loss: 0.5381 - val_binary_crossentropy: 0.5381 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1781 - val_f1_loss: 0.3491\n",
      "Epoch 28/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7834 - mean_absolute_error: 0.2992 - mean_squared_error: 0.1494 - f1_loss: 0.3778 - val_loss: 0.5335 - val_binary_crossentropy: 0.5335 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3355 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3484\n",
      "Epoch 29/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2983 - mean_squared_error: 0.1489 - f1_loss: 0.3771 - val_loss: 0.5366 - val_binary_crossentropy: 0.5366 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.1773 - val_f1_loss: 0.3495\n",
      "Epoch 30/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4592 - binary_crossentropy: 0.4592 - binary_accuracy: 0.7837 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1493 - f1_loss: 0.3776 - val_loss: 0.5361 - val_binary_crossentropy: 0.5361 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3352 - val_mean_squared_error: 0.1768 - val_f1_loss: 0.3485\n",
      "Epoch 31/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4580 - binary_crossentropy: 0.4580 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2984 - mean_squared_error: 0.1490 - f1_loss: 0.3773 - val_loss: 0.5380 - val_binary_crossentropy: 0.5380 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3485\n",
      "Epoch 32/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4595 - binary_crossentropy: 0.4595 - binary_accuracy: 0.7834 - mean_absolute_error: 0.2992 - mean_squared_error: 0.1495 - f1_loss: 0.3775 - val_loss: 0.5363 - val_binary_crossentropy: 0.5363 - val_binary_accuracy: 0.7281 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.1772 - val_f1_loss: 0.3484\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4591 - binary_crossentropy: 0.4591 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2984 - mean_squared_error: 0.1493 - f1_loss: 0.3773 - val_loss: 0.5304 - val_binary_crossentropy: 0.5304 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3358 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3478\n",
      "Epoch 34/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2980 - mean_squared_error: 0.1487 - f1_loss: 0.3766 - val_loss: 0.5281 - val_binary_crossentropy: 0.5281 - val_binary_accuracy: 0.7408 - val_mean_absolute_error: 0.3373 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3484\n",
      "Epoch 35/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2983 - mean_squared_error: 0.1489 - f1_loss: 0.3764 - val_loss: 0.5326 - val_binary_crossentropy: 0.5326 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3479\n",
      "Epoch 36/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4577 - binary_crossentropy: 0.4577 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2980 - mean_squared_error: 0.1488 - f1_loss: 0.3762 - val_loss: 0.5309 - val_binary_crossentropy: 0.5309 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3472\n",
      "Epoch 37/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2978 - mean_squared_error: 0.1488 - f1_loss: 0.3765 - val_loss: 0.5405 - val_binary_crossentropy: 0.5405 - val_binary_accuracy: 0.7273 - val_mean_absolute_error: 0.3336 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3478\n",
      "Epoch 38/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2977 - mean_squared_error: 0.1486 - f1_loss: 0.3766 - val_loss: 0.5288 - val_binary_crossentropy: 0.5288 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1745 - val_f1_loss: 0.3467\n",
      "Epoch 39/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4585 - binary_crossentropy: 0.4585 - binary_accuracy: 0.7835 - mean_absolute_error: 0.2986 - mean_squared_error: 0.1492 - f1_loss: 0.3764 - val_loss: 0.5383 - val_binary_crossentropy: 0.5383 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3477\n",
      "Epoch 40/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2973 - mean_squared_error: 0.1486 - f1_loss: 0.3760 - val_loss: 0.5318 - val_binary_crossentropy: 0.5318 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3472\n",
      "Epoch 41/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4577 - binary_crossentropy: 0.4577 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2978 - mean_squared_error: 0.1489 - f1_loss: 0.3767 - val_loss: 0.5313 - val_binary_crossentropy: 0.5313 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1751 - val_f1_loss: 0.3460\n",
      "Epoch 42/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2972 - mean_squared_error: 0.1486 - f1_loss: 0.3757 - val_loss: 0.5302 - val_binary_crossentropy: 0.5302 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3472\n",
      "Epoch 43/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1487 - f1_loss: 0.3762 - val_loss: 0.5311 - val_binary_crossentropy: 0.5311 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3374 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3487\n",
      "Epoch 44/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4579 - binary_crossentropy: 0.4579 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2979 - mean_squared_error: 0.1489 - f1_loss: 0.3763 - val_loss: 0.5388 - val_binary_crossentropy: 0.5388 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1773 - val_f1_loss: 0.3477\n",
      "Epoch 45/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4580 - binary_crossentropy: 0.4580 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2977 - mean_squared_error: 0.1489 - f1_loss: 0.3757 - val_loss: 0.5367 - val_binary_crossentropy: 0.5367 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1767 - val_f1_loss: 0.3468\n",
      "Epoch 46/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1483 - f1_loss: 0.3748 - val_loss: 0.5272 - val_binary_crossentropy: 0.5272 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1739 - val_f1_loss: 0.3464\n",
      "Epoch 47/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1486 - f1_loss: 0.3756 - val_loss: 0.5412 - val_binary_crossentropy: 0.5412 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1780 - val_f1_loss: 0.3475\n",
      "Epoch 48/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2976 - mean_squared_error: 0.1489 - f1_loss: 0.3758 - val_loss: 0.5401 - val_binary_crossentropy: 0.5401 - val_binary_accuracy: 0.7265 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3475\n",
      "Epoch 49/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7860 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1482 - f1_loss: 0.3751 - val_loss: 0.5332 - val_binary_crossentropy: 0.5332 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3336 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3465\n",
      "Epoch 50/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4570 - binary_crossentropy: 0.4570 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1486 - f1_loss: 0.3754 - val_loss: 0.5268 - val_binary_crossentropy: 0.5268 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.1738 - val_f1_loss: 0.3468\n",
      "Epoch 51/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1488 - f1_loss: 0.3753 - val_loss: 0.5388 - val_binary_crossentropy: 0.5388 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3467\n",
      "Epoch 52/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1485 - f1_loss: 0.3754 - val_loss: 0.5375 - val_binary_crossentropy: 0.5375 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3475\n",
      "Epoch 53/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1486 - f1_loss: 0.3752 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3467\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4557 - binary_crossentropy: 0.4557 - binary_accuracy: 0.7856 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1481 - f1_loss: 0.3745 - val_loss: 0.5375 - val_binary_crossentropy: 0.5375 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3462\n",
      "Epoch 55/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7855 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1483 - f1_loss: 0.3750 - val_loss: 0.5315 - val_binary_crossentropy: 0.5315 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3463\n",
      "Epoch 56/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1483 - f1_loss: 0.3750 - val_loss: 0.5306 - val_binary_crossentropy: 0.5306 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3458\n",
      "Epoch 57/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2970 - mean_squared_error: 0.1488 - f1_loss: 0.3751 - val_loss: 0.5368 - val_binary_crossentropy: 0.5368 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3326 - val_mean_squared_error: 0.1768 - val_f1_loss: 0.3463\n",
      "Epoch 58/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1486 - f1_loss: 0.3751 - val_loss: 0.5292 - val_binary_crossentropy: 0.5292 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.1742 - val_f1_loss: 0.3464\n",
      "Epoch 59/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1489 - f1_loss: 0.3754 - val_loss: 0.5325 - val_binary_crossentropy: 0.5325 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3465\n",
      "Epoch 60/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1484 - f1_loss: 0.3747 - val_loss: 0.5333 - val_binary_crossentropy: 0.5333 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3462\n",
      "Epoch 61/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1488 - f1_loss: 0.3753 - val_loss: 0.5327 - val_binary_crossentropy: 0.5327 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3465\n",
      "Epoch 62/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4554 - binary_crossentropy: 0.4554 - binary_accuracy: 0.7860 - mean_absolute_error: 0.2957 - mean_squared_error: 0.1480 - f1_loss: 0.3748 - val_loss: 0.5302 - val_binary_crossentropy: 0.5302 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1746 - val_f1_loss: 0.3462\n",
      "Epoch 63/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1485 - f1_loss: 0.3750 - val_loss: 0.5334 - val_binary_crossentropy: 0.5334 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3464\n",
      "Epoch 64/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1483 - f1_loss: 0.3745 - val_loss: 0.5345 - val_binary_crossentropy: 0.5345 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3474\n",
      "Epoch 65/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4559 - binary_crossentropy: 0.4559 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1483 - f1_loss: 0.3747 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.1760 - val_f1_loss: 0.3455\n",
      "Epoch 66/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4558 - binary_crossentropy: 0.4558 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1483 - f1_loss: 0.3749 - val_loss: 0.5333 - val_binary_crossentropy: 0.5333 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3322 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3454\n",
      "Epoch 67/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1485 - f1_loss: 0.3752 - val_loss: 0.5433 - val_binary_crossentropy: 0.5433 - val_binary_accuracy: 0.7265 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.1787 - val_f1_loss: 0.3466\n",
      "Epoch 68/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4554 - binary_crossentropy: 0.4554 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1481 - f1_loss: 0.3740 - val_loss: 0.5348 - val_binary_crossentropy: 0.5348 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3322 - val_mean_squared_error: 0.1760 - val_f1_loss: 0.3455\n",
      "Epoch 69/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1484 - f1_loss: 0.3749 - val_loss: 0.5328 - val_binary_crossentropy: 0.5328 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3462\n",
      "Epoch 70/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1488 - f1_loss: 0.3748 - val_loss: 0.5288 - val_binary_crossentropy: 0.5288 - val_binary_accuracy: 0.7408 - val_mean_absolute_error: 0.3362 - val_mean_squared_error: 0.1745 - val_f1_loss: 0.3472\n",
      "Epoch 71/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1484 - f1_loss: 0.3748 - val_loss: 0.5279 - val_binary_crossentropy: 0.5279 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1743 - val_f1_loss: 0.3459\n",
      "Epoch 72/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1483 - f1_loss: 0.3743 - val_loss: 0.5337 - val_binary_crossentropy: 0.5337 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3458\n",
      "Epoch 73/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1488 - f1_loss: 0.3751 - val_loss: 0.5282 - val_binary_crossentropy: 0.5282 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1743 - val_f1_loss: 0.3459\n",
      "Epoch 74/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1486 - f1_loss: 0.3747 - val_loss: 0.5361 - val_binary_crossentropy: 0.5361 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3461\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4559 - binary_crossentropy: 0.4559 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2957 - mean_squared_error: 0.1482 - f1_loss: 0.3743 - val_loss: 0.5297 - val_binary_crossentropy: 0.5297 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3463\n",
      "Epoch 76/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4554 - binary_crossentropy: 0.4554 - binary_accuracy: 0.7863 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1480 - f1_loss: 0.3748 - val_loss: 0.5408 - val_binary_crossentropy: 0.5408 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3318 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3459\n",
      "Epoch 77/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4551 - binary_crossentropy: 0.4551 - binary_accuracy: 0.7861 - mean_absolute_error: 0.2955 - mean_squared_error: 0.1479 - f1_loss: 0.3740 - val_loss: 0.5343 - val_binary_crossentropy: 0.5343 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3322 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3453\n",
      "Epoch 78/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1487 - f1_loss: 0.3748 - val_loss: 0.5322 - val_binary_crossentropy: 0.5322 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3325 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3454\n",
      "Epoch 79/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4571 - binary_crossentropy: 0.4571 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1487 - f1_loss: 0.3746 - val_loss: 0.5315 - val_binary_crossentropy: 0.5315 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3462\n",
      "Epoch 80/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1485 - f1_loss: 0.3742 - val_loss: 0.5428 - val_binary_crossentropy: 0.5428 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.1783 - val_f1_loss: 0.3463\n",
      "Epoch 81/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1483 - f1_loss: 0.3739 - val_loss: 0.5284 - val_binary_crossentropy: 0.5284 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1744 - val_f1_loss: 0.3453\n",
      "Epoch 82/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4576 - binary_crossentropy: 0.4576 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1489 - f1_loss: 0.3747 - val_loss: 0.5334 - val_binary_crossentropy: 0.5334 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3458\n",
      "Epoch 83/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1484 - f1_loss: 0.3742 - val_loss: 0.5337 - val_binary_crossentropy: 0.5337 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3460\n",
      "Epoch 84/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1484 - f1_loss: 0.3746 - val_loss: 0.5396 - val_binary_crossentropy: 0.5396 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3454\n",
      "Epoch 85/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3741 - val_loss: 0.5403 - val_binary_crossentropy: 0.5403 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1776 - val_f1_loss: 0.3464\n",
      "Epoch 86/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3742 - val_loss: 0.5366 - val_binary_crossentropy: 0.5366 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3463\n",
      "Epoch 87/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4558 - binary_crossentropy: 0.4558 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1482 - f1_loss: 0.3740 - val_loss: 0.5356 - val_binary_crossentropy: 0.5356 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3325 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3456\n",
      "Epoch 88/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1485 - f1_loss: 0.3746 - val_loss: 0.5399 - val_binary_crossentropy: 0.5399 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3326 - val_mean_squared_error: 0.1776 - val_f1_loss: 0.3462\n",
      "Epoch 89/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4558 - binary_crossentropy: 0.4558 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1482 - f1_loss: 0.3738 - val_loss: 0.5347 - val_binary_crossentropy: 0.5347 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1760 - val_f1_loss: 0.3461\n",
      "Epoch 90/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1484 - f1_loss: 0.3743 - val_loss: 0.5388 - val_binary_crossentropy: 0.5388 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3463\n",
      "Epoch 91/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1483 - f1_loss: 0.3743 - val_loss: 0.5319 - val_binary_crossentropy: 0.5319 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1751 - val_f1_loss: 0.3456\n",
      "Epoch 92/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1482 - f1_loss: 0.3740 - val_loss: 0.5371 - val_binary_crossentropy: 0.5371 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.1767 - val_f1_loss: 0.3458\n",
      "Epoch 93/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4555 - binary_crossentropy: 0.4555 - binary_accuracy: 0.7855 - mean_absolute_error: 0.2957 - mean_squared_error: 0.1482 - f1_loss: 0.3742 - val_loss: 0.5338 - val_binary_crossentropy: 0.5338 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3464\n",
      "Epoch 94/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1484 - f1_loss: 0.3746 - val_loss: 0.5407 - val_binary_crossentropy: 0.5407 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3469\n",
      "Epoch 95/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1484 - f1_loss: 0.3742 - val_loss: 0.5365 - val_binary_crossentropy: 0.5365 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3318 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3451\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1485 - f1_loss: 0.3746 - val_loss: 0.5334 - val_binary_crossentropy: 0.5334 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3463\n",
      "Epoch 97/100\n",
      "2057/2057 [==============================] - 8s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1485 - f1_loss: 0.3742 - val_loss: 0.5382 - val_binary_crossentropy: 0.5382 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3456\n",
      "Epoch 98/100\n",
      "2057/2057 [==============================] - 8s 4ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3741 - val_loss: 0.5354 - val_binary_crossentropy: 0.5354 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3461\n",
      "Epoch 99/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4551 - binary_crossentropy: 0.4551 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2952 - mean_squared_error: 0.1480 - f1_loss: 0.3743 - val_loss: 0.5354 - val_binary_crossentropy: 0.5354 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3459\n",
      "Epoch 100/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4548 - binary_crossentropy: 0.4548 - binary_accuracy: 0.7855 - mean_absolute_error: 0.2955 - mean_squared_error: 0.1480 - f1_loss: 0.3737 - val_loss: 0.5411 - val_binary_crossentropy: 0.5411 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3318 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3455\n",
      "fertig RASCH 1 binary_crossentropy loss\n",
      "None :F1s v/t  0.6872074631271334 0.7145971485243199 0.7225628465601508\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d57a262e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7225628465601508\n",
      "GO FOR RASCH1//(xe/px)#1000000\n",
      "checking for cached file ./lfa_models/RASCH1~~(xe~px)#1000000_1\n",
      "./lfa_models/RASCH1~~(xe~px)#1000000_1 found\n",
      "class weights: [2.67326092 1.        ]\n",
      "class weights (dict): {0: 2.6732609156777154, 1: 1.0}\n",
      "nq, ns\n",
      "1130 2512\n",
      "Using univariate Rasch model!\n",
      "TRAINING:\n",
      "Unique students: 2512\n",
      "Unique questions: 1130\n",
      "Total activity: 658050 ( 478904.0 )\n",
      "ov shape (658050, 1130) (1254, 1130)\n",
      "monitoring info loss min\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "psi_select (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hit_counter (InputLayer)        [(None, 1130)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gammas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "alphas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qk_loadings (Dense)             (None, 1)            1130        hit_counter[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 1)            0           gammas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "q_select (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 1)            0           alphas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 1)            0           qk_loadings[0][0]                \n",
      "                                                                 flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qn_embedding (Embedding)        (None, 1, 1)         1130        q_select[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1)            0           flatten_26[0][0]                 \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 1)            0           qn_embedding[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)           (None, 1)            0           add_8[0][0]                      \n",
      "                                                                 flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           subtract_8[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,284\n",
      "Trainable params: 7,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "fitting\n",
      "Epoch 1/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.5876 - binary_crossentropy: 0.5876 - binary_accuracy: 0.7029 - mean_absolute_error: 0.4148 - mean_squared_error: 0.2008 - f1_loss: 0.4808 - val_loss: 0.6082 - val_binary_crossentropy: 0.6082 - val_binary_accuracy: 0.6587 - val_mean_absolute_error: 0.3997 - val_mean_squared_error: 0.2111 - val_f1_loss: 0.4266\n",
      "Epoch 2/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4968 - binary_crossentropy: 0.4968 - binary_accuracy: 0.7645 - mean_absolute_error: 0.3450 - mean_squared_error: 0.1625 - f1_loss: 0.4290 - val_loss: 0.5690 - val_binary_crossentropy: 0.5690 - val_binary_accuracy: 0.6978 - val_mean_absolute_error: 0.3747 - val_mean_squared_error: 0.1939 - val_f1_loss: 0.3957\n",
      "Epoch 3/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4780 - binary_crossentropy: 0.4780 - binary_accuracy: 0.7750 - mean_absolute_error: 0.3263 - mean_squared_error: 0.1557 - f1_loss: 0.4092 - val_loss: 0.5532 - val_binary_crossentropy: 0.5532 - val_binary_accuracy: 0.7145 - val_mean_absolute_error: 0.3605 - val_mean_squared_error: 0.1868 - val_f1_loss: 0.3785\n",
      "Epoch 4/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4706 - binary_crossentropy: 0.4706 - binary_accuracy: 0.7780 - mean_absolute_error: 0.3169 - mean_squared_error: 0.1533 - f1_loss: 0.3986 - val_loss: 0.5432 - val_binary_crossentropy: 0.5432 - val_binary_accuracy: 0.7225 - val_mean_absolute_error: 0.3543 - val_mean_squared_error: 0.1828 - val_f1_loss: 0.3695\n",
      "Epoch 5/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4676 - binary_crossentropy: 0.4676 - binary_accuracy: 0.7796 - mean_absolute_error: 0.3122 - mean_squared_error: 0.1522 - f1_loss: 0.3929 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7265 - val_mean_absolute_error: 0.3487 - val_mean_squared_error: 0.1797 - val_f1_loss: 0.3628\n",
      "Epoch 6/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4656 - binary_crossentropy: 0.4656 - binary_accuracy: 0.7802 - mean_absolute_error: 0.3090 - mean_squared_error: 0.1516 - f1_loss: 0.3890 - val_loss: 0.5387 - val_binary_crossentropy: 0.5387 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3466 - val_mean_squared_error: 0.1804 - val_f1_loss: 0.3605\n",
      "Epoch 7/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4652 - binary_crossentropy: 0.4652 - binary_accuracy: 0.7805 - mean_absolute_error: 0.3073 - mean_squared_error: 0.1515 - f1_loss: 0.3874 - val_loss: 0.5326 - val_binary_crossentropy: 0.5326 - val_binary_accuracy: 0.7408 - val_mean_absolute_error: 0.3433 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3564\n",
      "Epoch 8/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4637 - binary_crossentropy: 0.4637 - binary_accuracy: 0.7815 - mean_absolute_error: 0.3055 - mean_squared_error: 0.1509 - f1_loss: 0.3859 - val_loss: 0.5301 - val_binary_crossentropy: 0.5301 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3427 - val_mean_squared_error: 0.1767 - val_f1_loss: 0.3551\n",
      "Epoch 9/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4630 - binary_crossentropy: 0.4630 - binary_accuracy: 0.7817 - mean_absolute_error: 0.3045 - mean_squared_error: 0.1507 - f1_loss: 0.3844 - val_loss: 0.5370 - val_binary_crossentropy: 0.5370 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3411 - val_mean_squared_error: 0.1793 - val_f1_loss: 0.3552\n",
      "Epoch 10/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4627 - binary_crossentropy: 0.4627 - binary_accuracy: 0.7821 - mean_absolute_error: 0.3038 - mean_squared_error: 0.1507 - f1_loss: 0.3835 - val_loss: 0.5315 - val_binary_crossentropy: 0.5315 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3399 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3528\n",
      "Epoch 11/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4610 - binary_crossentropy: 0.4610 - binary_accuracy: 0.7822 - mean_absolute_error: 0.3026 - mean_squared_error: 0.1501 - f1_loss: 0.3823 - val_loss: 0.5275 - val_binary_crossentropy: 0.5275 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3400 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4616 - binary_crossentropy: 0.4616 - binary_accuracy: 0.7823 - mean_absolute_error: 0.3027 - mean_squared_error: 0.1503 - f1_loss: 0.3822 - val_loss: 0.5300 - val_binary_crossentropy: 0.5300 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3402 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3522\n",
      "Epoch 13/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4627 - binary_crossentropy: 0.4627 - binary_accuracy: 0.7814 - mean_absolute_error: 0.3032 - mean_squared_error: 0.1507 - f1_loss: 0.3822 - val_loss: 0.5317 - val_binary_crossentropy: 0.5317 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3383 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3512\n",
      "Epoch 14/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4611 - binary_crossentropy: 0.4611 - binary_accuracy: 0.7828 - mean_absolute_error: 0.3017 - mean_squared_error: 0.1500 - f1_loss: 0.3815 - val_loss: 0.5282 - val_binary_crossentropy: 0.5282 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3407 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3518\n",
      "Epoch 15/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4607 - binary_crossentropy: 0.4607 - binary_accuracy: 0.7830 - mean_absolute_error: 0.3017 - mean_squared_error: 0.1498 - f1_loss: 0.3805 - val_loss: 0.5375 - val_binary_crossentropy: 0.5375 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3374 - val_mean_squared_error: 0.1786 - val_f1_loss: 0.3516\n",
      "Epoch 16/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4612 - binary_crossentropy: 0.4612 - binary_accuracy: 0.7825 - mean_absolute_error: 0.3014 - mean_squared_error: 0.1501 - f1_loss: 0.3806 - val_loss: 0.5293 - val_binary_crossentropy: 0.5293 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3383 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3503\n",
      "Epoch 17/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4605 - binary_crossentropy: 0.4605 - binary_accuracy: 0.7828 - mean_absolute_error: 0.3009 - mean_squared_error: 0.1498 - f1_loss: 0.3804 - val_loss: 0.5434 - val_binary_crossentropy: 0.5434 - val_binary_accuracy: 0.7209 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.1806 - val_f1_loss: 0.3519\n",
      "Epoch 18/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4585 - binary_crossentropy: 0.4585 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2997 - mean_squared_error: 0.1492 - f1_loss: 0.3796 - val_loss: 0.5291 - val_binary_crossentropy: 0.5291 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3384 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3501\n",
      "Epoch 19/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4615 - binary_crossentropy: 0.4615 - binary_accuracy: 0.7825 - mean_absolute_error: 0.3014 - mean_squared_error: 0.1502 - f1_loss: 0.3800 - val_loss: 0.5412 - val_binary_crossentropy: 0.5412 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3360 - val_mean_squared_error: 0.1797 - val_f1_loss: 0.3507\n",
      "Epoch 20/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4601 - binary_crossentropy: 0.4601 - binary_accuracy: 0.7834 - mean_absolute_error: 0.3004 - mean_squared_error: 0.1497 - f1_loss: 0.3795 - val_loss: 0.5359 - val_binary_crossentropy: 0.5359 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3360 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3496\n",
      "Epoch 21/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4601 - binary_crossentropy: 0.4601 - binary_accuracy: 0.7833 - mean_absolute_error: 0.3004 - mean_squared_error: 0.1497 - f1_loss: 0.3796 - val_loss: 0.5351 - val_binary_crossentropy: 0.5351 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3363 - val_mean_squared_error: 0.1773 - val_f1_loss: 0.3496\n",
      "Epoch 22/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7833 - mean_absolute_error: 0.3000 - mean_squared_error: 0.1495 - f1_loss: 0.3789 - val_loss: 0.5330 - val_binary_crossentropy: 0.5330 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3376 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3498\n",
      "Epoch 23/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4585 - binary_crossentropy: 0.4585 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1491 - f1_loss: 0.3785 - val_loss: 0.5284 - val_binary_crossentropy: 0.5284 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3380 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3495\n",
      "Epoch 24/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4595 - binary_crossentropy: 0.4595 - binary_accuracy: 0.7833 - mean_absolute_error: 0.2999 - mean_squared_error: 0.1495 - f1_loss: 0.3787 - val_loss: 0.5399 - val_binary_crossentropy: 0.5399 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3355 - val_mean_squared_error: 0.1788 - val_f1_loss: 0.3498\n",
      "Epoch 25/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4596 - binary_crossentropy: 0.4596 - binary_accuracy: 0.7832 - mean_absolute_error: 0.2997 - mean_squared_error: 0.1496 - f1_loss: 0.3787 - val_loss: 0.5341 - val_binary_crossentropy: 0.5341 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3375 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3498\n",
      "Epoch 26/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4592 - binary_crossentropy: 0.4592 - binary_accuracy: 0.7834 - mean_absolute_error: 0.2996 - mean_squared_error: 0.1494 - f1_loss: 0.3785 - val_loss: 0.5368 - val_binary_crossentropy: 0.5368 - val_binary_accuracy: 0.7281 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.1781 - val_f1_loss: 0.3493\n",
      "Epoch 27/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4582 - binary_crossentropy: 0.4582 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2989 - mean_squared_error: 0.1490 - f1_loss: 0.3776 - val_loss: 0.5317 - val_binary_crossentropy: 0.5317 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3480\n",
      "Epoch 28/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2980 - mean_squared_error: 0.1485 - f1_loss: 0.3769 - val_loss: 0.5431 - val_binary_crossentropy: 0.5431 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.1794 - val_f1_loss: 0.3502\n",
      "Epoch 29/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4581 - binary_crossentropy: 0.4581 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2985 - mean_squared_error: 0.1490 - f1_loss: 0.3778 - val_loss: 0.5310 - val_binary_crossentropy: 0.5310 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3485\n",
      "Epoch 30/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4593 - binary_crossentropy: 0.4593 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1494 - f1_loss: 0.3778 - val_loss: 0.5267 - val_binary_crossentropy: 0.5267 - val_binary_accuracy: 0.7448 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.1741 - val_f1_loss: 0.3476\n",
      "Epoch 31/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4593 - binary_crossentropy: 0.4593 - binary_accuracy: 0.7835 - mean_absolute_error: 0.2993 - mean_squared_error: 0.1494 - f1_loss: 0.3780 - val_loss: 0.5292 - val_binary_crossentropy: 0.5292 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3479\n",
      "Epoch 32/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1494 - f1_loss: 0.3772 - val_loss: 0.5313 - val_binary_crossentropy: 0.5313 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3478\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4582 - binary_crossentropy: 0.4582 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2983 - mean_squared_error: 0.1490 - f1_loss: 0.3771 - val_loss: 0.5337 - val_binary_crossentropy: 0.5337 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3476\n",
      "Epoch 34/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4586 - binary_crossentropy: 0.4586 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2988 - mean_squared_error: 0.1492 - f1_loss: 0.3769 - val_loss: 0.5347 - val_binary_crossentropy: 0.5347 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3479\n",
      "Epoch 35/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2978 - mean_squared_error: 0.1487 - f1_loss: 0.3763 - val_loss: 0.5333 - val_binary_crossentropy: 0.5333 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3476\n",
      "Epoch 36/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4585 - binary_crossentropy: 0.4585 - binary_accuracy: 0.7835 - mean_absolute_error: 0.2984 - mean_squared_error: 0.1492 - f1_loss: 0.3772 - val_loss: 0.5315 - val_binary_crossentropy: 0.5315 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3360 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3481\n",
      "Epoch 37/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2979 - mean_squared_error: 0.1489 - f1_loss: 0.3767 - val_loss: 0.5291 - val_binary_crossentropy: 0.5291 - val_binary_accuracy: 0.7416 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1745 - val_f1_loss: 0.3470\n",
      "Epoch 38/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4581 - binary_crossentropy: 0.4581 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2980 - mean_squared_error: 0.1489 - f1_loss: 0.3768 - val_loss: 0.5390 - val_binary_crossentropy: 0.5390 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1776 - val_f1_loss: 0.3482\n",
      "Epoch 39/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2976 - mean_squared_error: 0.1487 - f1_loss: 0.3760 - val_loss: 0.5394 - val_binary_crossentropy: 0.5394 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3479\n",
      "Epoch 40/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4577 - binary_crossentropy: 0.4577 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2977 - mean_squared_error: 0.1489 - f1_loss: 0.3761 - val_loss: 0.5292 - val_binary_crossentropy: 0.5292 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3470\n",
      "Epoch 41/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1487 - f1_loss: 0.3757 - val_loss: 0.5322 - val_binary_crossentropy: 0.5322 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3350 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3475\n",
      "Epoch 42/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2977 - mean_squared_error: 0.1488 - f1_loss: 0.3762 - val_loss: 0.5318 - val_binary_crossentropy: 0.5318 - val_binary_accuracy: 0.7273 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3469\n",
      "Epoch 43/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1485 - f1_loss: 0.3762 - val_loss: 0.5320 - val_binary_crossentropy: 0.5320 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3464\n",
      "Epoch 44/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2973 - mean_squared_error: 0.1487 - f1_loss: 0.3757 - val_loss: 0.5339 - val_binary_crossentropy: 0.5339 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1760 - val_f1_loss: 0.3469\n",
      "Epoch 45/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4582 - binary_crossentropy: 0.4582 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2979 - mean_squared_error: 0.1490 - f1_loss: 0.3766 - val_loss: 0.5280 - val_binary_crossentropy: 0.5280 - val_binary_accuracy: 0.7464 - val_mean_absolute_error: 0.3362 - val_mean_squared_error: 0.1742 - val_f1_loss: 0.3471\n",
      "Epoch 46/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2972 - mean_squared_error: 0.1486 - f1_loss: 0.3761 - val_loss: 0.5328 - val_binary_crossentropy: 0.5328 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3462\n",
      "Epoch 47/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2972 - mean_squared_error: 0.1487 - f1_loss: 0.3758 - val_loss: 0.5337 - val_binary_crossentropy: 0.5337 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3468\n",
      "Epoch 48/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1483 - f1_loss: 0.3753 - val_loss: 0.5352 - val_binary_crossentropy: 0.5352 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1763 - val_f1_loss: 0.3464\n",
      "Epoch 49/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1488 - f1_loss: 0.3756 - val_loss: 0.5343 - val_binary_crossentropy: 0.5343 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3323 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3460\n",
      "Epoch 50/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1484 - f1_loss: 0.3753 - val_loss: 0.5285 - val_binary_crossentropy: 0.5285 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.1742 - val_f1_loss: 0.3462\n",
      "Epoch 51/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4580 - binary_crossentropy: 0.4580 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2975 - mean_squared_error: 0.1490 - f1_loss: 0.3761 - val_loss: 0.5322 - val_binary_crossentropy: 0.5322 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3463\n",
      "Epoch 52/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7860 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1480 - f1_loss: 0.3754 - val_loss: 0.5333 - val_binary_crossentropy: 0.5333 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3464\n",
      "Epoch 53/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2970 - mean_squared_error: 0.1487 - f1_loss: 0.3752 - val_loss: 0.5305 - val_binary_crossentropy: 0.5305 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3463\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1488 - f1_loss: 0.3757 - val_loss: 0.5329 - val_binary_crossentropy: 0.5329 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3464\n",
      "Epoch 55/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1483 - f1_loss: 0.3749 - val_loss: 0.5296 - val_binary_crossentropy: 0.5296 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3462\n",
      "Epoch 56/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4551 - binary_crossentropy: 0.4551 - binary_accuracy: 0.7859 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1479 - f1_loss: 0.3743 - val_loss: 0.5310 - val_binary_crossentropy: 0.5310 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1748 - val_f1_loss: 0.3462\n",
      "Epoch 57/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4570 - binary_crossentropy: 0.4570 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1487 - f1_loss: 0.3751 - val_loss: 0.5308 - val_binary_crossentropy: 0.5308 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3326 - val_mean_squared_error: 0.1751 - val_f1_loss: 0.3456\n",
      "Epoch 58/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1486 - f1_loss: 0.3753 - val_loss: 0.5432 - val_binary_crossentropy: 0.5432 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1787 - val_f1_loss: 0.3484\n",
      "Epoch 59/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1485 - f1_loss: 0.3751 - val_loss: 0.5386 - val_binary_crossentropy: 0.5386 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3468\n",
      "Epoch 60/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4558 - binary_crossentropy: 0.4558 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1481 - f1_loss: 0.3746 - val_loss: 0.5295 - val_binary_crossentropy: 0.5295 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1746 - val_f1_loss: 0.3461\n",
      "Epoch 61/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1485 - f1_loss: 0.3748 - val_loss: 0.5399 - val_binary_crossentropy: 0.5399 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3470\n",
      "Epoch 62/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4559 - binary_crossentropy: 0.4559 - binary_accuracy: 0.7859 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1482 - f1_loss: 0.3749 - val_loss: 0.5311 - val_binary_crossentropy: 0.5311 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3455\n",
      "Epoch 63/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1487 - f1_loss: 0.3752 - val_loss: 0.5281 - val_binary_crossentropy: 0.5281 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1744 - val_f1_loss: 0.3461\n",
      "Epoch 64/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1484 - f1_loss: 0.3751 - val_loss: 0.5415 - val_binary_crossentropy: 0.5415 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3325 - val_mean_squared_error: 0.1780 - val_f1_loss: 0.3467\n",
      "Epoch 65/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3742 - val_loss: 0.5346 - val_binary_crossentropy: 0.5346 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3464\n",
      "Epoch 66/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1484 - f1_loss: 0.3744 - val_loss: 0.5324 - val_binary_crossentropy: 0.5324 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3466\n",
      "Epoch 67/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1486 - f1_loss: 0.3747 - val_loss: 0.5367 - val_binary_crossentropy: 0.5367 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3462\n",
      "Epoch 68/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1482 - f1_loss: 0.3749 - val_loss: 0.5274 - val_binary_crossentropy: 0.5274 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.1738 - val_f1_loss: 0.3458\n",
      "Epoch 69/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4555 - binary_crossentropy: 0.4555 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1481 - f1_loss: 0.3743 - val_loss: 0.5332 - val_binary_crossentropy: 0.5332 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3322 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3455\n",
      "Epoch 70/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4557 - binary_crossentropy: 0.4557 - binary_accuracy: 0.7857 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1482 - f1_loss: 0.3746 - val_loss: 0.5374 - val_binary_crossentropy: 0.5374 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3461\n",
      "Epoch 71/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1485 - f1_loss: 0.3746 - val_loss: 0.5368 - val_binary_crossentropy: 0.5368 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3323 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3460\n",
      "Epoch 72/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1484 - f1_loss: 0.3745 - val_loss: 0.5301 - val_binary_crossentropy: 0.5301 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3460\n",
      "Epoch 73/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4555 - binary_crossentropy: 0.4555 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1481 - f1_loss: 0.3740 - val_loss: 0.5350 - val_binary_crossentropy: 0.5350 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3461\n",
      "Epoch 74/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4549 - binary_crossentropy: 0.4549 - binary_accuracy: 0.7858 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1479 - f1_loss: 0.3738 - val_loss: 0.5303 - val_binary_crossentropy: 0.5303 - val_binary_accuracy: 0.7424 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1742 - val_f1_loss: 0.3457\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1487 - f1_loss: 0.3750 - val_loss: 0.5355 - val_binary_crossentropy: 0.5355 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3460\n",
      "Epoch 76/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1484 - f1_loss: 0.3747 - val_loss: 0.5317 - val_binary_crossentropy: 0.5317 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3468\n",
      "Epoch 77/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1483 - f1_loss: 0.3741 - val_loss: 0.5335 - val_binary_crossentropy: 0.5335 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3467\n",
      "Epoch 78/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4544 - binary_crossentropy: 0.4544 - binary_accuracy: 0.7858 - mean_absolute_error: 0.2952 - mean_squared_error: 0.1477 - f1_loss: 0.3741 - val_loss: 0.5305 - val_binary_crossentropy: 0.5305 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.1748 - val_f1_loss: 0.3467\n",
      "Epoch 79/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4555 - binary_crossentropy: 0.4555 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1482 - f1_loss: 0.3745 - val_loss: 0.5361 - val_binary_crossentropy: 0.5361 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.1763 - val_f1_loss: 0.3455\n",
      "Epoch 80/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1486 - f1_loss: 0.3746 - val_loss: 0.5339 - val_binary_crossentropy: 0.5339 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3460\n",
      "Epoch 81/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1486 - f1_loss: 0.3748 - val_loss: 0.5362 - val_binary_crossentropy: 0.5362 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3317 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3454\n",
      "Epoch 82/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7855 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1481 - f1_loss: 0.3746 - val_loss: 0.5343 - val_binary_crossentropy: 0.5343 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3452\n",
      "Epoch 83/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4549 - binary_crossentropy: 0.4549 - binary_accuracy: 0.7857 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1479 - f1_loss: 0.3739 - val_loss: 0.5344 - val_binary_crossentropy: 0.5344 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3481\n",
      "Epoch 84/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1488 - f1_loss: 0.3746 - val_loss: 0.5297 - val_binary_crossentropy: 0.5297 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1748 - val_f1_loss: 0.3465\n",
      "Epoch 85/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4576 - binary_crossentropy: 0.4576 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1489 - f1_loss: 0.3751 - val_loss: 0.5318 - val_binary_crossentropy: 0.5318 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3323 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3451\n",
      "Epoch 86/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3739 - val_loss: 0.5305 - val_binary_crossentropy: 0.5305 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.1749 - val_f1_loss: 0.3457\n",
      "Epoch 87/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1486 - f1_loss: 0.3746 - val_loss: 0.5417 - val_binary_crossentropy: 0.5417 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3322 - val_mean_squared_error: 0.1779 - val_f1_loss: 0.3461\n",
      "Epoch 88/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1484 - f1_loss: 0.3736 - val_loss: 0.5363 - val_binary_crossentropy: 0.5363 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3460\n",
      "Epoch 89/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2955 - mean_squared_error: 0.1482 - f1_loss: 0.3742 - val_loss: 0.5341 - val_binary_crossentropy: 0.5341 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3319 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3451\n",
      "Epoch 90/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4571 - binary_crossentropy: 0.4571 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1487 - f1_loss: 0.3744 - val_loss: 0.5350 - val_binary_crossentropy: 0.5350 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3464\n",
      "Epoch 91/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2955 - mean_squared_error: 0.1482 - f1_loss: 0.3742 - val_loss: 0.5302 - val_binary_crossentropy: 0.5302 - val_binary_accuracy: 0.7408 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3464\n",
      "Epoch 92/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1486 - f1_loss: 0.3742 - val_loss: 0.5320 - val_binary_crossentropy: 0.5320 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3452\n",
      "Epoch 93/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1486 - f1_loss: 0.3747 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3455\n",
      "Epoch 94/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4553 - binary_crossentropy: 0.4553 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2954 - mean_squared_error: 0.1481 - f1_loss: 0.3739 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3336 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3466\n",
      "Epoch 95/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1484 - f1_loss: 0.3738 - val_loss: 0.5331 - val_binary_crossentropy: 0.5331 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3465\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1486 - f1_loss: 0.3744 - val_loss: 0.5316 - val_binary_crossentropy: 0.5316 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3468\n",
      "Epoch 97/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4549 - binary_crossentropy: 0.4549 - binary_accuracy: 0.7859 - mean_absolute_error: 0.2952 - mean_squared_error: 0.1478 - f1_loss: 0.3743 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3457\n",
      "Epoch 98/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7862 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1481 - f1_loss: 0.3743 - val_loss: 0.5329 - val_binary_crossentropy: 0.5329 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3456\n",
      "Epoch 99/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3742 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3461\n",
      "Epoch 100/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4555 - binary_crossentropy: 0.4555 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1481 - f1_loss: 0.3742 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3457\n",
      "fertig RASCH 1 binary_crossentropy loss\n",
      "None :F1s v/t  0.6884114350775064 0.7210214842371634 0.7230908474427966\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d579f44a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7225628465601508\n",
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7230908474427966\n",
      "GO FOR RASCH1//(xe/px)#1000000\n",
      "checking for cached file ./lfa_models/RASCH1~~(xe~px)#1000000_2\n",
      "./lfa_models/RASCH1~~(xe~px)#1000000_2 found\n",
      "class weights: [2.67326092 1.        ]\n",
      "class weights (dict): {0: 2.6732609156777154, 1: 1.0}\n",
      "nq, ns\n",
      "1130 2512\n",
      "Using univariate Rasch model!\n",
      "TRAINING:\n",
      "Unique students: 2512\n",
      "Unique questions: 1130\n",
      "Total activity: 658050 ( 478904.0 )\n",
      "ov shape (658050, 1130) (1254, 1130)\n",
      "monitoring info loss min\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "psi_select (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hit_counter (InputLayer)        [(None, 1130)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gammas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "alphas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qk_loadings (Dense)             (None, 1)            1130        hit_counter[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 1)            0           gammas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "q_select (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 1)            0           alphas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 1)            0           qk_loadings[0][0]                \n",
      "                                                                 flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qn_embedding (Embedding)        (None, 1, 1)         1130        q_select[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1)            0           flatten_29[0][0]                 \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 1)            0           qn_embedding[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_9 (Subtract)           (None, 1)            0           add_9[0][0]                      \n",
      "                                                                 flatten_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           subtract_9[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,284\n",
      "Trainable params: 7,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "fitting\n",
      "Epoch 1/100\n",
      "2057/2057 [==============================] - 12s 4ms/step - loss: 0.5876 - binary_crossentropy: 0.5876 - binary_accuracy: 0.7030 - mean_absolute_error: 0.4146 - mean_squared_error: 0.2008 - f1_loss: 0.4813 - val_loss: 0.6090 - val_binary_crossentropy: 0.6090 - val_binary_accuracy: 0.6643 - val_mean_absolute_error: 0.4004 - val_mean_squared_error: 0.2108 - val_f1_loss: 0.4268\n",
      "Epoch 2/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4981 - binary_crossentropy: 0.4981 - binary_accuracy: 0.7641 - mean_absolute_error: 0.3458 - mean_squared_error: 0.1630 - f1_loss: 0.4302 - val_loss: 0.5652 - val_binary_crossentropy: 0.5652 - val_binary_accuracy: 0.7049 - val_mean_absolute_error: 0.3734 - val_mean_squared_error: 0.1922 - val_f1_loss: 0.3939\n",
      "Epoch 3/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4781 - binary_crossentropy: 0.4781 - binary_accuracy: 0.7748 - mean_absolute_error: 0.3263 - mean_squared_error: 0.1558 - f1_loss: 0.4099 - val_loss: 0.5442 - val_binary_crossentropy: 0.5442 - val_binary_accuracy: 0.7201 - val_mean_absolute_error: 0.3611 - val_mean_squared_error: 0.1836 - val_f1_loss: 0.3770\n",
      "Epoch 4/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4709 - binary_crossentropy: 0.4709 - binary_accuracy: 0.7784 - mean_absolute_error: 0.3172 - mean_squared_error: 0.1533 - f1_loss: 0.3987 - val_loss: 0.5434 - val_binary_crossentropy: 0.5434 - val_binary_accuracy: 0.7249 - val_mean_absolute_error: 0.3543 - val_mean_squared_error: 0.1828 - val_f1_loss: 0.3696\n",
      "Epoch 5/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4673 - binary_crossentropy: 0.4673 - binary_accuracy: 0.7801 - mean_absolute_error: 0.3117 - mean_squared_error: 0.1521 - f1_loss: 0.3930 - val_loss: 0.5367 - val_binary_crossentropy: 0.5367 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3481 - val_mean_squared_error: 0.1799 - val_f1_loss: 0.3626\n",
      "Epoch 6/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4656 - binary_crossentropy: 0.4656 - binary_accuracy: 0.7806 - mean_absolute_error: 0.3090 - mean_squared_error: 0.1516 - f1_loss: 0.3890 - val_loss: 0.5410 - val_binary_crossentropy: 0.5410 - val_binary_accuracy: 0.7257 - val_mean_absolute_error: 0.3451 - val_mean_squared_error: 0.1812 - val_f1_loss: 0.3601\n",
      "Epoch 7/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4660 - binary_crossentropy: 0.4660 - binary_accuracy: 0.7798 - mean_absolute_error: 0.3077 - mean_squared_error: 0.1518 - f1_loss: 0.3878 - val_loss: 0.5316 - val_binary_crossentropy: 0.5316 - val_binary_accuracy: 0.7424 - val_mean_absolute_error: 0.3435 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3563\n",
      "Epoch 8/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4634 - binary_crossentropy: 0.4634 - binary_accuracy: 0.7814 - mean_absolute_error: 0.3054 - mean_squared_error: 0.1509 - f1_loss: 0.3856 - val_loss: 0.5375 - val_binary_crossentropy: 0.5375 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3434 - val_mean_squared_error: 0.1796 - val_f1_loss: 0.3569\n",
      "Epoch 9/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4631 - binary_crossentropy: 0.4631 - binary_accuracy: 0.7814 - mean_absolute_error: 0.3045 - mean_squared_error: 0.1508 - f1_loss: 0.3843 - val_loss: 0.5362 - val_binary_crossentropy: 0.5362 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3409 - val_mean_squared_error: 0.1786 - val_f1_loss: 0.3546\n",
      "Epoch 10/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4636 - binary_crossentropy: 0.4636 - binary_accuracy: 0.7812 - mean_absolute_error: 0.3046 - mean_squared_error: 0.1510 - f1_loss: 0.3835 - val_loss: 0.5335 - val_binary_crossentropy: 0.5335 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3412 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3539\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4632 - binary_crossentropy: 0.4632 - binary_accuracy: 0.7806 - mean_absolute_error: 0.3039 - mean_squared_error: 0.1509 - f1_loss: 0.3834 - val_loss: 0.5374 - val_binary_crossentropy: 0.5374 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3397 - val_mean_squared_error: 0.1789 - val_f1_loss: 0.3535\n",
      "Epoch 12/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4638 - binary_crossentropy: 0.4638 - binary_accuracy: 0.7807 - mean_absolute_error: 0.3038 - mean_squared_error: 0.1511 - f1_loss: 0.3822 - val_loss: 0.5375 - val_binary_crossentropy: 0.5375 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3391 - val_mean_squared_error: 0.1788 - val_f1_loss: 0.3529\n",
      "Epoch 13/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4621 - binary_crossentropy: 0.4621 - binary_accuracy: 0.7820 - mean_absolute_error: 0.3025 - mean_squared_error: 0.1505 - f1_loss: 0.3818 - val_loss: 0.5334 - val_binary_crossentropy: 0.5334 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3391 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3519\n",
      "Epoch 14/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4624 - binary_crossentropy: 0.4624 - binary_accuracy: 0.7816 - mean_absolute_error: 0.3027 - mean_squared_error: 0.1506 - f1_loss: 0.3813 - val_loss: 0.5302 - val_binary_crossentropy: 0.5302 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3379 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3506\n",
      "Epoch 15/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4613 - binary_crossentropy: 0.4613 - binary_accuracy: 0.7827 - mean_absolute_error: 0.3020 - mean_squared_error: 0.1501 - f1_loss: 0.3811 - val_loss: 0.5297 - val_binary_crossentropy: 0.5297 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3382 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3504\n",
      "Epoch 16/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4609 - binary_crossentropy: 0.4609 - binary_accuracy: 0.7827 - mean_absolute_error: 0.3014 - mean_squared_error: 0.1500 - f1_loss: 0.3803 - val_loss: 0.5321 - val_binary_crossentropy: 0.5321 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3381 - val_mean_squared_error: 0.1767 - val_f1_loss: 0.3507\n",
      "Epoch 17/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4605 - binary_crossentropy: 0.4605 - binary_accuracy: 0.7826 - mean_absolute_error: 0.3012 - mean_squared_error: 0.1499 - f1_loss: 0.3799 - val_loss: 0.5385 - val_binary_crossentropy: 0.5385 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3373 - val_mean_squared_error: 0.1788 - val_f1_loss: 0.3512\n",
      "Epoch 18/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4612 - binary_crossentropy: 0.4612 - binary_accuracy: 0.7821 - mean_absolute_error: 0.3013 - mean_squared_error: 0.1502 - f1_loss: 0.3804 - val_loss: 0.5435 - val_binary_crossentropy: 0.5435 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3361 - val_mean_squared_error: 0.1800 - val_f1_loss: 0.3510\n",
      "Epoch 19/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4599 - binary_crossentropy: 0.4599 - binary_accuracy: 0.7837 - mean_absolute_error: 0.3002 - mean_squared_error: 0.1495 - f1_loss: 0.3793 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3385 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3508\n",
      "Epoch 20/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4608 - binary_crossentropy: 0.4608 - binary_accuracy: 0.7821 - mean_absolute_error: 0.3010 - mean_squared_error: 0.1501 - f1_loss: 0.3799 - val_loss: 0.5419 - val_binary_crossentropy: 0.5419 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3362 - val_mean_squared_error: 0.1794 - val_f1_loss: 0.3508\n",
      "Epoch 21/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7837 - mean_absolute_error: 0.3000 - mean_squared_error: 0.1495 - f1_loss: 0.3789 - val_loss: 0.5352 - val_binary_crossentropy: 0.5352 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3497\n",
      "Epoch 22/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4590 - binary_crossentropy: 0.4590 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2995 - mean_squared_error: 0.1492 - f1_loss: 0.3785 - val_loss: 0.5322 - val_binary_crossentropy: 0.5322 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3368 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3491\n",
      "Epoch 23/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4596 - binary_crossentropy: 0.4596 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2997 - mean_squared_error: 0.1494 - f1_loss: 0.3788 - val_loss: 0.5334 - val_binary_crossentropy: 0.5334 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3495\n",
      "Epoch 24/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4592 - binary_crossentropy: 0.4592 - binary_accuracy: 0.7833 - mean_absolute_error: 0.2997 - mean_squared_error: 0.1494 - f1_loss: 0.3785 - val_loss: 0.5342 - val_binary_crossentropy: 0.5342 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3361 - val_mean_squared_error: 0.1768 - val_f1_loss: 0.3491\n",
      "Epoch 25/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4591 - binary_crossentropy: 0.4591 - binary_accuracy: 0.7837 - mean_absolute_error: 0.2993 - mean_squared_error: 0.1493 - f1_loss: 0.3788 - val_loss: 0.5390 - val_binary_crossentropy: 0.5390 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.1782 - val_f1_loss: 0.3494\n",
      "Epoch 26/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4587 - binary_crossentropy: 0.4587 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1492 - f1_loss: 0.3781 - val_loss: 0.5360 - val_binary_crossentropy: 0.5360 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3362 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3493\n",
      "Epoch 27/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4596 - binary_crossentropy: 0.4596 - binary_accuracy: 0.7832 - mean_absolute_error: 0.2995 - mean_squared_error: 0.1496 - f1_loss: 0.3779 - val_loss: 0.5381 - val_binary_crossentropy: 0.5381 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3496\n",
      "Epoch 28/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4581 - binary_crossentropy: 0.4581 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2987 - mean_squared_error: 0.1489 - f1_loss: 0.3774 - val_loss: 0.5275 - val_binary_crossentropy: 0.5275 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3363 - val_mean_squared_error: 0.1743 - val_f1_loss: 0.3476\n",
      "Epoch 29/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4577 - binary_crossentropy: 0.4577 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2985 - mean_squared_error: 0.1488 - f1_loss: 0.3772 - val_loss: 0.5374 - val_binary_crossentropy: 0.5374 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.1776 - val_f1_loss: 0.3488\n",
      "Epoch 30/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4586 - binary_crossentropy: 0.4586 - binary_accuracy: 0.7828 - mean_absolute_error: 0.2989 - mean_squared_error: 0.1492 - f1_loss: 0.3774 - val_loss: 0.5394 - val_binary_crossentropy: 0.5394 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3349 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3487\n",
      "Epoch 31/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4588 - binary_crossentropy: 0.4588 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2986 - mean_squared_error: 0.1492 - f1_loss: 0.3773 - val_loss: 0.5301 - val_binary_crossentropy: 0.5301 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.1751 - val_f1_loss: 0.3482\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4592 - binary_crossentropy: 0.4592 - binary_accuracy: 0.7834 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1494 - f1_loss: 0.3778 - val_loss: 0.5295 - val_binary_crossentropy: 0.5295 - val_binary_accuracy: 0.7408 - val_mean_absolute_error: 0.3366 - val_mean_squared_error: 0.1751 - val_f1_loss: 0.3481\n",
      "Epoch 33/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4585 - binary_crossentropy: 0.4585 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2985 - mean_squared_error: 0.1491 - f1_loss: 0.3773 - val_loss: 0.5305 - val_binary_crossentropy: 0.5305 - val_binary_accuracy: 0.7408 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1748 - val_f1_loss: 0.3474\n",
      "Epoch 34/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4577 - binary_crossentropy: 0.4577 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2979 - mean_squared_error: 0.1488 - f1_loss: 0.3767 - val_loss: 0.5365 - val_binary_crossentropy: 0.5365 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3479\n",
      "Epoch 35/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4586 - binary_crossentropy: 0.4586 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2987 - mean_squared_error: 0.1493 - f1_loss: 0.3766 - val_loss: 0.5288 - val_binary_crossentropy: 0.5288 - val_binary_accuracy: 0.7424 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.1746 - val_f1_loss: 0.3474\n",
      "Epoch 36/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4579 - binary_crossentropy: 0.4579 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2981 - mean_squared_error: 0.1489 - f1_loss: 0.3764 - val_loss: 0.5323 - val_binary_crossentropy: 0.5323 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3475\n",
      "Epoch 37/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4585 - binary_crossentropy: 0.4585 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2983 - mean_squared_error: 0.1492 - f1_loss: 0.3767 - val_loss: 0.5346 - val_binary_crossentropy: 0.5346 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3345 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3477\n",
      "Epoch 38/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2979 - mean_squared_error: 0.1489 - f1_loss: 0.3761 - val_loss: 0.5355 - val_binary_crossentropy: 0.5355 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3474\n",
      "Epoch 39/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1486 - f1_loss: 0.3760 - val_loss: 0.5313 - val_binary_crossentropy: 0.5313 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3345 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3470\n",
      "Epoch 40/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.4583 - binary_crossentropy: 0.4583 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2980 - mean_squared_error: 0.1490 - f1_loss: 0.3762 - val_loss: 0.5333 - val_binary_crossentropy: 0.5333 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3465\n",
      "Epoch 41/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1487 - f1_loss: 0.3761 - val_loss: 0.5321 - val_binary_crossentropy: 0.5321 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3467\n",
      "Epoch 42/100\n",
      "2057/2057 [==============================] - 12s 5ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1484 - f1_loss: 0.3760 - val_loss: 0.5321 - val_binary_crossentropy: 0.5321 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3467\n",
      "Epoch 43/100\n",
      "2057/2057 [==============================] - 12s 4ms/step - loss: 0.4587 - binary_crossentropy: 0.4587 - binary_accuracy: 0.7833 - mean_absolute_error: 0.2983 - mean_squared_error: 0.1493 - f1_loss: 0.3763 - val_loss: 0.5299 - val_binary_crossentropy: 0.5299 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1748 - val_f1_loss: 0.3467\n",
      "Epoch 44/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2973 - mean_squared_error: 0.1487 - f1_loss: 0.3761 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3467\n",
      "Epoch 45/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.4581 - binary_crossentropy: 0.4581 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2976 - mean_squared_error: 0.1490 - f1_loss: 0.3757 - val_loss: 0.5298 - val_binary_crossentropy: 0.5298 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1745 - val_f1_loss: 0.3469\n",
      "Epoch 46/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4561 - binary_crossentropy: 0.4561 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1482 - f1_loss: 0.3756 - val_loss: 0.5409 - val_binary_crossentropy: 0.5409 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3471\n",
      "Epoch 47/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4570 - binary_crossentropy: 0.4570 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2970 - mean_squared_error: 0.1486 - f1_loss: 0.3756 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3470\n",
      "Epoch 48/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4579 - binary_crossentropy: 0.4579 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1489 - f1_loss: 0.3759 - val_loss: 0.5372 - val_binary_crossentropy: 0.5372 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3464\n",
      "Epoch 49/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1487 - f1_loss: 0.3757 - val_loss: 0.5277 - val_binary_crossentropy: 0.5277 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.1739 - val_f1_loss: 0.3461\n",
      "Epoch 50/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4584 - binary_crossentropy: 0.4584 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2980 - mean_squared_error: 0.1491 - f1_loss: 0.3763 - val_loss: 0.5365 - val_binary_crossentropy: 0.5365 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3465\n",
      "Epoch 51/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1484 - f1_loss: 0.3750 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3461\n",
      "Epoch 52/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4571 - binary_crossentropy: 0.4571 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1486 - f1_loss: 0.3759 - val_loss: 0.5336 - val_binary_crossentropy: 0.5336 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3460\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2970 - mean_squared_error: 0.1486 - f1_loss: 0.3749 - val_loss: 0.5327 - val_binary_crossentropy: 0.5327 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3462\n",
      "Epoch 54/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1487 - f1_loss: 0.3752 - val_loss: 0.5303 - val_binary_crossentropy: 0.5303 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3458\n",
      "Epoch 55/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1484 - f1_loss: 0.3755 - val_loss: 0.5356 - val_binary_crossentropy: 0.5356 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3464\n",
      "Epoch 56/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1489 - f1_loss: 0.3752 - val_loss: 0.5373 - val_binary_crossentropy: 0.5373 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3322 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3461\n",
      "Epoch 57/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1486 - f1_loss: 0.3750 - val_loss: 0.5361 - val_binary_crossentropy: 0.5361 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3325 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3462\n",
      "Epoch 58/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1488 - f1_loss: 0.3753 - val_loss: 0.5346 - val_binary_crossentropy: 0.5346 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3469\n",
      "Epoch 59/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1484 - f1_loss: 0.3752 - val_loss: 0.5318 - val_binary_crossentropy: 0.5318 - val_binary_accuracy: 0.7408 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3462\n",
      "Epoch 60/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4583 - binary_crossentropy: 0.4583 - binary_accuracy: 0.7837 - mean_absolute_error: 0.2975 - mean_squared_error: 0.1491 - f1_loss: 0.3753 - val_loss: 0.5309 - val_binary_crossentropy: 0.5309 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1748 - val_f1_loss: 0.3458\n",
      "Epoch 61/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1482 - f1_loss: 0.3747 - val_loss: 0.5355 - val_binary_crossentropy: 0.5355 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3336 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3466\n",
      "Epoch 62/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1484 - f1_loss: 0.3749 - val_loss: 0.5373 - val_binary_crossentropy: 0.5373 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3464\n",
      "Epoch 63/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7856 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1481 - f1_loss: 0.3745 - val_loss: 0.5300 - val_binary_crossentropy: 0.5300 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1745 - val_f1_loss: 0.3466\n",
      "Epoch 64/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1484 - f1_loss: 0.3748 - val_loss: 0.5266 - val_binary_crossentropy: 0.5266 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1734 - val_f1_loss: 0.3451\n",
      "Epoch 65/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1485 - f1_loss: 0.3749 - val_loss: 0.5360 - val_binary_crossentropy: 0.5360 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1763 - val_f1_loss: 0.3464\n",
      "Epoch 66/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1483 - f1_loss: 0.3746 - val_loss: 0.5365 - val_binary_crossentropy: 0.5365 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3456\n",
      "Epoch 67/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4555 - binary_crossentropy: 0.4555 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1481 - f1_loss: 0.3744 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3460\n",
      "Epoch 68/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4576 - binary_crossentropy: 0.4576 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2970 - mean_squared_error: 0.1489 - f1_loss: 0.3747 - val_loss: 0.5317 - val_binary_crossentropy: 0.5317 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3458\n",
      "Epoch 69/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7858 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1482 - f1_loss: 0.3743 - val_loss: 0.5323 - val_binary_crossentropy: 0.5323 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3326 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3453\n",
      "Epoch 70/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4552 - binary_crossentropy: 0.4552 - binary_accuracy: 0.7855 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1480 - f1_loss: 0.3739 - val_loss: 0.5353 - val_binary_crossentropy: 0.5353 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3459\n",
      "Epoch 71/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1484 - f1_loss: 0.3746 - val_loss: 0.5321 - val_binary_crossentropy: 0.5321 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3460\n",
      "Epoch 72/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4576 - binary_crossentropy: 0.4576 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1489 - f1_loss: 0.3751 - val_loss: 0.5266 - val_binary_crossentropy: 0.5266 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1736 - val_f1_loss: 0.3450\n",
      "Epoch 73/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1485 - f1_loss: 0.3744 - val_loss: 0.5348 - val_binary_crossentropy: 0.5348 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3461\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4557 - binary_crossentropy: 0.4557 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1482 - f1_loss: 0.3745 - val_loss: 0.5305 - val_binary_crossentropy: 0.5305 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3460\n",
      "Epoch 75/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1487 - f1_loss: 0.3749 - val_loss: 0.5348 - val_binary_crossentropy: 0.5348 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3323 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3454\n",
      "Epoch 76/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1485 - f1_loss: 0.3746 - val_loss: 0.5333 - val_binary_crossentropy: 0.5333 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3463\n",
      "Epoch 77/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1485 - f1_loss: 0.3749 - val_loss: 0.5289 - val_binary_crossentropy: 0.5289 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1742 - val_f1_loss: 0.3464\n",
      "Epoch 78/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1486 - f1_loss: 0.3751 - val_loss: 0.5379 - val_binary_crossentropy: 0.5379 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3333 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3465\n",
      "Epoch 79/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1489 - f1_loss: 0.3749 - val_loss: 0.5331 - val_binary_crossentropy: 0.5331 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3315 - val_mean_squared_error: 0.1752 - val_f1_loss: 0.3446\n",
      "Epoch 80/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4558 - binary_crossentropy: 0.4558 - binary_accuracy: 0.7855 - mean_absolute_error: 0.2957 - mean_squared_error: 0.1482 - f1_loss: 0.3741 - val_loss: 0.5330 - val_binary_crossentropy: 0.5330 - val_binary_accuracy: 0.7400 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3456\n",
      "Epoch 81/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1485 - f1_loss: 0.3748 - val_loss: 0.5407 - val_binary_crossentropy: 0.5407 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3316 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3457\n",
      "Epoch 82/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3743 - val_loss: 0.5290 - val_binary_crossentropy: 0.5290 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.1743 - val_f1_loss: 0.3450\n",
      "Epoch 83/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1484 - f1_loss: 0.3741 - val_loss: 0.5335 - val_binary_crossentropy: 0.5335 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3457\n",
      "Epoch 84/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4553 - binary_crossentropy: 0.4553 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2955 - mean_squared_error: 0.1480 - f1_loss: 0.3737 - val_loss: 0.5343 - val_binary_crossentropy: 0.5343 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.1760 - val_f1_loss: 0.3454\n",
      "Epoch 85/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1486 - f1_loss: 0.3747 - val_loss: 0.5308 - val_binary_crossentropy: 0.5308 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1748 - val_f1_loss: 0.3466\n",
      "Epoch 86/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1485 - f1_loss: 0.3744 - val_loss: 0.5332 - val_binary_crossentropy: 0.5332 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1757 - val_f1_loss: 0.3464\n",
      "Epoch 87/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1488 - f1_loss: 0.3747 - val_loss: 0.5306 - val_binary_crossentropy: 0.5306 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.1749 - val_f1_loss: 0.3453\n",
      "Epoch 88/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1485 - f1_loss: 0.3746 - val_loss: 0.5326 - val_binary_crossentropy: 0.5326 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3345 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3464\n",
      "Epoch 89/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1486 - f1_loss: 0.3747 - val_loss: 0.5349 - val_binary_crossentropy: 0.5349 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1760 - val_f1_loss: 0.3460\n",
      "Epoch 90/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1487 - f1_loss: 0.3748 - val_loss: 0.5311 - val_binary_crossentropy: 0.5311 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.1750 - val_f1_loss: 0.3462\n",
      "Epoch 91/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4555 - binary_crossentropy: 0.4555 - binary_accuracy: 0.7857 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1481 - f1_loss: 0.3744 - val_loss: 0.5345 - val_binary_crossentropy: 0.5345 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3321 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3451\n",
      "Epoch 92/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1484 - f1_loss: 0.3744 - val_loss: 0.5341 - val_binary_crossentropy: 0.5341 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3330 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3457\n",
      "Epoch 93/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1483 - f1_loss: 0.3742 - val_loss: 0.5366 - val_binary_crossentropy: 0.5366 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3339 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3467\n",
      "Epoch 94/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4558 - binary_crossentropy: 0.4558 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1483 - f1_loss: 0.3741 - val_loss: 0.5312 - val_binary_crossentropy: 0.5312 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1753 - val_f1_loss: 0.3459\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1484 - f1_loss: 0.3744 - val_loss: 0.5308 - val_binary_crossentropy: 0.5308 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3324 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3449\n",
      "Epoch 96/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4557 - binary_crossentropy: 0.4557 - binary_accuracy: 0.7859 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1482 - f1_loss: 0.3739 - val_loss: 0.5331 - val_binary_crossentropy: 0.5331 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3467\n",
      "Epoch 97/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4559 - binary_crossentropy: 0.4559 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3743 - val_loss: 0.5346 - val_binary_crossentropy: 0.5346 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3460\n",
      "Epoch 98/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2955 - mean_squared_error: 0.1482 - f1_loss: 0.3747 - val_loss: 0.5371 - val_binary_crossentropy: 0.5371 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3459\n",
      "Epoch 99/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1485 - f1_loss: 0.3746 - val_loss: 0.5365 - val_binary_crossentropy: 0.5365 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3327 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3457\n",
      "Epoch 100/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1484 - f1_loss: 0.3739 - val_loss: 0.5416 - val_binary_crossentropy: 0.5416 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1772 - val_f1_loss: 0.3465\n",
      "fertig RASCH 1 binary_crossentropy loss\n",
      "None :F1s v/t  0.687383856024327 0.7133694959595176 0.7240811485037297\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d694dc710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7225628465601508\n",
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7230908474427966\n",
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7240811485037297\n",
      "GO FOR RASCH1//(xe/px)#1000000\n",
      "checking for cached file ./lfa_models/RASCH1~~(xe~px)#1000000_3\n",
      "./lfa_models/RASCH1~~(xe~px)#1000000_3 found\n",
      "class weights: [2.67326092 1.        ]\n",
      "class weights (dict): {0: 2.6732609156777154, 1: 1.0}\n",
      "nq, ns\n",
      "1130 2512\n",
      "Using univariate Rasch model!\n",
      "TRAINING:\n",
      "Unique students: 2512\n",
      "Unique questions: 1130\n",
      "Total activity: 658050 ( 478904.0 )\n",
      "ov shape (658050, 1130) (1254, 1130)\n",
      "monitoring info loss min\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "psi_select (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hit_counter (InputLayer)        [(None, 1130)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gammas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "alphas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qk_loadings (Dense)             (None, 1)            1130        hit_counter[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 1)            0           gammas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "q_select (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 1)            0           alphas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 1)            0           qk_loadings[0][0]                \n",
      "                                                                 flatten_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qn_embedding (Embedding)        (None, 1, 1)         1130        q_select[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1)            0           flatten_32[0][0]                 \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 1)            0           qn_embedding[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_10 (Subtract)          (None, 1)            0           add_10[0][0]                     \n",
      "                                                                 flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           subtract_10[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,284\n",
      "Trainable params: 7,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "fitting\n",
      "Epoch 1/100\n",
      "2057/2057 [==============================] - 14s 4ms/step - loss: 0.5962 - binary_crossentropy: 0.5962 - binary_accuracy: 0.7030 - mean_absolute_error: 0.4242 - mean_squared_error: 0.2047 - f1_loss: 0.4853 - val_loss: 0.5981 - val_binary_crossentropy: 0.5981 - val_binary_accuracy: 0.6675 - val_mean_absolute_error: 0.3998 - val_mean_squared_error: 0.2067 - val_f1_loss: 0.4242\n",
      "Epoch 2/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4985 - binary_crossentropy: 0.4985 - binary_accuracy: 0.7654 - mean_absolute_error: 0.3470 - mean_squared_error: 0.1631 - f1_loss: 0.4308 - val_loss: 0.5570 - val_binary_crossentropy: 0.5570 - val_binary_accuracy: 0.7097 - val_mean_absolute_error: 0.3752 - val_mean_squared_error: 0.1890 - val_f1_loss: 0.3936\n",
      "Epoch 3/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4793 - binary_crossentropy: 0.4793 - binary_accuracy: 0.7743 - mean_absolute_error: 0.3282 - mean_squared_error: 0.1561 - f1_loss: 0.4104 - val_loss: 0.5411 - val_binary_crossentropy: 0.5411 - val_binary_accuracy: 0.7217 - val_mean_absolute_error: 0.3600 - val_mean_squared_error: 0.1821 - val_f1_loss: 0.3759\n",
      "Epoch 4/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4718 - binary_crossentropy: 0.4718 - binary_accuracy: 0.7781 - mean_absolute_error: 0.3183 - mean_squared_error: 0.1536 - f1_loss: 0.3995 - val_loss: 0.5351 - val_binary_crossentropy: 0.5351 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3528 - val_mean_squared_error: 0.1799 - val_f1_loss: 0.3674\n",
      "Epoch 5/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4675 - binary_crossentropy: 0.4675 - binary_accuracy: 0.7805 - mean_absolute_error: 0.3125 - mean_squared_error: 0.1521 - f1_loss: 0.3930 - val_loss: 0.5353 - val_binary_crossentropy: 0.5353 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3488 - val_mean_squared_error: 0.1793 - val_f1_loss: 0.3629\n",
      "Epoch 6/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4655 - binary_crossentropy: 0.4655 - binary_accuracy: 0.7806 - mean_absolute_error: 0.3094 - mean_squared_error: 0.1516 - f1_loss: 0.3894 - val_loss: 0.5387 - val_binary_crossentropy: 0.5387 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3463 - val_mean_squared_error: 0.1805 - val_f1_loss: 0.3610\n",
      "Epoch 7/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4648 - binary_crossentropy: 0.4648 - binary_accuracy: 0.7807 - mean_absolute_error: 0.3073 - mean_squared_error: 0.1513 - f1_loss: 0.3878 - val_loss: 0.5368 - val_binary_crossentropy: 0.5368 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3450 - val_mean_squared_error: 0.1796 - val_f1_loss: 0.3587\n",
      "Epoch 8/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4645 - binary_crossentropy: 0.4645 - binary_accuracy: 0.7816 - mean_absolute_error: 0.3063 - mean_squared_error: 0.1512 - f1_loss: 0.3858 - val_loss: 0.5355 - val_binary_crossentropy: 0.5355 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3440 - val_mean_squared_error: 0.1791 - val_f1_loss: 0.3575\n",
      "Epoch 9/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4630 - binary_crossentropy: 0.4630 - binary_accuracy: 0.7822 - mean_absolute_error: 0.3045 - mean_squared_error: 0.1507 - f1_loss: 0.3847 - val_loss: 0.5342 - val_binary_crossentropy: 0.5342 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3417 - val_mean_squared_error: 0.1783 - val_f1_loss: 0.3552\n",
      "Epoch 10/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4632 - binary_crossentropy: 0.4632 - binary_accuracy: 0.7820 - mean_absolute_error: 0.3043 - mean_squared_error: 0.1508 - f1_loss: 0.3838 - val_loss: 0.5377 - val_binary_crossentropy: 0.5377 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3425 - val_mean_squared_error: 0.1797 - val_f1_loss: 0.3561\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4622 - binary_crossentropy: 0.4622 - binary_accuracy: 0.7823 - mean_absolute_error: 0.3033 - mean_squared_error: 0.1504 - f1_loss: 0.3831 - val_loss: 0.5317 - val_binary_crossentropy: 0.5317 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3416 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3542\n",
      "Epoch 12/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4627 - binary_crossentropy: 0.4627 - binary_accuracy: 0.7817 - mean_absolute_error: 0.3032 - mean_squared_error: 0.1506 - f1_loss: 0.3823 - val_loss: 0.5326 - val_binary_crossentropy: 0.5326 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3424 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3547\n",
      "Epoch 13/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4622 - binary_crossentropy: 0.4622 - binary_accuracy: 0.7815 - mean_absolute_error: 0.3028 - mean_squared_error: 0.1506 - f1_loss: 0.3816 - val_loss: 0.5374 - val_binary_crossentropy: 0.5374 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3415 - val_mean_squared_error: 0.1791 - val_f1_loss: 0.3547\n",
      "Epoch 14/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4617 - binary_crossentropy: 0.4617 - binary_accuracy: 0.7821 - mean_absolute_error: 0.3021 - mean_squared_error: 0.1503 - f1_loss: 0.3819 - val_loss: 0.5301 - val_binary_crossentropy: 0.5301 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3405 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3526\n",
      "Epoch 15/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4607 - binary_crossentropy: 0.4607 - binary_accuracy: 0.7828 - mean_absolute_error: 0.3013 - mean_squared_error: 0.1498 - f1_loss: 0.3809 - val_loss: 0.5355 - val_binary_crossentropy: 0.5355 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3399 - val_mean_squared_error: 0.1784 - val_f1_loss: 0.3531\n",
      "Epoch 16/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4615 - binary_crossentropy: 0.4615 - binary_accuracy: 0.7824 - mean_absolute_error: 0.3017 - mean_squared_error: 0.1502 - f1_loss: 0.3807 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3397 - val_mean_squared_error: 0.1785 - val_f1_loss: 0.3530\n",
      "Epoch 17/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4618 - binary_crossentropy: 0.4618 - binary_accuracy: 0.7825 - mean_absolute_error: 0.3017 - mean_squared_error: 0.1503 - f1_loss: 0.3807 - val_loss: 0.5397 - val_binary_crossentropy: 0.5397 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3392 - val_mean_squared_error: 0.1795 - val_f1_loss: 0.3531\n",
      "Epoch 18/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4612 - binary_crossentropy: 0.4612 - binary_accuracy: 0.7817 - mean_absolute_error: 0.3015 - mean_squared_error: 0.1503 - f1_loss: 0.3805 - val_loss: 0.5354 - val_binary_crossentropy: 0.5354 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3392 - val_mean_squared_error: 0.1780 - val_f1_loss: 0.3521\n",
      "Epoch 19/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4603 - binary_crossentropy: 0.4603 - binary_accuracy: 0.7835 - mean_absolute_error: 0.3007 - mean_squared_error: 0.1497 - f1_loss: 0.3797 - val_loss: 0.5338 - val_binary_crossentropy: 0.5338 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3382 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3513\n",
      "Epoch 20/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4598 - binary_crossentropy: 0.4598 - binary_accuracy: 0.7833 - mean_absolute_error: 0.3003 - mean_squared_error: 0.1496 - f1_loss: 0.3799 - val_loss: 0.5351 - val_binary_crossentropy: 0.5351 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3393 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3521\n",
      "Epoch 21/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4598 - binary_crossentropy: 0.4598 - binary_accuracy: 0.7835 - mean_absolute_error: 0.3003 - mean_squared_error: 0.1496 - f1_loss: 0.3799 - val_loss: 0.5416 - val_binary_crossentropy: 0.5416 - val_binary_accuracy: 0.7281 - val_mean_absolute_error: 0.3391 - val_mean_squared_error: 0.1797 - val_f1_loss: 0.3528\n",
      "Epoch 22/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4610 - binary_crossentropy: 0.4610 - binary_accuracy: 0.7825 - mean_absolute_error: 0.3007 - mean_squared_error: 0.1500 - f1_loss: 0.3801 - val_loss: 0.5344 - val_binary_crossentropy: 0.5344 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3384 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3512\n",
      "Epoch 23/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4605 - binary_crossentropy: 0.4605 - binary_accuracy: 0.7825 - mean_absolute_error: 0.3005 - mean_squared_error: 0.1499 - f1_loss: 0.3797 - val_loss: 0.5357 - val_binary_crossentropy: 0.5357 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3506\n",
      "Epoch 24/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4600 - binary_crossentropy: 0.4600 - binary_accuracy: 0.7830 - mean_absolute_error: 0.3002 - mean_squared_error: 0.1497 - f1_loss: 0.3790 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3377 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3507\n",
      "Epoch 25/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4606 - binary_crossentropy: 0.4606 - binary_accuracy: 0.7832 - mean_absolute_error: 0.3003 - mean_squared_error: 0.1499 - f1_loss: 0.3791 - val_loss: 0.5353 - val_binary_crossentropy: 0.5353 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3392 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3516\n",
      "Epoch 26/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4604 - binary_crossentropy: 0.4604 - binary_accuracy: 0.7829 - mean_absolute_error: 0.3000 - mean_squared_error: 0.1498 - f1_loss: 0.3790 - val_loss: 0.5357 - val_binary_crossentropy: 0.5357 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3369 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3504\n",
      "Epoch 27/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4605 - binary_crossentropy: 0.4605 - binary_accuracy: 0.7828 - mean_absolute_error: 0.3002 - mean_squared_error: 0.1499 - f1_loss: 0.3787 - val_loss: 0.5369 - val_binary_crossentropy: 0.5369 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3374 - val_mean_squared_error: 0.1782 - val_f1_loss: 0.3509\n",
      "Epoch 28/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4588 - binary_crossentropy: 0.4588 - binary_accuracy: 0.7834 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1493 - f1_loss: 0.3784 - val_loss: 0.5373 - val_binary_crossentropy: 0.5373 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3385 - val_mean_squared_error: 0.1781 - val_f1_loss: 0.3516\n",
      "Epoch 29/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4598 - binary_crossentropy: 0.4598 - binary_accuracy: 0.7833 - mean_absolute_error: 0.2995 - mean_squared_error: 0.1496 - f1_loss: 0.3784 - val_loss: 0.5406 - val_binary_crossentropy: 0.5406 - val_binary_accuracy: 0.7273 - val_mean_absolute_error: 0.3370 - val_mean_squared_error: 0.1792 - val_f1_loss: 0.3510\n",
      "Epoch 30/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4595 - binary_crossentropy: 0.4595 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2995 - mean_squared_error: 0.1495 - f1_loss: 0.3788 - val_loss: 0.5325 - val_binary_crossentropy: 0.5325 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3372 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3498\n",
      "Epoch 31/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4583 - binary_crossentropy: 0.4583 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2988 - mean_squared_error: 0.1491 - f1_loss: 0.3777 - val_loss: 0.5358 - val_binary_crossentropy: 0.5358 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3367 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3500\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4592 - binary_crossentropy: 0.4592 - binary_accuracy: 0.7837 - mean_absolute_error: 0.2989 - mean_squared_error: 0.1494 - f1_loss: 0.3781 - val_loss: 0.5331 - val_binary_crossentropy: 0.5331 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3377 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3502\n",
      "Epoch 33/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4588 - binary_crossentropy: 0.4588 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2989 - mean_squared_error: 0.1492 - f1_loss: 0.3776 - val_loss: 0.5419 - val_binary_crossentropy: 0.5419 - val_binary_accuracy: 0.7265 - val_mean_absolute_error: 0.3371 - val_mean_squared_error: 0.1795 - val_f1_loss: 0.3511\n",
      "Epoch 34/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4600 - binary_crossentropy: 0.4600 - binary_accuracy: 0.7833 - mean_absolute_error: 0.2993 - mean_squared_error: 0.1497 - f1_loss: 0.3780 - val_loss: 0.5412 - val_binary_crossentropy: 0.5412 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.1790 - val_f1_loss: 0.3505\n",
      "Epoch 35/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4583 - binary_crossentropy: 0.4583 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2984 - mean_squared_error: 0.1491 - f1_loss: 0.3772 - val_loss: 0.5342 - val_binary_crossentropy: 0.5342 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3366 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3495\n",
      "Epoch 36/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4590 - binary_crossentropy: 0.4590 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2989 - mean_squared_error: 0.1493 - f1_loss: 0.3775 - val_loss: 0.5362 - val_binary_crossentropy: 0.5362 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.1773 - val_f1_loss: 0.3497\n",
      "Epoch 37/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4588 - binary_crossentropy: 0.4588 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2986 - mean_squared_error: 0.1493 - f1_loss: 0.3779 - val_loss: 0.5338 - val_binary_crossentropy: 0.5338 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3487\n",
      "Epoch 38/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4587 - binary_crossentropy: 0.4587 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2987 - mean_squared_error: 0.1492 - f1_loss: 0.3769 - val_loss: 0.5366 - val_binary_crossentropy: 0.5366 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3360 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3494\n",
      "Epoch 39/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2978 - mean_squared_error: 0.1487 - f1_loss: 0.3767 - val_loss: 0.5383 - val_binary_crossentropy: 0.5383 - val_binary_accuracy: 0.7257 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.1779 - val_f1_loss: 0.3493\n",
      "Epoch 40/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4589 - binary_crossentropy: 0.4589 - binary_accuracy: 0.7837 - mean_absolute_error: 0.2986 - mean_squared_error: 0.1493 - f1_loss: 0.3772 - val_loss: 0.5334 - val_binary_crossentropy: 0.5334 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3485\n",
      "Epoch 41/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2987 - mean_squared_error: 0.1494 - f1_loss: 0.3775 - val_loss: 0.5369 - val_binary_crossentropy: 0.5369 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3355 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3489\n",
      "Epoch 42/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4574 - binary_crossentropy: 0.4574 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2977 - mean_squared_error: 0.1488 - f1_loss: 0.3764 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3363 - val_mean_squared_error: 0.1767 - val_f1_loss: 0.3490\n",
      "Epoch 43/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4592 - binary_crossentropy: 0.4592 - binary_accuracy: 0.7834 - mean_absolute_error: 0.2986 - mean_squared_error: 0.1495 - f1_loss: 0.3773 - val_loss: 0.5370 - val_binary_crossentropy: 0.5370 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3484\n",
      "Epoch 44/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4579 - binary_crossentropy: 0.4579 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2979 - mean_squared_error: 0.1490 - f1_loss: 0.3765 - val_loss: 0.5369 - val_binary_crossentropy: 0.5369 - val_binary_accuracy: 0.7265 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1773 - val_f1_loss: 0.3485\n",
      "Epoch 45/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4571 - binary_crossentropy: 0.4571 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1486 - f1_loss: 0.3763 - val_loss: 0.5370 - val_binary_crossentropy: 0.5370 - val_binary_accuracy: 0.7281 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.1774 - val_f1_loss: 0.3482\n",
      "Epoch 46/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4591 - binary_crossentropy: 0.4591 - binary_accuracy: 0.7831 - mean_absolute_error: 0.2986 - mean_squared_error: 0.1495 - f1_loss: 0.3766 - val_loss: 0.5315 - val_binary_crossentropy: 0.5315 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.1756 - val_f1_loss: 0.3484\n",
      "Epoch 47/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4583 - binary_crossentropy: 0.4583 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2980 - mean_squared_error: 0.1490 - f1_loss: 0.3765 - val_loss: 0.5306 - val_binary_crossentropy: 0.5306 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1755 - val_f1_loss: 0.3476\n",
      "Epoch 48/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4573 - binary_crossentropy: 0.4573 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1487 - f1_loss: 0.3766 - val_loss: 0.5366 - val_binary_crossentropy: 0.5366 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3489\n",
      "Epoch 49/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4580 - binary_crossentropy: 0.4580 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2978 - mean_squared_error: 0.1490 - f1_loss: 0.3761 - val_loss: 0.5453 - val_binary_crossentropy: 0.5453 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1796 - val_f1_loss: 0.3484\n",
      "Epoch 50/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2972 - mean_squared_error: 0.1486 - f1_loss: 0.3761 - val_loss: 0.5325 - val_binary_crossentropy: 0.5325 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3360 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3483\n",
      "Epoch 51/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4580 - binary_crossentropy: 0.4580 - binary_accuracy: 0.7836 - mean_absolute_error: 0.2977 - mean_squared_error: 0.1491 - f1_loss: 0.3765 - val_loss: 0.5322 - val_binary_crossentropy: 0.5322 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3487\n",
      "Epoch 52/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2975 - mean_squared_error: 0.1488 - f1_loss: 0.3756 - val_loss: 0.5291 - val_binary_crossentropy: 0.5291 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.1751 - val_f1_loss: 0.3478\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4577 - binary_crossentropy: 0.4577 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2976 - mean_squared_error: 0.1489 - f1_loss: 0.3760 - val_loss: 0.5342 - val_binary_crossentropy: 0.5342 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3479\n",
      "Epoch 54/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7855 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1483 - f1_loss: 0.3755 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3359 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3486\n",
      "Epoch 55/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4582 - binary_crossentropy: 0.4582 - binary_accuracy: 0.7837 - mean_absolute_error: 0.2976 - mean_squared_error: 0.1491 - f1_loss: 0.3761 - val_loss: 0.5402 - val_binary_crossentropy: 0.5402 - val_binary_accuracy: 0.7241 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.1779 - val_f1_loss: 0.3481\n",
      "Epoch 56/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4579 - binary_crossentropy: 0.4579 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2975 - mean_squared_error: 0.1490 - f1_loss: 0.3759 - val_loss: 0.5359 - val_binary_crossentropy: 0.5359 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3474\n",
      "Epoch 57/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1486 - f1_loss: 0.3755 - val_loss: 0.5327 - val_binary_crossentropy: 0.5327 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1758 - val_f1_loss: 0.3471\n",
      "Epoch 58/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4576 - binary_crossentropy: 0.4576 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2973 - mean_squared_error: 0.1488 - f1_loss: 0.3755 - val_loss: 0.5373 - val_binary_crossentropy: 0.5373 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3476\n",
      "Epoch 59/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1484 - f1_loss: 0.3754 - val_loss: 0.5352 - val_binary_crossentropy: 0.5352 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3476\n",
      "Epoch 60/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7847 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1485 - f1_loss: 0.3755 - val_loss: 0.5373 - val_binary_crossentropy: 0.5373 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3343 - val_mean_squared_error: 0.1772 - val_f1_loss: 0.3477\n",
      "Epoch 61/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2974 - mean_squared_error: 0.1490 - f1_loss: 0.3757 - val_loss: 0.5349 - val_binary_crossentropy: 0.5349 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1761 - val_f1_loss: 0.3466\n",
      "Epoch 62/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1487 - f1_loss: 0.3753 - val_loss: 0.5399 - val_binary_crossentropy: 0.5399 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3338 - val_mean_squared_error: 0.1778 - val_f1_loss: 0.3476\n",
      "Epoch 63/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1487 - f1_loss: 0.3751 - val_loss: 0.5350 - val_binary_crossentropy: 0.5350 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3477\n",
      "Epoch 64/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4570 - binary_crossentropy: 0.4570 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2970 - mean_squared_error: 0.1486 - f1_loss: 0.3753 - val_loss: 0.5394 - val_binary_crossentropy: 0.5394 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1780 - val_f1_loss: 0.3473\n",
      "Epoch 65/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1485 - f1_loss: 0.3751 - val_loss: 0.5410 - val_binary_crossentropy: 0.5410 - val_binary_accuracy: 0.7273 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1784 - val_f1_loss: 0.3476\n",
      "Epoch 66/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4575 - binary_crossentropy: 0.4575 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2967 - mean_squared_error: 0.1488 - f1_loss: 0.3757 - val_loss: 0.5329 - val_binary_crossentropy: 0.5329 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3477\n",
      "Epoch 67/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7838 - mean_absolute_error: 0.2969 - mean_squared_error: 0.1486 - f1_loss: 0.3755 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3469\n",
      "Epoch 68/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4549 - binary_crossentropy: 0.4549 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1479 - f1_loss: 0.3747 - val_loss: 0.5353 - val_binary_crossentropy: 0.5353 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3337 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3470\n",
      "Epoch 69/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1485 - f1_loss: 0.3749 - val_loss: 0.5425 - val_binary_crossentropy: 0.5425 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1787 - val_f1_loss: 0.3472\n",
      "Epoch 70/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4569 - binary_crossentropy: 0.4569 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1486 - f1_loss: 0.3755 - val_loss: 0.5353 - val_binary_crossentropy: 0.5353 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3475\n",
      "Epoch 71/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1485 - f1_loss: 0.3748 - val_loss: 0.5350 - val_binary_crossentropy: 0.5350 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3345 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3473\n",
      "Epoch 72/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4571 - binary_crossentropy: 0.4571 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2970 - mean_squared_error: 0.1488 - f1_loss: 0.3752 - val_loss: 0.5338 - val_binary_crossentropy: 0.5338 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1763 - val_f1_loss: 0.3475\n",
      "Epoch 73/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4576 - binary_crossentropy: 0.4576 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2971 - mean_squared_error: 0.1489 - f1_loss: 0.3755 - val_loss: 0.5383 - val_binary_crossentropy: 0.5383 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3329 - val_mean_squared_error: 0.1773 - val_f1_loss: 0.3466\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4559 - binary_crossentropy: 0.4559 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3747 - val_loss: 0.5337 - val_binary_crossentropy: 0.5337 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3469\n",
      "Epoch 75/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1484 - f1_loss: 0.3748 - val_loss: 0.5343 - val_binary_crossentropy: 0.5343 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3361 - val_mean_squared_error: 0.1763 - val_f1_loss: 0.3484\n",
      "Epoch 76/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4559 - binary_crossentropy: 0.4559 - binary_accuracy: 0.7849 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1483 - f1_loss: 0.3742 - val_loss: 0.5355 - val_binary_crossentropy: 0.5355 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3335 - val_mean_squared_error: 0.1768 - val_f1_loss: 0.3468\n",
      "Epoch 77/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1485 - f1_loss: 0.3746 - val_loss: 0.5358 - val_binary_crossentropy: 0.5358 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3342 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3473\n",
      "Epoch 78/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4572 - binary_crossentropy: 0.4572 - binary_accuracy: 0.7840 - mean_absolute_error: 0.2968 - mean_squared_error: 0.1488 - f1_loss: 0.3753 - val_loss: 0.5368 - val_binary_crossentropy: 0.5368 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1772 - val_f1_loss: 0.3466\n",
      "Epoch 79/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1485 - f1_loss: 0.3750 - val_loss: 0.5339 - val_binary_crossentropy: 0.5339 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3375 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3494\n",
      "Epoch 80/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1485 - f1_loss: 0.3747 - val_loss: 0.5421 - val_binary_crossentropy: 0.5421 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1788 - val_f1_loss: 0.3473\n",
      "Epoch 81/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4566 - binary_crossentropy: 0.4566 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1485 - f1_loss: 0.3747 - val_loss: 0.5351 - val_binary_crossentropy: 0.5351 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3481\n",
      "Epoch 82/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4556 - binary_crossentropy: 0.4556 - binary_accuracy: 0.7851 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1481 - f1_loss: 0.3747 - val_loss: 0.5360 - val_binary_crossentropy: 0.5360 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3354 - val_mean_squared_error: 0.1768 - val_f1_loss: 0.3481\n",
      "Epoch 83/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7850 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1484 - f1_loss: 0.3744 - val_loss: 0.5372 - val_binary_crossentropy: 0.5372 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3456\n",
      "Epoch 84/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4567 - binary_crossentropy: 0.4567 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2963 - mean_squared_error: 0.1485 - f1_loss: 0.3748 - val_loss: 0.5361 - val_binary_crossentropy: 0.5361 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3334 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3467\n",
      "Epoch 85/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4570 - binary_crossentropy: 0.4570 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1486 - f1_loss: 0.3745 - val_loss: 0.5380 - val_binary_crossentropy: 0.5380 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3351 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3481\n",
      "Epoch 86/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4551 - binary_crossentropy: 0.4551 - binary_accuracy: 0.7860 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1479 - f1_loss: 0.3743 - val_loss: 0.5353 - val_binary_crossentropy: 0.5353 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1768 - val_f1_loss: 0.3472\n",
      "Epoch 87/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4571 - binary_crossentropy: 0.4571 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1488 - f1_loss: 0.3748 - val_loss: 0.5344 - val_binary_crossentropy: 0.5344 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3332 - val_mean_squared_error: 0.1760 - val_f1_loss: 0.3462\n",
      "Epoch 88/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4570 - binary_crossentropy: 0.4570 - binary_accuracy: 0.7842 - mean_absolute_error: 0.2966 - mean_squared_error: 0.1487 - f1_loss: 0.3746 - val_loss: 0.5339 - val_binary_crossentropy: 0.5339 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3346 - val_mean_squared_error: 0.1762 - val_f1_loss: 0.3473\n",
      "Epoch 89/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2964 - mean_squared_error: 0.1486 - f1_loss: 0.3746 - val_loss: 0.5359 - val_binary_crossentropy: 0.5359 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3355 - val_mean_squared_error: 0.1764 - val_f1_loss: 0.3480\n",
      "Epoch 90/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4558 - binary_crossentropy: 0.4558 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1483 - f1_loss: 0.3744 - val_loss: 0.5355 - val_binary_crossentropy: 0.5355 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3348 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3475\n",
      "Epoch 91/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4568 - binary_crossentropy: 0.4568 - binary_accuracy: 0.7843 - mean_absolute_error: 0.2965 - mean_squared_error: 0.1487 - f1_loss: 0.3748 - val_loss: 0.5347 - val_binary_crossentropy: 0.5347 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3480\n",
      "Epoch 92/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4554 - binary_crossentropy: 0.4554 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2957 - mean_squared_error: 0.1481 - f1_loss: 0.3740 - val_loss: 0.5387 - val_binary_crossentropy: 0.5387 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3344 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3475\n",
      "Epoch 93/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4553 - binary_crossentropy: 0.4553 - binary_accuracy: 0.7852 - mean_absolute_error: 0.2956 - mean_squared_error: 0.1481 - f1_loss: 0.3745 - val_loss: 0.5389 - val_binary_crossentropy: 0.5389 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3340 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3474\n",
      "Epoch 94/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4565 - binary_crossentropy: 0.4565 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2960 - mean_squared_error: 0.1485 - f1_loss: 0.3741 - val_loss: 0.5477 - val_binary_crossentropy: 0.5477 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3320 - val_mean_squared_error: 0.1801 - val_f1_loss: 0.3463\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1485 - f1_loss: 0.3742 - val_loss: 0.5350 - val_binary_crossentropy: 0.5350 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3353 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3477\n",
      "Epoch 96/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4564 - binary_crossentropy: 0.4564 - binary_accuracy: 0.7846 - mean_absolute_error: 0.2961 - mean_squared_error: 0.1484 - f1_loss: 0.3738 - val_loss: 0.5352 - val_binary_crossentropy: 0.5352 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1765 - val_f1_loss: 0.3475\n",
      "Epoch 97/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4560 - binary_crossentropy: 0.4560 - binary_accuracy: 0.7853 - mean_absolute_error: 0.2958 - mean_squared_error: 0.1483 - f1_loss: 0.3741 - val_loss: 0.5401 - val_binary_crossentropy: 0.5401 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3328 - val_mean_squared_error: 0.1779 - val_f1_loss: 0.3464\n",
      "Epoch 98/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4554 - binary_crossentropy: 0.4554 - binary_accuracy: 0.7854 - mean_absolute_error: 0.2954 - mean_squared_error: 0.1481 - f1_loss: 0.3738 - val_loss: 0.5374 - val_binary_crossentropy: 0.5374 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3331 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3463\n",
      "Epoch 99/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4562 - binary_crossentropy: 0.4562 - binary_accuracy: 0.7845 - mean_absolute_error: 0.2959 - mean_squared_error: 0.1484 - f1_loss: 0.3744 - val_loss: 0.5363 - val_binary_crossentropy: 0.5363 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3341 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3470\n",
      "Epoch 100/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4563 - binary_crossentropy: 0.4563 - binary_accuracy: 0.7848 - mean_absolute_error: 0.2962 - mean_squared_error: 0.1484 - f1_loss: 0.3743 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3350 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3478\n",
      "fertig RASCH 1 binary_crossentropy loss\n",
      "None :F1s v/t  0.6881967772299047 0.718088215457938 0.7253275109170306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d57a25e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7225628465601508\n",
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7230908474427966\n",
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7240811485037297\n",
      "RASCH1//(xe/px)#1000000 None None \t\t 0.7253275109170306\n",
      "GO FOR RASCH1//(xe/px)#1000000\n",
      "checking for cached file ./lfa_models/RASCH1~~(xe~px)#1000000_4\n",
      "./lfa_models/RASCH1~~(xe~px)#1000000_4 found\n",
      "class weights: [2.67326092 1.        ]\n",
      "class weights (dict): {0: 2.6732609156777154, 1: 1.0}\n",
      "nq, ns\n",
      "1130 2512\n",
      "Using univariate Rasch model!\n",
      "TRAINING:\n",
      "Unique students: 2512\n",
      "Unique questions: 1130\n",
      "Total activity: 658050 ( 478904.0 )\n",
      "ov shape (658050, 1130) (1254, 1130)\n",
      "monitoring info loss min\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "psi_select (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hit_counter (InputLayer)        [(None, 1130)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gammas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "alphas (Embedding)              (None, 1, 1)         2512        psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qk_loadings (Dense)             (None, 1)            1130        hit_counter[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 1)            0           gammas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "q_select (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 1)            0           alphas[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 1)            0           qk_loadings[0][0]                \n",
      "                                                                 flatten_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "qn_embedding (Embedding)        (None, 1, 1)         1130        q_select[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1)            0           flatten_35[0][0]                 \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 1)            0           qn_embedding[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_11 (Subtract)          (None, 1)            0           add_11[0][0]                     \n",
      "                                                                 flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           subtract_11[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 7,284\n",
      "Trainable params: 7,284\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "fitting\n",
      "Epoch 1/100\n",
      "2057/2057 [==============================] - 11s 4ms/step - loss: 0.5873 - binary_crossentropy: 0.5873 - binary_accuracy: 0.7038 - mean_absolute_error: 0.4144 - mean_squared_error: 0.2006 - f1_loss: 0.4812 - val_loss: 0.6096 - val_binary_crossentropy: 0.6096 - val_binary_accuracy: 0.6611 - val_mean_absolute_error: 0.3991 - val_mean_squared_error: 0.2110 - val_f1_loss: 0.4262\n",
      "Epoch 2/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4965 - binary_crossentropy: 0.4965 - binary_accuracy: 0.7649 - mean_absolute_error: 0.3447 - mean_squared_error: 0.1624 - f1_loss: 0.4296 - val_loss: 0.5651 - val_binary_crossentropy: 0.5651 - val_binary_accuracy: 0.7073 - val_mean_absolute_error: 0.3746 - val_mean_squared_error: 0.1923 - val_f1_loss: 0.3946\n",
      "Epoch 3/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4774 - binary_crossentropy: 0.4774 - binary_accuracy: 0.7760 - mean_absolute_error: 0.3260 - mean_squared_error: 0.1554 - f1_loss: 0.4094 - val_loss: 0.5481 - val_binary_crossentropy: 0.5481 - val_binary_accuracy: 0.7209 - val_mean_absolute_error: 0.3593 - val_mean_squared_error: 0.1850 - val_f1_loss: 0.3769\n",
      "Epoch 4/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4718 - binary_crossentropy: 0.4718 - binary_accuracy: 0.7781 - mean_absolute_error: 0.3177 - mean_squared_error: 0.1536 - f1_loss: 0.3992 - val_loss: 0.5364 - val_binary_crossentropy: 0.5364 - val_binary_accuracy: 0.7297 - val_mean_absolute_error: 0.3533 - val_mean_squared_error: 0.1796 - val_f1_loss: 0.3673\n",
      "Epoch 5/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4676 - binary_crossentropy: 0.4676 - binary_accuracy: 0.7795 - mean_absolute_error: 0.3122 - mean_squared_error: 0.1523 - f1_loss: 0.3927 - val_loss: 0.5409 - val_binary_crossentropy: 0.5409 - val_binary_accuracy: 0.7249 - val_mean_absolute_error: 0.3482 - val_mean_squared_error: 0.1814 - val_f1_loss: 0.3632\n",
      "Epoch 6/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4655 - binary_crossentropy: 0.4655 - binary_accuracy: 0.7808 - mean_absolute_error: 0.3088 - mean_squared_error: 0.1515 - f1_loss: 0.3893 - val_loss: 0.5354 - val_binary_crossentropy: 0.5354 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3463 - val_mean_squared_error: 0.1794 - val_f1_loss: 0.3600\n",
      "Epoch 7/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4647 - binary_crossentropy: 0.4647 - binary_accuracy: 0.7803 - mean_absolute_error: 0.3073 - mean_squared_error: 0.1514 - f1_loss: 0.3871 - val_loss: 0.5383 - val_binary_crossentropy: 0.5383 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3421 - val_mean_squared_error: 0.1799 - val_f1_loss: 0.3569\n",
      "Epoch 8/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4639 - binary_crossentropy: 0.4639 - binary_accuracy: 0.7813 - mean_absolute_error: 0.3057 - mean_squared_error: 0.1511 - f1_loss: 0.3860 - val_loss: 0.5376 - val_binary_crossentropy: 0.5376 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3420 - val_mean_squared_error: 0.1794 - val_f1_loss: 0.3561\n",
      "Epoch 9/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4642 - binary_crossentropy: 0.4642 - binary_accuracy: 0.7807 - mean_absolute_error: 0.3051 - mean_squared_error: 0.1512 - f1_loss: 0.3848 - val_loss: 0.5313 - val_binary_crossentropy: 0.5313 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3412 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3539\n",
      "Epoch 10/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4632 - binary_crossentropy: 0.4632 - binary_accuracy: 0.7812 - mean_absolute_error: 0.3042 - mean_squared_error: 0.1508 - f1_loss: 0.3835 - val_loss: 0.5338 - val_binary_crossentropy: 0.5338 - val_binary_accuracy: 0.7289 - val_mean_absolute_error: 0.3401 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3531\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4631 - binary_crossentropy: 0.4631 - binary_accuracy: 0.7808 - mean_absolute_error: 0.3040 - mean_squared_error: 0.1509 - f1_loss: 0.3828 - val_loss: 0.5310 - val_binary_crossentropy: 0.5310 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3404 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3528\n",
      "Epoch 12/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4620 - binary_crossentropy: 0.4620 - binary_accuracy: 0.7820 - mean_absolute_error: 0.3030 - mean_squared_error: 0.1504 - f1_loss: 0.3822 - val_loss: 0.5330 - val_binary_crossentropy: 0.5330 - val_binary_accuracy: 0.7360 - val_mean_absolute_error: 0.3406 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3530\n",
      "Epoch 13/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4617 - binary_crossentropy: 0.4617 - binary_accuracy: 0.7821 - mean_absolute_error: 0.3024 - mean_squared_error: 0.1503 - f1_loss: 0.3817 - val_loss: 0.5345 - val_binary_crossentropy: 0.5345 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3392 - val_mean_squared_error: 0.1780 - val_f1_loss: 0.3524\n",
      "Epoch 14/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4612 - binary_crossentropy: 0.4612 - binary_accuracy: 0.7824 - mean_absolute_error: 0.3018 - mean_squared_error: 0.1501 - f1_loss: 0.3814 - val_loss: 0.5310 - val_binary_crossentropy: 0.5310 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3379 - val_mean_squared_error: 0.1766 - val_f1_loss: 0.3507\n",
      "Epoch 15/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4618 - binary_crossentropy: 0.4618 - binary_accuracy: 0.7822 - mean_absolute_error: 0.3020 - mean_squared_error: 0.1503 - f1_loss: 0.3814 - val_loss: 0.5351 - val_binary_crossentropy: 0.5351 - val_binary_accuracy: 0.7376 - val_mean_absolute_error: 0.3374 - val_mean_squared_error: 0.1776 - val_f1_loss: 0.3509\n",
      "Epoch 16/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4608 - binary_crossentropy: 0.4608 - binary_accuracy: 0.7828 - mean_absolute_error: 0.3012 - mean_squared_error: 0.1499 - f1_loss: 0.3806 - val_loss: 0.5340 - val_binary_crossentropy: 0.5340 - val_binary_accuracy: 0.7321 - val_mean_absolute_error: 0.3383 - val_mean_squared_error: 0.1773 - val_f1_loss: 0.3512\n",
      "Epoch 17/100\n",
      "2057/2057 [==============================] - 8s 3ms/step - loss: 0.4602 - binary_crossentropy: 0.4602 - binary_accuracy: 0.7832 - mean_absolute_error: 0.3008 - mean_squared_error: 0.1497 - f1_loss: 0.3802 - val_loss: 0.5379 - val_binary_crossentropy: 0.5379 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3382 - val_mean_squared_error: 0.1787 - val_f1_loss: 0.3515\n",
      "Epoch 18/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4602 - binary_crossentropy: 0.4602 - binary_accuracy: 0.7828 - mean_absolute_error: 0.3008 - mean_squared_error: 0.1498 - f1_loss: 0.3799 - val_loss: 0.5339 - val_binary_crossentropy: 0.5339 - val_binary_accuracy: 0.7305 - val_mean_absolute_error: 0.3378 - val_mean_squared_error: 0.1770 - val_f1_loss: 0.3506\n",
      "Epoch 19/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4600 - binary_crossentropy: 0.4600 - binary_accuracy: 0.7829 - mean_absolute_error: 0.3008 - mean_squared_error: 0.1497 - f1_loss: 0.3796 - val_loss: 0.5365 - val_binary_crossentropy: 0.5365 - val_binary_accuracy: 0.7352 - val_mean_absolute_error: 0.3372 - val_mean_squared_error: 0.1781 - val_f1_loss: 0.3507\n",
      "Epoch 20/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4606 - binary_crossentropy: 0.4606 - binary_accuracy: 0.7829 - mean_absolute_error: 0.3007 - mean_squared_error: 0.1499 - f1_loss: 0.3796 - val_loss: 0.5343 - val_binary_crossentropy: 0.5343 - val_binary_accuracy: 0.7344 - val_mean_absolute_error: 0.3373 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3504\n",
      "Epoch 21/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4596 - binary_crossentropy: 0.4596 - binary_accuracy: 0.7829 - mean_absolute_error: 0.3003 - mean_squared_error: 0.1496 - f1_loss: 0.3785 - val_loss: 0.5429 - val_binary_crossentropy: 0.5429 - val_binary_accuracy: 0.7313 - val_mean_absolute_error: 0.3363 - val_mean_squared_error: 0.1797 - val_f1_loss: 0.3509\n",
      "Epoch 22/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4608 - binary_crossentropy: 0.4608 - binary_accuracy: 0.7827 - mean_absolute_error: 0.3006 - mean_squared_error: 0.1500 - f1_loss: 0.3796 - val_loss: 0.5366 - val_binary_crossentropy: 0.5366 - val_binary_accuracy: 0.7329 - val_mean_absolute_error: 0.3369 - val_mean_squared_error: 0.1775 - val_f1_loss: 0.3501\n",
      "Epoch 23/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4591 - binary_crossentropy: 0.4591 - binary_accuracy: 0.7841 - mean_absolute_error: 0.2994 - mean_squared_error: 0.1494 - f1_loss: 0.3789 - val_loss: 0.5388 - val_binary_crossentropy: 0.5388 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3364 - val_mean_squared_error: 0.1781 - val_f1_loss: 0.3501\n",
      "Epoch 24/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4595 - binary_crossentropy: 0.4595 - binary_accuracy: 0.7833 - mean_absolute_error: 0.2997 - mean_squared_error: 0.1495 - f1_loss: 0.3787 - val_loss: 0.5332 - val_binary_crossentropy: 0.5332 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3367 - val_mean_squared_error: 0.1763 - val_f1_loss: 0.3492\n",
      "Epoch 25/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4591 - binary_crossentropy: 0.4591 - binary_accuracy: 0.7834 - mean_absolute_error: 0.2994 - mean_squared_error: 0.1494 - f1_loss: 0.3781 - val_loss: 0.5372 - val_binary_crossentropy: 0.5372 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3367 - val_mean_squared_error: 0.1777 - val_f1_loss: 0.3499\n",
      "Epoch 26/100\n",
      "2057/2057 [==============================] - 9s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7831 - mean_absolute_error: 0.2995 - mean_squared_error: 0.1495 - f1_loss: 0.3783 - val_loss: 0.5318 - val_binary_crossentropy: 0.5318 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3358 - val_mean_squared_error: 0.1759 - val_f1_loss: 0.3485\n",
      "Epoch 27/100\n",
      "2057/2057 [==============================] - 9s 3ms/step - loss: 0.4584 - binary_crossentropy: 0.4584 - binary_accuracy: 0.7835 - mean_absolute_error: 0.2988 - mean_squared_error: 0.1491 - f1_loss: 0.3775 - val_loss: 0.5335 - val_binary_crossentropy: 0.5335 - val_binary_accuracy: 0.7368 - val_mean_absolute_error: 0.3357 - val_mean_squared_error: 0.1763 - val_f1_loss: 0.3486\n",
      "Epoch 28/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4578 - binary_crossentropy: 0.4578 - binary_accuracy: 0.7844 - mean_absolute_error: 0.2986 - mean_squared_error: 0.1489 - f1_loss: 0.3776 - val_loss: 0.5279 - val_binary_crossentropy: 0.5279 - val_binary_accuracy: 0.7384 - val_mean_absolute_error: 0.3365 - val_mean_squared_error: 0.1747 - val_f1_loss: 0.3480\n",
      "Epoch 29/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4584 - binary_crossentropy: 0.4584 - binary_accuracy: 0.7839 - mean_absolute_error: 0.2988 - mean_squared_error: 0.1491 - f1_loss: 0.3778 - val_loss: 0.5358 - val_binary_crossentropy: 0.5358 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3347 - val_mean_squared_error: 0.1769 - val_f1_loss: 0.3482\n",
      "Epoch 30/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7832 - mean_absolute_error: 0.2990 - mean_squared_error: 0.1494 - f1_loss: 0.3775 - val_loss: 0.5365 - val_binary_crossentropy: 0.5365 - val_binary_accuracy: 0.7337 - val_mean_absolute_error: 0.3352 - val_mean_squared_error: 0.1771 - val_f1_loss: 0.3487\n",
      "Epoch 31/100\n",
      "2057/2057 [==============================] - 10s 4ms/step - loss: 0.4594 - binary_crossentropy: 0.4594 - binary_accuracy: 0.7833 - mean_absolute_error: 0.2992 - mean_squared_error: 0.1495 - f1_loss: 0.3777 - val_loss: 0.5305 - val_binary_crossentropy: 0.5305 - val_binary_accuracy: 0.7392 - val_mean_absolute_error: 0.3356 - val_mean_squared_error: 0.1754 - val_f1_loss: 0.3479\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 936/2057 [============>.................] - ETA: 4s - loss: 0.4591 - binary_crossentropy: 0.4591 - binary_accuracy: 0.7828 - mean_absolute_error: 0.2991 - mean_squared_error: 0.1494 - f1_loss: 0.3770"
     ]
    }
   ],
   "source": [
    "#RESET\n",
    "model_lookup = {} #defaultdict(list)\n",
    "max_acc = 0\n",
    "handles = []\n",
    "\n",
    "from keras.metrics import binary_accuracy, binary_crossentropy, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "import os\n",
    "mon_lookup = {\n",
    "    \"binary_crossentropy\" : \"xe\",\n",
    "    \"mean_squared_error\"  : \"mse\",\n",
    "    \"mean_absolute_error\" : \"mae\",\n",
    "    \"f1_loss\" : \"f1\",\n",
    "    \"binary_accuracy\" : \"acc\",\n",
    "    \"log_likelihood\" : \"ll\",\n",
    "    \"loss\" : \"px\"\n",
    "}\n",
    "\n",
    "# max_s = 250000\n",
    "print(\"max_s\", max_s)\n",
    "\n",
    "\n",
    "def step_through_cog_models(data_bundle=None, cog_models=None):\n",
    "# def step_through_cog_models(sixs, qixs, hout, cog_models=None, data_bundle=None):\n",
    "#     cog_models = [\"MLP\", \"MLP+\",\"MLTM\",\"LFA\",\"SLFA\"]\n",
    "#     cog_models = [\"MLP\", \"MLP+\",\"MLTM\", \"MLTM+\", \"MLTM_no_init\"]\n",
    "#     cog_models = [\"MLP\", \"MLP+\",\"MLTM\", \"MLTM+\", \"LFA\",\"SLFA\"]\n",
    "    #(\"MLTM+\",32,10,\"val_f1_m\",False)\n",
    "    metrics = [binary_crossentropy, binary_accuracy, mean_absolute_error, mean_squared_error, f1_loss]\n",
    "\n",
    "    if cog_models is None:\n",
    "        core_models = [\"CFM\", \"RASCH\", \"AFM\", \"MLTM\"]\n",
    "        variant_models = [\"AFMg\", \"MLTMb\", \"MLTM0\"]\n",
    "#         ffnn_models = [\"MLPs\", \"MLPsz\"] #\"MLP\", \"MLPd\"]#, \"CONC\"]\n",
    "        ffnn_models = [\"MLPs\", \"MLP\", \"MLPd\"]#, \"CONC\"]\n",
    "        regd_models = [s+\"z\" for s in [\"MLTM\",\"MLP\",\"MLPd\",\"AFM\",\"AFMg\",\"CFM\",\"MLTMb\",\"MLTM0\"]]\n",
    "#         cog_models = variant_models\n",
    "        cog_models = regd_models\n",
    "#         cog_models = [\"AFM\", \"AFMg\", \"AFMx\", \"MLTM\", \"MLTMa\",\"MLTMb\", \"CFM\", \"MLP\", \"MLPd\"]\n",
    "#         cog_models = [\"MLTMz\"] #\"MLTMb\", \"MLP\", \"CFM\", \"RASCH\", \"AFM\", \"AFMg\", \"AFMx\", \"MLTM\", \"MLTMa\",\"MLTMb\",\"MLTM0\", \"MLP\", \"MLPd\"]\n",
    "#         cog_models = [\"AFMg\"]\n",
    "#         cog_models = [\"MLTMz\"]#,\"AFMg\"]\n",
    "        cog_models = [\"RASCH\"]\n",
    "#         cog_models = [\"MLTMb\",\"MLTMbz\",\"MLTM0\",\"MLTM0z\"]\n",
    "#         cog_models = [\"MLPrawDen\", \"MLPrawDP\"]#, \"MLPrawAD\", \"MLPrawADD\"]\n",
    "#         cog_models = ffnn_models\n",
    "#         emb_ws = [400,300,256,128,64,32,16, 8]\n",
    "        emb_ws = [ 64, ]#, 32, 64]\n",
    "#         emb_ws = [24, 32]\n",
    "#         emb_ws = [32, 64, 128]\n",
    "#         emb_ws = [96]# 32, 64, 96]\n",
    "#         emb_ws = [8,16,32, 64,128]#, 256, 300, 400]\n",
    "#         emb_ws = [32,64,128,256,300,400,500]\n",
    "\n",
    "#         emb_ws = [8,]#, 16, 32, 64, 128, 256, 300, 400,]\n",
    "\n",
    "#         q_ws = [None]\n",
    "#         losses = [\"binary_crossentropy\",\"mean_squared_error\",\"f1_loss\"]#, \"binary_crossentropy\"]\n",
    "#         losses = [(\"binary_crossentropy\", \"val_loss\")]\n",
    "        losses = [\n",
    "                    (\"binary_crossentropy\", \"val_loss\"), \n",
    "#                   (\"binary_crossentropy\", \"val_f1_loss\"), \n",
    "#                   (\"mean_squared_error\", \"val_loss\"),\n",
    "#                   (\"f1_loss\", \"val_f1_loss\")\n",
    "                 ]\n",
    "#         losses = [(\"f1_loss\", \"val_f1_loss\")]\n",
    "        q_ws = [None]\n",
    "\n",
    "#         reg_ws = numpy.random.normal(loc=1e-5, scale=1e-5, size=20) # [1e-8, 1e-7, 1e-6, 0.00001]#, 0.0001, 0.001]\n",
    "        reg_ws = [None]\n",
    "#         reg_ws = [None, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "#         monitor_settings = [\"val_mean_absolute_error\", \"val_mean_squared_error\"]\n",
    "#         monitor_settings = [\"val_loss\", \"val_f1_m\", \"val_mean_squared_error\"]\n",
    "        balance_settings = [ False, ]\n",
    "#         q_ws = [None, 1, 5, 10, 50, 100, 500]\n",
    "#         q_ws = [None,1,10,100,1000]\n",
    "#     emb_ws = [14, ]# [1,2,4,6,8,10,12,14,16]\n",
    "#     emb_ws = [1,2,4,6,8,10,12,14,16]\n",
    "    n_reps = 5\n",
    "\n",
    "    payload = []\n",
    "        \n",
    "\n",
    "    seen=[]\n",
    "    \n",
    "    \n",
    "    odata, vdata, tdata, sid_six_lookup, qid_qix_lookup = data_bundle\n",
    "    (o_sixs, o_qixs, o_hits, o_out), (v_sixs, v_qixs, v_hits, v_out), (t_sixs, t_qixs, t_hits, t_out) = (odata, vdata, tdata)\n",
    "    o_hits = o_hits.astype(\"int8\")\n",
    "    \n",
    "    print(len(v_out), sum(v_out))\n",
    "    print(len(t_out), sum(t_out))\n",
    "#     raise Exception(\"le what\")\n",
    "    \n",
    "    f1s = []\n",
    "    overwrite_disc=True\n",
    "    for rep in range(n_reps):\n",
    "        for cog_model in cog_models:# zip(cog_models, q_ws):\n",
    "            for w in emb_ws:\n",
    "                if cog_model==\"RASCH\":\n",
    "                    w=1\n",
    "                for qw in q_ws:\n",
    "                    for rw in reg_ws:\n",
    "                        w0 = rw\n",
    "                        for bal in balance_settings:\n",
    "                            for lozz,mon in losses:\n",
    "                                best_f1_regw = (0,0)\n",
    "#                                 rw = None #rw / (w*n_students)\n",
    "                                #w1 = rw if (rw is not None) else None\n",
    "#                                 w1 = 5.5e-8\n",
    "                                w1 = rw\n",
    "    \n",
    "#                                 if max_w = None:\n",
    "#                                     max_w = (rw, 0)                \n",
    "#                                 w1s = numpy.random.normal(max_w[0], scale=w1, size=10)\n",
    "                    \n",
    "                                qcode = \"\" if (qw is None) else \"q\"+str(qw)\n",
    "                                moncode = mon_lookup[mon[mon.index(\"_\")+1:]]\n",
    "                                losscode = mon_lookup[lozz]\n",
    "                                balstr = \"bal\" if bal else \"\"\n",
    "                                \n",
    "                                handle = \"{}{}/{}/{}({}/{})\".format(cog_model, w, qcode, balstr, losscode, moncode)\n",
    "                                memkey = handle+str(w1)\n",
    "                                if max_s != 100000:\n",
    "                                    handle += \"#\"+str(max_s)\n",
    "                                print(\"GO FOR\", handle)\n",
    "                                \n",
    "                                fn = home+\"/lfa_models/\" + handle.replace(\"/\",\"~\") + \"_\" + str(rep)\n",
    "                                \n",
    "                                print(\"checking for cached file\", fn)\n",
    "                                if os.path.isfile(fn):\n",
    "                                    print(fn, \"found\")\n",
    "#                                     continue         \n",
    "                                \n",
    "                                m, h, config_dict = gen_and_train(odata, vdata, tdata, draw=True, cog_model=cog_model, emb_w=w, q_weight=qw, monitor=mon, balance_classes=bal, loss=lozz, metrics=metrics, reg_w=w1)\n",
    "#                                 m.summary()\n",
    "#                                 t_sixs, t_qixs, t_hits, _ = t_data\n",
    "#                                 o_sixs, o_qixs, o_hits, _ = o_data\n",
    "\n",
    "                                op_hats = numpy.round( m.predict( [o_qixs, o_sixs, o_hits] ) )\n",
    "                                op_trues = numpy.round(o_out)    \n",
    "                                o_f1 = f1_score(op_trues, op_hats, average=\"macro\")\n",
    "\n",
    "                                vp_hats = numpy.round( m.predict( [v_qixs, v_sixs, v_hits] ) )\n",
    "                                vp_trues = numpy.round(v_out)    \n",
    "                                v_f1 = f1_score(vp_trues, vp_hats, average=\"macro\")\n",
    "    \n",
    "                                p_hats = numpy.round( m.predict( [t_qixs, t_sixs, t_hits] ) )\n",
    "                                p_trues = numpy.round(t_out)    \n",
    "                                t_f1 = f1_score(p_trues, p_hats, average=\"macro\")\n",
    "                \n",
    "#                                 if t_f1 > max_w[1]:\n",
    "#                                     max_w = (w1,t_f1)\n",
    "                \n",
    "                                print(w1, \":F1s v/t \", o_f1, v_f1, t_f1)\n",
    "                                f1s.append((handle, w0, w1, v_f1, t_f1))\n",
    "                \n",
    "                                config_dict[\"q_weight\"]=qw\n",
    "                                config_dict[\"monitor_value\"]=mon\n",
    "                                config_dict[\"balance_classes\"]=bal\n",
    "                                config_dict[\"loss\"]=lozz\n",
    "                                \n",
    "                                config_dict[\"handle\"] = handle\n",
    "                                \n",
    "                                payload.append( (config_dict, _, _) )\n",
    "                                \n",
    "                                plt.plot(h.history['loss'], label='xH (trn)')\n",
    "                                plt.plot(h.history['val_loss'], label='xH (val)')\n",
    "                                plt.plot(h.history['f1_loss'], label='F1L (trn)')\n",
    "                                plt.plot(h.history['val_f1_loss'], label='F1L (val)')\n",
    "                                plt.title(handle)\n",
    "#                                 plt.ylabel('MAE value')\n",
    "#                                 plt.xlabel('No. epoch')\n",
    "                                plt.legend(loc=\"upper right\")\n",
    "                                plt.show()\n",
    "                                \n",
    "                                if overwrite_disc:\n",
    "                                    try:\n",
    "                                        m.save(home+\"/lfa_models/\" + handle.replace(\"/\",\"~\") + \"_\" + str(rep), save_format=\"h5\")\n",
    "                                    except OSError as ose:\n",
    "                                        print(ose)\n",
    "                                        import shutil\n",
    "                                        shutil.rmtree(fn)\n",
    "                                        m.save(home+\"/lfa_models/\" + handle.replace(\"/\",\"~\") + \"_\" + str(rep), save_format=\"h5\")\n",
    "                                                                \n",
    "        for h, ww,w,v,t in f1s:\n",
    "    #         print(h, ww,w,\"\\t\", v,\"\\t\", t)\n",
    "            print(h, ww,w,\"\\t\\t\", t)\n",
    "\n",
    "    mn = numpy.median([tup[4] for tup in f1s])\n",
    "    mae = numpy.mean([numpy.abs(tup[4]-mn) for tup in f1s])\n",
    "    print(mn, mae)\n",
    "    \n",
    "    return payload, data_bundle\n",
    "\n",
    "#########################################\n",
    "\n",
    "# try:\n",
    "#     del data_bundle\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     data_bundle\n",
    "#     print(\"DATA FOUJND\")\n",
    "#     (sixs, qixs, hout) = (None, None, None)\n",
    "# except:\n",
    "#     data_bundle = None\n",
    "# (sixs, qixs, hout) = pickle.load(open(home+\"/real_data/XL1041.p\", \"rb\"))\n",
    "    \n",
    "\n",
    "history_results, data_bundle = step_through_cog_models(data_bundle=data_bundle)\n",
    "(o_data, v_data, t_data, sid_six_lookup, qid_qix_lookup) = data_bundle\n",
    "\n",
    "(o_sixs, o_qixs, o_hits, o_out), (v_sixs, v_qixs, v_hits, v_out), (t_sixs, t_qixs, t_hits, t_out) = (o_data, v_data, t_data)\n",
    "print(numpy.array(o_hits).shape)\n",
    "print(numpy.array(v_hits).shape)\n",
    "print(numpy.array(t_hits).shape)\n",
    "\n",
    "print(\"DATAGEN DONE\")\n",
    "print(max(o_qixs), max(v_qixs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f1_kde={}\n",
    "# acc_kde={}\n",
    "# upto=10\n",
    "# for h in seen:\n",
    "#     print(h)\n",
    "#     pears = numpy.array(agg[h])\n",
    "#     f1s = [p[0] for p in pears]\n",
    "#     mu_f1 = numpy.mean(f1s)\n",
    "#     accs = [p[1] for p in pears]\n",
    "#     mu_acc = numpy.mean(accs)\n",
    "#     print(h, len(pears))\n",
    "#     print(pears)\n",
    "# #     print(av_f1, av_acc)\n",
    "#     print(\"\\t\", numpy.round(mu_f1,4), numpy.round(mu_acc,4))\n",
    "#     f1_kde[h] = f1s[0:upto]\n",
    "#     acc_kde[h] = accs[0:upto]\n",
    "\n",
    "# print(\"Plot of resultant F1 score\")\n",
    "# # print(f1_kde)\n",
    "# for row in f1_kde:\n",
    "#     print(row)\n",
    "# ax1 = pandas.DataFrame(f1_kde).plot.kde(bw_method=.8, figsize=(8,8))\n",
    "# ax1.set_xlabel(\"$F_{1}$\")\n",
    "# ax1.set_title(\"Distribution of prediction $F_{1}$ across models\")\n",
    "\n",
    "# print(\"Plot of resultant F1 score\")\n",
    "# print(acc_kde)\n",
    "# ax2 = pandas.DataFrame(acc_kde).plot.kde(bw_method=.8, figsize=(8,8))\n",
    "# ax2.set_xlabel(\"Accuracy\")\n",
    "# ax2.set_title(\"Distribution of prediction accuracy across models\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Longitudinal_Datagen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
