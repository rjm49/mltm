{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from math import exp, sqrt, log\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import Input, Model\n",
    "from keras.layers import Lambda, subtract, concatenate\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "from random import random, shuffle, choice, randint\n",
    "\n",
    "from classes import Student, Question\n",
    "from utils import generate_student_name, create_qs, create_students, generate_attempts, calculate_pass_probability, attempt_q\n",
    "\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "from NN_utils import BigTable, WeightClip\n",
    "\n",
    "print(\"started\")\n",
    "\n",
    "use_saved = True\n",
    "do_train = True\n",
    "do_testing = True\n",
    "create_scorecards = True\n",
    "\n",
    "base = \"../../../isaac_data_files/\"\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "def gompertz(x, A,k1,k2,off):\n",
    "    return A*numpy.exp(-k1*numpy.exp(-k2*(x-off)))\n",
    "\n",
    "def inv_gompertz(y, A,k1,k2,off):\n",
    "    return off + numpy.log(k1/numpy.log(A/y))/k2\n",
    "\n",
    "def logistic(x, b,off):\n",
    "    return 1/(1+(numpy.exp(-b*(x-off))))\n",
    "\n",
    "# p = 1/(1+e(-x))\n",
    "# 1+e(-x) = 1/p\n",
    "# e(-x) = (1/p)-1\n",
    "# x = -log((1/p)-1)\n",
    "\n",
    "def inv_logistic(pr, b,off):\n",
    "    return off-(numpy.log((1/pr) -1))/b\n",
    "\n",
    "sigmoid = lambda z: 1/(1+(numpy.exp(-z)))\n",
    "def pr(a,d): return sigmoid((a-d))\n",
    "def pr_to_spread(p, comps=1, as_A_and_D=True):\n",
    "    per_comp_p = p**(1/comps)\n",
    "#     print(\"p         \", p)\n",
    "#     print(\"per comp p\", per_comp_p)\n",
    "#     spread = -numpy.log((1.0/per_comp_p)-1.0)\n",
    "    inv_sigmoid = lambda pr : ( -numpy.log((1/pr) -1) )\n",
    "    spread = inv_sigmoid(per_comp_p)\n",
    "#     print(\"spread    \", spread)\n",
    "    if as_A_and_D:\n",
    "        a = spread/2.0\n",
    "        d = -spread/2.0\n",
    "        return a,d\n",
    "    else:\n",
    "        return spread\n",
    "\n",
    "def spread_to_pr(sp, comps=1):\n",
    "    return numpy.power((1/(1+numpy.exp(-sp))), comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import uniform, random_integers\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "def gen_students(n_students, a0, a1, n_factors, gen_mode=\"truncnorm\"):\n",
    "    students = numpy.zeros((n_students, n_factors))\n",
    "    for six in range(n_students):\n",
    "#         true_comps = numpy.repeat(3, n_factors)\n",
    "        if gen_mode==\"truncnorm\":\n",
    "            true_comps = numpy.random.normal(a0, a1, size=n_factors)\n",
    "            true_comps = numpy.clip(true_comps,6,12)\n",
    "        elif gen_mode==\"uniform\":\n",
    "            clip0 = a0 - a1*3\n",
    "            clip1 = a0 + a1*3\n",
    "            true_comps = numpy.random.uniform(clip0, clip1, size=n_factors)\n",
    "        else:\n",
    "            print(\"unknown distro mode\")\n",
    "        print(\"True comps\", a0,a1, true_comps)\n",
    "#         true_comps = numpy.random.uniform(a0-3*a1, a0+3*a1, size=n_factors)\n",
    "#         true_comps = numpy.repeat(3, n_factors)\n",
    "        for cix,c in zip(range(n_factors), true_comps):\n",
    "            students[six,cix] = c\n",
    "    return students\n",
    "\n",
    "def gen_questions(n_questions, a0, a1, min_active_traits, max_active_traits, gen_mode=\"truncnorm\"):\n",
    "    #approximate the min and max outputs from the gaussian\n",
    "    inv_fn = spread_to_pr\n",
    "    av_c = (min_active_traits + max_active_traits)/2\n",
    "    p = numpy.linspace(0.001,0.999,30)\n",
    "    sprd = pr_to_spread(p, av_c, as_A_and_D=False)\n",
    "#     plt.scatter(sprd,p)\n",
    "#     plt.show()\n",
    "#     popt, pcov = curve_fit(inv_fn, p, sprd)\n",
    "#     print(popt)\n",
    "#     p = numpy.linspace(0.001,0.999,50)\n",
    "#     d = (p, comps=av_c)\n",
    "    p2 = spread_to_pr(sprd, av_c)\n",
    "    d50 = pr_to_spread(.5, av_c, as_A_and_D=False)\n",
    "    d99 = pr_to_spread(.999, av_c, as_A_and_D=False)\n",
    "    d00 = pr_to_spread(.001, av_c, as_A_and_D=False)\n",
    "    print(\"dvals\", d00, d50, d99)\n",
    "    print(\"inv_logistic curve\")\n",
    "    plt.scatter(sprd,p)\n",
    "    plt.plot(sprd,p2)\n",
    "    plt.show()\n",
    "    print(\"tru spread d50=\",d50, \"(prob={})\".format(spread_to_pr(d50, av_c)))\n",
    "    \n",
    "    minval = math.inf\n",
    "    \n",
    "    questions = numpy.zeros((n_questions, n_factors))\n",
    "    for qix in range(n_questions):\n",
    "        n_comps = random_integers(min_active_traits, max_active_traits)\n",
    "        print(\"NCOMPS\", n_comps)\n",
    "        comp_ixs = numpy.random.choice(range(n_factors), size=n_comps, replace=False)\n",
    "        \n",
    "        mu = a0\n",
    "        sd = a1\n",
    "        clip_a, clip_b = 0.0001,0.9999\n",
    "#         a, b = (clip_a - mu) / sd, (clip_b - mu) / sd\n",
    "#         standard_probs = scipy.stats.norm.rvs(loc=.5, scale=1/6, size=n_comps)\n",
    "        if gen_mode == \"u_uniform\":\n",
    "#             true_comps = numpy.random.uniform((mu-3*sd)-d99, (mu+3*sd)-d00, size=n_comps)\n",
    "            true_comps = numpy.random.uniform(mu-d99, mu-d00, size=n_comps)\n",
    "#             print(\"true q comps\", true_comps)\n",
    "        elif gen_mode == \"c50\":\n",
    "            true_comps = numpy.repeat(mu-d50, n_comps)\n",
    "        else:\n",
    "            standard_probs=[]\n",
    "            if gen_mode == \"truncnorm\":\n",
    "                standard_probs = numpy.random.normal(loc=0.5, scale=1/6, size=n_comps)\n",
    "                standard_probs = numpy.clip(standard_probs,clip_a,clip_b)\n",
    "            elif gen_mode == \"beta22\":\n",
    "                standard_probs = numpy.random.beta(2,2, size=n_comps)# normal(loc=.5, scale=1/6, size=n_comps)\n",
    "    #         standard_probs = truncnorm.rvs(clip_a, clip_b, loc=mu, scale=sd, size=n_comps)\n",
    "            elif gen_mode == \"uniform\":\n",
    "                standard_probs = numpy.random.uniform(clip_a, clip_b, size=n_comps)\n",
    "#         standard_probs = numpy.repeat(0.5, n_comps)\n",
    "            true_comps = a0 - pr_to_spread(standard_probs, comps=n_comps, as_A_and_D=False)\n",
    "            print(standard_probs,\"-->\",true_comps)\n",
    "        \n",
    "        this_min = min(true_comps)\n",
    "        if this_min < minval:\n",
    "            minval= this_min\n",
    "        \n",
    "#         plt.scatter(true_comps, standard_probs)\n",
    "#         plt.show()\n",
    "                \n",
    "#         print(\"Q comps\", true_comps)\n",
    "        for cix,c in zip(comp_ixs,true_comps):\n",
    "            questions[qix,cix] = c\n",
    "            \n",
    "        print(\"q minval is\", minval)\n",
    "        for cix,c in zip(comp_ixs,true_comps):\n",
    "            if questions[qix,cix] !=0:\n",
    "                questions[qix,cix] = questions[qix,cix]# - minval + 1\n",
    "    return questions, minval\n",
    "\n",
    "# minb,maxb,mina,maxa =(1.0, 11, 6, 11)\n",
    "def gen_run(n_traits, a0, a1, min_active_traits, max_active_traits, q_gen=\"uniform\"):\n",
    "    students = gen_students(n_students, a0, a1, n_factors)\n",
    "    questions, offset = gen_questions(n_questions, a0, a1, min_active_traits, max_active_traits, gen_mode=q_gen)\n",
    "\n",
    "    questions[questions>0] = questions[questions>0] - offset+6\n",
    "    students = students - offset+6\n",
    "    \n",
    "    sig = lambda z : 1/(1+numpy.exp(-z))\n",
    "    obs = numpy.zeros((len(students), len(questions)))\n",
    "    probs = numpy.zeros((len(students), len(questions)))\n",
    "    #obs = numpy.matmul(viewers, movies.T)/n_factors\n",
    "    vz = []\n",
    "    mz = []\n",
    "    scz =[]\n",
    "    for vi in range(len(students)):\n",
    "        for mi in range(len(questions)):\n",
    "            zmask = (questions[mi]==0).astype(int)\n",
    "            deltas = students[vi]-questions[mi]\n",
    "            prs = sig(deltas)\n",
    "            prs = numpy.maximum(zmask,prs)\n",
    "\n",
    "#             print(vi,mi)\n",
    "#             print(\"S\", students[vi])\n",
    "#             print(\"Q\", questions[mi])\n",
    "#             print(\"Z\", zmask)\n",
    "#             print(\"D\", deltas)\n",
    "#             print(\"p\", prs)\n",
    "#             print(\"P\", numpy.prod(prs))\n",
    "            pr = numpy.prod(prs)\n",
    "            obs[vi,mi] = (random.random() < pr)\n",
    "            probs[vi,mi] = numpy.prod(prs)\n",
    "#             print(vi,mi, numpy.prod(prs))\n",
    "    return obs, probs, students, questions\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_factors, a0, a1, min_active, max_active = (5, 9, 1, 1, 3)\n",
    "n_factors, a0, a1, min_active, max_active = (100, 9, 1, 1, 5)\n",
    "n_students = 100\n",
    "n_questions = 100\n",
    "\n",
    "# mind,maxd, a0,sda, n_factors = (1.0, 4.257960060005227, 4.492513201000301, 11.647587058653233, 100)\n",
    "\n",
    "# res =gen_run(n_factors, n_students, n_questions, a0, sda, min_active, max_active, None,None)\n",
    "obs, probz, students, questions  = gen_run(n_factors, a0, a1, min_active, max_active, q_gen=\"u_uniform\")\n",
    "# print(len(res))\n",
    "plt.hist(students.flatten(), alpha=0.5)\n",
    "plt.hist(questions.flatten(), alpha=0.5)\n",
    "plt.show()\n",
    "# print(numpy.mean(questions[questions>0]))\n",
    "\n",
    "plt.hist(probz.flatten())\n",
    "plt.show()\n",
    "\n",
    "print(obs.flatten())\n",
    "print(len(obs.flatten()), sum(obs.flatten()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = gen_students(100, 9, 1, 100)\n",
    "questions, minval = gen_questions(100, 9, 1, 1,5, gen_mode=\"uniform\")\n",
    "# plt.hist(questions.flatten())\n",
    "print(minval)\n",
    "q2 = questions\n",
    "q2[q2>0] = q2[q2>0] - minval +6\n",
    "s2 = students - minval +6\n",
    "plt.hist(q2.flatten(), alpha=0.5)\n",
    "plt.hist(s2.flatten(), alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1\n",
    "from keras.layers import Dropout, multiply, subtract, GaussianNoise, GaussianDropout\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "def generate_qs_model(qn_table, psi_table, optimiser, comp_lims=True):\n",
    "    psi_sel = Input(shape=(1,), name=\"psi_select\", dtype=\"int32\")\n",
    "    qn_sel = Input(shape=(1,), name=\"q_select\", dtype=\"int32\")\n",
    "    print(qn_table, psi_table, psi_sel, qn_sel)\n",
    "    print(\"psi_sel shape\", psi_sel.shape)\n",
    "\n",
    "    psi_table.trainable=True\n",
    "    qn_table.trainable=True\n",
    "    \n",
    "    qn_row = qn_table(qn_sel)\n",
    "    klip = Lambda(lambda q: K.clip(q,0,1))\n",
    "    q_masque = klip(qn_row)\n",
    "\n",
    "#     qn_row = GaussianNoise(.5)(qn_row)\n",
    "    psi_row = psi_table(psi_sel)\n",
    "#     psi_row = GaussianNoise(0.5)(psi_row)\n",
    "    \n",
    "#     prds = multiply([qn_row, psi_row])\n",
    "    difs = subtract([psi_row, qn_row])\n",
    "#     score = Lambda(lambda ps: K.sum(ps, axis=1, keepdims=True)/n_factors, name=\"score\")(prds)\n",
    "    Prs = Lambda(lambda z: (1.0 / (1.0 + K.exp(-z))), name=\"Pr_sigmoid1\")(difs)\n",
    "    Prs = Lambda(lambda ps_q:  ps_q[0]*ps_q[1] + (1.0-ps_q[1]) ) ([Prs, q_masque])\n",
    "\n",
    "    score = Lambda(lambda ps: K.prod(ps, axis=1, keepdims=True), name=\"score\")(Prs)\n",
    "    \n",
    "#     L_2a = Lambda(lambda w: K.mean(K.abs(K.zeros_like(w)-w)))\n",
    "#     mag_loss = (L_2a(qn_table.kernel) + sumstack)\n",
    "    \n",
    "    five_limit = Lambda(lambda w: K.mean(K.clip(K.sum(K.clip(w,0,1), axis=1),5,math.inf)))\n",
    "    one_limit = Lambda(lambda w: K.mean(1-K.clip(K.max(w,axis=1),0,1)))\n",
    "    \n",
    "    five_loss = 10*five_limit(qn_row)#(qn_table.kernel)\n",
    "    one_loss = one_limit(qn_row)#(qn_table.kernel)\n",
    "#     mag_loss = L_2a(qn_table.kernel) #+ five_limit(qn_table.kernel) + one_limit(qn_table.kernel)*5\n",
    "    mag_loss = five_loss + one_loss\n",
    "#     mag_loss = L_2(qn_row)\n",
    "    \n",
    "    def ident_loss(outer):\n",
    "        def inner(t,h):\n",
    "            return outer\n",
    "        return inner\n",
    "    \n",
    "    \n",
    "    def custom_loss(mag_loss):\n",
    "        def orig_loss(yt,yh):\n",
    "#             return K.binary_crossentropy(yt,yh) + mag_loss/100000 #+mag_loss # (reg_loss+mag_loss)/2\n",
    "            if comp_lims:\n",
    "                return K.mean(K.square(yt-yh)) + mag_loss#/10000 #+mag_loss # (reg_loss+mag_loss)/2\n",
    "            else:\n",
    "                return K.mean(K.square(yt-yh))\n",
    "        return orig_loss\n",
    "    \n",
    "    model = Model(inputs=[qn_sel, psi_sel], outputs=score)\n",
    "#     model.compile(optimizer=optimiser, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.compile(optimizer=optimiser, loss=custom_loss(mag_loss), metrics=[ident_loss(five_loss), ident_loss(one_loss),\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p50 is  4.96821536878\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "all_sz = []\n",
    "all_qz = []\n",
    "all_pfz = []\n",
    "\n",
    "# n_factors = 100\n",
    "# n_students = 1000\n",
    "# n_questions = 100\n",
    "\n",
    "frak = 1\n",
    "pairs_to_use = [(v,m) for v in range(n_students) for m in range(n_questions)]\n",
    "seenkeys = []\n",
    "seen = defaultdict(list)\n",
    "# if frak != 1:\n",
    "#     all_pair_ixs = list(range(len(all_pairs)))\n",
    "#     print(all_pairs[0:10])\n",
    "#     pairs_to_use = numpy.random.choice(all_pair_ixs, size=int(max(frak*len(all_pairs),10000)), replace=True)\n",
    "#     pairs_to_use = numpy.array(all_pairs)[pairs_to_use]\n",
    "        \n",
    "for vi,mi in pairs_to_use:\n",
    "# #         sc = 1 if (random.random() <= numpy.prod(sig(viewers[vi]-movies[mi]))) else 0\n",
    "# #         p = numpy.prod(sig(viewers[vi]-movies[mi]))\n",
    "# #         sc = int(0.5 <= numpy.prod(sig(viewers[vi]-movies[mi])))\n",
    "#         sc = obs[vi,mi]\n",
    "        all_sz.append(vi)\n",
    "        all_qz.append(mi)\n",
    "#         all_pfz.append(sc)\n",
    "#         seenkeys.append((vi,mi))\n",
    "#         seen[(vi,mi)].append(sc)\n",
    "\n",
    "av_c = (min_active + max_active)/2\n",
    "inv_sigmoid = lambda p: -numpy.log(1/p - 1)\n",
    "p50 = inv_sigmoid( 0.5**(1/n_factors) )\n",
    "print(\"p50 is \", p50)\n",
    "\n",
    "s_table =  BigTable((n_students, n_factors), 6, 100, init_hilo=7)#, regulariser=regularizers.l1(10e-6))\n",
    "qn_table = BigTable((n_questions, n_factors), 0, 100, init_hilo=7-p50)#, regulariser=regularizers.l1(10e-6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step - loss: 74.9022 - inner: 74.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1590/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 74.9022 - inner: 74.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1591/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 74.9022 - inner: 74.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1592/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 74.9022 - inner: 74.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1593/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 74.9022 - inner: 74.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1594/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 74.9022 - inner: 74.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1595/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 74.8989 - inner: 74.8968 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1596/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 74.8726 - inner: 74.8704 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1597/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 74.8522 - inner: 74.8501 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1598/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 74.8368 - inner: 74.8346 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1599/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.8237 - inner: 74.8216 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1600/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 74.8118 - inner: 74.8096 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1601/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.8028 - inner: 74.8006 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1602/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.8022 - inner: 74.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1603/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 74.8018 - inner: 74.7997 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1604/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 74.7786 - inner: 74.7765 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1605/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 74.7554 - inner: 74.7532 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1606/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.7390 - inner: 74.7368 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1607/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.7251 - inner: 74.7230 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1608/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 74.7127 - inner: 74.7105 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1609/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 74.7031 - inner: 74.7009 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1610/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 74.7021 - inner: 74.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1611/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 74.6939 - inner: 74.6917 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1612/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 74.6651 - inner: 74.6630 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1613/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 74.6464 - inner: 74.6443 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1614/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.6315 - inner: 74.6294 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1615/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.6189 - inner: 74.6167 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1616/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 74.6073 - inner: 74.6052 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1617/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 74.5841 - inner: 74.5819 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1618/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5571 - inner: 74.5549 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1619/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5395 - inner: 74.5374 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1620/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5253 - inner: 74.5232 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1621/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5127 - inner: 74.5106 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1622/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5032 - inner: 74.5010 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1623/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5021 - inner: 74.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1624/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5021 - inner: 74.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1625/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.5021 - inner: 74.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1626/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5021 - inner: 74.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1627/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.5021 - inner: 74.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1628/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5021 - inner: 74.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1629/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.5001 - inner: 74.4979 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1630/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.4727 - inner: 74.4706 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1631/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.4512 - inner: 74.4491 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1632/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.4323 - inner: 74.4302 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1633/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 74.3909 - inner: 74.3888 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1634/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.3581 - inner: 74.3560 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1635/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.3136 - inner: 74.3115 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1636/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.2758 - inner: 74.2737 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1637/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.2466 - inner: 74.2445 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1638/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.2257 - inner: 74.2235 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1639/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.1938 - inner: 74.1917 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1640/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.1585 - inner: 74.1564 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1641/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 74.1404 - inner: 74.1383 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1642/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 74.1264 - inner: 74.1242 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1643/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 74.1142 - inner: 74.1121 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1644/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 74.1039 - inner: 74.1018 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1645/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1646/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1647/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1648/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1649/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1650/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1651/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1652/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1653/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1654/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1655/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1656/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1657/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1658/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1659/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1660/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1661/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 74.1021 - inner: 74.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1662/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 74.0915 - inner: 74.0894 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1663/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 74.0660 - inner: 74.0639 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1664/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 74.0484 - inner: 74.0463 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1665/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 74.0181 - inner: 74.0160 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1666/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.9784 - inner: 73.9763 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1667/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 73.9491 - inner: 73.9470 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1668/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 73.9279 - inner: 73.9258 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1669/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.9151 - inner: 73.9130 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1670/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 73.9043 - inner: 73.9022 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1671/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.8939 - inner: 73.8918 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1672/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.8647 - inner: 73.8626 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1673/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 73.8448 - inner: 73.8427 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1674/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 73.8293 - inner: 73.8272 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1675/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 73.8161 - inner: 73.8140 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1676/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.8048 - inner: 73.8028 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1677/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 73.8021 - inner: 73.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1678/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 73.8021 - inner: 73.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1679/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.8021 - inner: 73.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1680/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.8021 - inner: 73.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1681/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.8021 - inner: 73.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1682/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.7978 - inner: 73.7957 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1683/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.7714 - inner: 73.7693 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1684/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 73.7505 - inner: 73.7485 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1685/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.7084 - inner: 73.7063 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1686/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.6726 - inner: 73.6706 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1687/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.6451 - inner: 73.6430 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1688/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.6218 - inner: 73.6198 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1689/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 73.6085 - inner: 73.6064 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1690/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 73.6021 - inner: 73.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1691/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.5947 - inner: 73.5926 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1692/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 73.5679 - inner: 73.5658 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1693/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 73.5488 - inner: 73.5468 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1694/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.5336 - inner: 73.5315 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1695/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 73.5000 - inner: 73.4979 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1696/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.4639 - inner: 73.4619 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1697/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4406 - inner: 73.4385 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1698/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.4267 - inner: 73.4247 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1699/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4147 - inner: 73.4126 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1700/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 73.4042 - inner: 73.4021 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1701/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1702/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1703/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1704/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1705/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1706/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1707/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1708/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1709/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1710/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1711/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1712/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.4021 - inner: 73.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1713/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.4017 - inner: 73.3997 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1714/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.3786 - inner: 73.3765 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1715/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 73.3548 - inner: 73.3527 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1716/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.3379 - inner: 73.3358 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1717/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 73.3237 - inner: 73.3216 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1718/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.3114 - inner: 73.3093 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1719/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.2956 - inner: 73.2935 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1720/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.2506 - inner: 73.2485 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1721/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.2071 - inner: 73.2050 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1722/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.1756 - inner: 73.1735 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1723/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 73.1489 - inner: 73.1468 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1724/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 73.1249 - inner: 73.1229 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1725/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 73.1055 - inner: 73.1034 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1726/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.0714 - inner: 73.0694 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1727/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 73.0506 - inner: 73.0485 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1728/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.0346 - inner: 73.0326 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1729/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 73.0211 - inner: 73.0190 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1730/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.0089 - inner: 73.0069 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1731/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.0021 - inner: 73.0001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1732/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1733/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1734/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1735/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1736/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1737/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1738/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1739/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 73.0020 - inner: 73.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1740/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 73.0018 - inner: 72.9998 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1741/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.9799 - inner: 72.9778 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1742/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.9567 - inner: 72.9546 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1743/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.9394 - inner: 72.9374 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1744/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.9254 - inner: 72.9233 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1745/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.9127 - inner: 72.9107 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1746/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 72.9030 - inner: 72.9010 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1747/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.9020 - inner: 72.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1748/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.9020 - inner: 72.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1749/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.9020 - inner: 72.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1750/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.9020 - inner: 72.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1751/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.9020 - inner: 72.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1752/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8834 - inner: 72.8814 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1753/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.8578 - inner: 72.8558 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1754/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.8408 - inner: 72.8387 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1755/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8265 - inner: 72.8245 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1756/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.8140 - inner: 72.8120 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1757/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8037 - inner: 72.8016 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1758/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1759/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1760/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1761/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1762/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1763/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1764/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1765/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1766/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1767/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 72.8020 - inner: 72.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1768/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.7979 - inner: 72.7959 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1769/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.7721 - inner: 72.7701 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1770/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.7524 - inner: 72.7504 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1771/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.7368 - inner: 72.7348 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1772/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.7233 - inner: 72.7213 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1773/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.7065 - inner: 72.7045 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1774/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.6698 - inner: 72.6677 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1775/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.6489 - inner: 72.6469 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1776/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.6329 - inner: 72.6309 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1777/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.6192 - inner: 72.6172 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1778/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6072 - inner: 72.6052 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1779/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1780/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1781/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1782/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1783/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1784/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1785/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1786/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1787/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1788/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1789/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1790/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1791/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1792/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1793/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1794/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1795/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1796/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1797/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1798/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1799/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1800/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.6020 - inner: 72.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1801/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 72.5846 - inner: 72.5826 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1802/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.5314 - inner: 72.5295 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1803/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.4844 - inner: 72.4824 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1804/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 72.4268 - inner: 72.4248 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1805/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3829 - inner: 72.3809 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1806/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3452 - inner: 72.3433 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1807/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3157 - inner: 72.3137 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1808/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3040 - inner: 72.3021 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1809/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1810/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1811/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1812/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1813/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1814/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1815/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1816/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1817/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1818/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1819/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1820/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1821/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1822/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1823/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1824/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1825/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1826/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1827/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1828/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1829/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1830/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1831/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1832/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1833/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1834/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1835/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1836/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1837/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1838/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1839/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.3020 - inner: 72.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1840/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.3012 - inner: 72.2992 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1841/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.2771 - inner: 72.2751 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1842/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.2549 - inner: 72.2530 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1843/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.2389 - inner: 72.2369 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1844/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 72.2253 - inner: 72.2233 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1845/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 72.2132 - inner: 72.2112 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1846/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 72.2032 - inner: 72.2013 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1847/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 72.2020 - inner: 72.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1848/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.2020 - inner: 72.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1849/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 72.2020 - inner: 72.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1850/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.2004 - inner: 72.1984 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1851/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.1774 - inner: 72.1755 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1852/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.1572 - inner: 72.1553 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1853/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.1417 - inner: 72.1397 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1854/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.1285 - inner: 72.1266 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1855/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 72.1167 - inner: 72.1148 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1856/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.1059 - inner: 72.1040 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1857/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 72.1018 - inner: 72.0999 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1858/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 72.0698 - inner: 72.0678 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1859/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 72.0010 - inner: 71.9991 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1860/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 71.9315 - inner: 71.9295 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1861/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.8366 - inner: 71.8346 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1862/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.7536 - inner: 71.7517 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1863/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.6872 - inner: 71.6853 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1864/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 71.6438 - inner: 71.6418 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1865/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 71.6174 - inner: 71.6155 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1866/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 71.5773 - inner: 71.5753 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1867/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 71.5550 - inner: 71.5530 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1868/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 71.5393 - inner: 71.5374 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1869/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 71.5262 - inner: 71.5243 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1870/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.5144 - inner: 71.5125 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1871/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 71.5043 - inner: 71.5023 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1872/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1873/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1874/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1875/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1876/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1877/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1878/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1879/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1880/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1881/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1882/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1883/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1884/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1885/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1886/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1887/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1888/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1889/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1890/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1891/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1892/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1893/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1894/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1895/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1896/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1897/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1898/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1899/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1900/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1901/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1902/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.5019 - inner: 71.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1903/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.5018 - inner: 71.4999 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1904/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 71.4805 - inner: 71.4786 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1905/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.4574 - inner: 71.4554 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1906/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 71.4410 - inner: 71.4391 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1907/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 71.4272 - inner: 71.4253 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1908/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.4150 - inner: 71.4130 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1909/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.4043 - inner: 71.4023 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1910/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1911/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1912/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1913/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1914/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1915/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1916/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1917/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1918/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1919/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1920/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 71.4019 - inner: 71.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1921/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3951 - inner: 71.3931 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1922/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.3681 - inner: 71.3662 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1923/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3493 - inner: 71.3474 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1924/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3341 - inner: 71.3322 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1925/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3209 - inner: 71.3190 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1926/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3089 - inner: 71.3070 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1927/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3020 - inner: 71.3001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1928/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1929/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1930/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1931/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1932/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1933/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1934/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1935/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1936/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1937/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1938/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1939/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.3019 - inner: 71.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1940/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 71.3018 - inner: 71.2999 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1941/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.2805 - inner: 71.2785 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1942/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.2570 - inner: 71.2551 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1943/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.2402 - inner: 71.2383 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1944/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.2263 - inner: 71.2244 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1945/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.2138 - inner: 71.2119 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1946/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.2035 - inner: 71.2016 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1947/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.2019 - inner: 71.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1948/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.2019 - inner: 71.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1949/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.1851 - inner: 71.1832 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1950/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.1595 - inner: 71.1576 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1951/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 71.1419 - inner: 71.1400 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1952/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.1275 - inner: 71.1256 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1953/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.1149 - inner: 71.1130 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1954/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.1040 - inner: 71.1021 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1955/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1956/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1957/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1958/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1959/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1960/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1961/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1962/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.1019 - inner: 71.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1963/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.0876 - inner: 71.0857 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1964/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 71.0614 - inner: 71.0595 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1965/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 71.0438 - inner: 71.0419 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1966/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.0292 - inner: 71.0273 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1967/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 71.0167 - inner: 71.0148 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1968/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.0055 - inner: 71.0036 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1969/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1970/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1971/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1972/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1973/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1974/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1975/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1976/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1977/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1978/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1979/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1980/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1981/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1982/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1983/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1984/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1985/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 71.0019 - inner: 71.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1986/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 70.9857 - inner: 70.9839 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1987/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.9605 - inner: 70.9586 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1988/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.9432 - inner: 70.9414 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1989/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 70.9288 - inner: 70.9269 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1990/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 70.9161 - inner: 70.9142 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1991/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 70.9049 - inner: 70.9031 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1992/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 70.9018 - inner: 70.8999 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1993/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.8792 - inner: 70.8773 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1994/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 70.8528 - inner: 70.8509 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1995/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 70.8087 - inner: 70.8068 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1996/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.7731 - inner: 70.7712 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1997/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 70.7448 - inner: 70.7429 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1998/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.7219 - inner: 70.7200 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 1999/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 70.7087 - inner: 70.7069 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2000/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.7019 - inner: 70.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2001/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.7019 - inner: 70.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2002/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 70.7019 - inner: 70.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2003/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 70.7019 - inner: 70.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2004/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.7019 - inner: 70.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2005/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 70.6961 - inner: 70.6943 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2006/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.6664 - inner: 70.6645 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2007/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.6461 - inner: 70.6442 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2008/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.6309 - inner: 70.6290 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2009/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 70.6155 - inner: 70.6136 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2010/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 70.5762 - inner: 70.5743 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2011/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.5496 - inner: 70.5477 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2012/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.5331 - inner: 70.5313 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2013/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 70.5127 - inner: 70.5109 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2014/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 70.4734 - inner: 70.4715 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2015/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 70.4497 - inner: 70.4478 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2016/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 70.4355 - inner: 70.4337 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2017/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.4230 - inner: 70.4212 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2018/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 70.3965 - inner: 70.3947 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2019/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.3335 - inner: 70.3316 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2020/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 70.2937 - inner: 70.2918 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2021/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2629 - inner: 70.2611 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2022/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2364 - inner: 70.2345 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2023/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2126 - inner: 70.2108 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2024/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2025/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2026/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2027/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2028/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2029/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2030/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2031/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2032/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2033/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2034/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2035/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2036/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2037/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 70.2019 - inner: 70.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2038/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.1802 - inner: 70.1784 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2039/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 70.1545 - inner: 70.1527 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2040/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 70.1373 - inner: 70.1355 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2041/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 70.1233 - inner: 70.1214 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2042/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.1108 - inner: 70.1089 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2043/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 70.1022 - inner: 70.1004 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2044/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.1018 - inner: 70.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2045/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.1018 - inner: 70.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2046/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 70.0919 - inner: 70.0901 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2047/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 70.0646 - inner: 70.0628 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2048/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.0459 - inner: 70.0440 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2049/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.0305 - inner: 70.0286 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2050/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 70.0175 - inner: 70.0157 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2051/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.0057 - inner: 70.0039 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2052/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 70.0018 - inner: 70.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2053/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 70.0018 - inner: 70.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2054/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 70.0012 - inner: 69.9993 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2055/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.9762 - inner: 69.9743 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2056/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.9532 - inner: 69.9514 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2057/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 69.9278 - inner: 69.9259 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2058/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.8657 - inner: 69.8638 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2059/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.7800 - inner: 69.7782 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2060/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.7181 - inner: 69.7162 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2061/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.6740 - inner: 69.6722 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2062/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.6369 - inner: 69.6351 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2063/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.6118 - inner: 69.6100 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2064/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2065/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2066/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2067/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2068/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2069/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2070/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2071/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2072/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2073/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2074/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.6018 - inner: 69.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2075/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.5860 - inner: 69.5842 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2076/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.5578 - inner: 69.5560 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2077/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 69.5404 - inner: 69.5385 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2078/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.5259 - inner: 69.5241 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2079/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.5131 - inner: 69.5112 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2080/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.4819 - inner: 69.4800 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2081/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 69.4565 - inner: 69.4546 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2082/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 69.4325 - inner: 69.4307 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2083/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.3915 - inner: 69.3897 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2084/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 69.3604 - inner: 69.3586 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2085/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 69.3354 - inner: 69.3336 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2086/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.3208 - inner: 69.3189 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2087/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 69.3090 - inner: 69.3072 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2088/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.3019 - inner: 69.3001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2089/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2090/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2091/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2092/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2093/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2094/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2095/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2096/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2097/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2098/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2099/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2100/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2101/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2102/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2103/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2104/100000\n",
      "10000/10000 [==============================] - 1s 52us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2105/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2106/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2107/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2108/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2109/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2110/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2111/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 69.3018 - inner: 69.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2112/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 69.2859 - inner: 69.2841 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2113/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 69.2608 - inner: 69.2590 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2114/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 69.2434 - inner: 69.2416 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2115/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.2291 - inner: 69.2273 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2116/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.2165 - inner: 69.2147 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2117/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.2054 - inner: 69.2036 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2118/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 69.2018 - inner: 69.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2119/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.2018 - inner: 69.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2120/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.2007 - inner: 69.1989 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2121/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.1773 - inner: 69.1755 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2122/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 69.1563 - inner: 69.1545 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2123/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.1406 - inner: 69.1388 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2124/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.1272 - inner: 69.1254 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2125/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 69.1149 - inner: 69.1131 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2126/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1043 - inner: 69.1025 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2127/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2128/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2129/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2130/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2131/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2132/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2133/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2134/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2135/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2136/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2137/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2138/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2139/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2140/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2141/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2142/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2143/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2144/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 69.1018 - inner: 69.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2145/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 69.0834 - inner: 69.0816 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2146/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 69.0527 - inner: 69.0509 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2147/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 69.0066 - inner: 69.0048 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2148/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 68.9714 - inner: 68.9696 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2149/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.9197 - inner: 68.9179 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2150/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.8733 - inner: 68.8716 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2151/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.8428 - inner: 68.8410 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2152/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.8251 - inner: 68.8233 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2153/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.8129 - inner: 68.8111 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2154/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 68.8030 - inner: 68.8012 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2155/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 68.8018 - inner: 68.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2156/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.8018 - inner: 68.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2157/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.8018 - inner: 68.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2158/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.8018 - inner: 68.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2159/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.8018 - inner: 68.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2160/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.8018 - inner: 68.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2161/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 68.7901 - inner: 68.7883 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2162/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 68.7598 - inner: 68.7581 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2163/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7403 - inner: 68.7385 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2164/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 68.7250 - inner: 68.7232 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2165/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7117 - inner: 68.7099 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2166/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7024 - inner: 68.7006 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2167/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2168/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2169/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2170/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2171/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2172/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2173/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2174/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2175/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2176/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2177/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2178/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2179/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2180/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2181/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2182/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2183/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2184/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2185/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2186/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2187/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2188/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2189/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2190/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2191/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2192/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2193/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2194/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2195/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2196/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 68.7018 - inner: 68.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2197/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 68.6936 - inner: 68.6918 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2198/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6657 - inner: 68.6639 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2199/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.6463 - inner: 68.6446 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2200/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6310 - inner: 68.6293 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2201/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6177 - inner: 68.6159 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2202/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6057 - inner: 68.6040 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2203/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2204/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2205/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2206/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2207/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2208/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2209/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2210/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2211/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2212/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2213/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2214/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2215/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2216/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2217/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2218/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2219/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2220/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2221/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2222/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2223/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2224/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2225/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2226/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.6018 - inner: 68.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2227/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5998 - inner: 68.5980 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2228/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5725 - inner: 68.5708 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2229/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5507 - inner: 68.5490 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2230/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5347 - inner: 68.5329 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2231/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5211 - inner: 68.5193 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2232/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 68.5091 - inner: 68.5073 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2233/100000\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 68.5019 - inner: 68.5001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2234/100000\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2235/100000\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2236/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2237/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2238/100000\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2239/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2240/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2241/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2242/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2243/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2244/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2245/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5018 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2246/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2247/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2248/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2249/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2250/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2251/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2252/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2253/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2254/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2255/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2256/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.5017 - inner: 68.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2257/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.5016 - inner: 68.4998 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2258/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4802 - inner: 68.4784 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2259/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.4567 - inner: 68.4549 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2260/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4403 - inner: 68.4385 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2261/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4265 - inner: 68.4248 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2262/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 68.4143 - inner: 68.4125 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2263/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4039 - inner: 68.4021 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2264/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.4017 - inner: 68.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2265/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4017 - inner: 68.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2266/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4017 - inner: 68.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2267/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4017 - inner: 68.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2268/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 68.4017 - inner: 68.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2269/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.4017 - inner: 68.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2270/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.3982 - inner: 68.3965 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2271/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.3702 - inner: 68.3685 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2272/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.3497 - inner: 68.3479 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2273/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.3210 - inner: 68.3192 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2274/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.2824 - inner: 68.2807 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2275/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2532 - inner: 68.2515 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2276/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2327 - inner: 68.2309 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2277/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2201 - inner: 68.2184 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2278/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2087 - inner: 68.2070 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2279/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2019 - inner: 68.2001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2280/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2281/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2282/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2283/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2284/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2285/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2286/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2287/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2288/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2289/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2290/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2291/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2292/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2293/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2294/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2295/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2296/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2297/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2298/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2299/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2300/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2301/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2302/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2303/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2304/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2305/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2306/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2307/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2308/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2309/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2310/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2311/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2312/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2313/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2314/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 68.2017 - inner: 68.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2315/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 68.1867 - inner: 68.1849 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2316/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 68.1298 - inner: 68.1280 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2317/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 68.0911 - inner: 68.0894 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2318/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 68.0606 - inner: 68.0589 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2319/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 68.0343 - inner: 68.0326 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2320/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 68.0109 - inner: 68.0092 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2321/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2322/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2323/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2324/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2325/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2326/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2327/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2328/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2329/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2330/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2331/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2332/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2333/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2334/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2335/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2336/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2337/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2338/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2339/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2340/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2341/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2342/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2343/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2344/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2345/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2346/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2347/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 68.0017 - inner: 68.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2348/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9995 - inner: 67.9978 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2349/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9734 - inner: 67.9717 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2350/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9526 - inner: 67.9509 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2351/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 67.9372 - inner: 67.9355 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2352/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9240 - inner: 67.9223 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2353/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9122 - inner: 67.9105 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2354/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9028 - inner: 67.9011 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2355/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2356/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2357/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2358/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2359/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2360/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2361/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2362/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2363/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2364/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2365/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2366/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2367/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2368/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2369/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2370/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2371/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2372/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2373/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2374/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2375/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2376/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2377/100000\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2378/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2379/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2380/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2381/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2382/100000\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2383/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2384/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2385/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2386/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2387/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2388/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2389/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2390/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2391/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.9017 - inner: 67.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2392/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.9011 - inner: 67.8994 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2393/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.8798 - inner: 67.8781 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2394/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8587 - inner: 67.8570 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2395/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.8430 - inner: 67.8413 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2396/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8298 - inner: 67.8281 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2397/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8179 - inner: 67.8162 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2398/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8069 - inner: 67.8052 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2399/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2400/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2401/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2402/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2403/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2404/100000\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2405/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2406/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2407/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2408/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2409/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 67.8017 - inner: 67.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2410/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 67.7920 - inner: 67.7903 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2411/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.7674 - inner: 67.7657 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2412/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 67.7502 - inner: 67.7485 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2413/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.7361 - inner: 67.7344 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2414/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.7238 - inner: 67.7221 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2415/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 67.7126 - inner: 67.7109 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2416/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 67.7031 - inner: 67.7014 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2417/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 67.7017 - inner: 67.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2418/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 67.6835 - inner: 67.6818 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2419/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 67.6569 - inner: 67.6552 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2420/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.6392 - inner: 67.6375 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2421/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 67.6250 - inner: 67.6233 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2422/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 67.6125 - inner: 67.6108 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2423/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 67.6028 - inner: 67.6011 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2424/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 67.6017 - inner: 67.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2425/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 67.6017 - inner: 67.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2426/100000\n",
      "10000/10000 [==============================] - 0s 49us/step - loss: 67.6017 - inner: 67.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2427/100000\n",
      "10000/10000 [==============================] - 1s 59us/step - loss: 67.6017 - inner: 67.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2428/100000\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 67.5864 - inner: 67.5847 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2429/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 67.5605 - inner: 67.5589 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2430/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 67.5433 - inner: 67.5416 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2431/100000\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 67.5294 - inner: 67.5277 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2432/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 67.5170 - inner: 67.5153 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2433/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.5060 - inner: 67.5043 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2434/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2435/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2436/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2437/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2438/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2439/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2440/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2441/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2442/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2443/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2444/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2445/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2446/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2447/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2448/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2449/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2450/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.5017 - inner: 67.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2451/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.4866 - inner: 67.4849 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2452/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 67.4573 - inner: 67.4556 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2453/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.4388 - inner: 67.4372 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2454/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.4243 - inner: 67.4226 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2455/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 67.4116 - inner: 67.4099 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2456/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.4023 - inner: 67.4007 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2457/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.4017 - inner: 67.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2458/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 67.4017 - inner: 67.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2459/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.4017 - inner: 67.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2460/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.4006 - inner: 67.3990 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2461/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.3742 - inner: 67.3725 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2462/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.3516 - inner: 67.3499 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2463/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.3350 - inner: 67.3334 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2464/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.3213 - inner: 67.3196 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2465/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 67.3091 - inner: 67.3075 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2466/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.3018 - inner: 67.3001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2467/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2468/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2469/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2470/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2471/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2472/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2473/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2474/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.3017 - inner: 67.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2475/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.2841 - inner: 67.2824 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2476/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.2597 - inner: 67.2580 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2477/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.2433 - inner: 67.2417 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2478/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 67.2298 - inner: 67.2281 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2479/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.2176 - inner: 67.2159 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2480/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.1949 - inner: 67.1933 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2481/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.1638 - inner: 67.1621 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2482/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.1461 - inner: 67.1444 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2483/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.1319 - inner: 67.1303 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2484/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.1195 - inner: 67.1179 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2485/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.1083 - inner: 67.1066 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2486/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.1017 - inner: 67.1001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2487/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 67.0951 - inner: 67.0934 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2488/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 67.0450 - inner: 67.0433 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2489/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 67.0052 - inner: 67.0035 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2490/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.9747 - inner: 66.9731 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2491/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.9486 - inner: 66.9470 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2492/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9250 - inner: 66.9233 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2493/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.9079 - inner: 66.9063 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2494/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9017 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2495/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2496/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2497/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2498/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2499/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2500/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2501/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2502/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2503/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2504/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2505/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2506/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2507/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2508/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2509/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2510/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2511/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.9016 - inner: 66.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2512/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8940 - inner: 66.8923 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2513/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.8639 - inner: 66.8622 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2514/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8442 - inner: 66.8426 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2515/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8291 - inner: 66.8274 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2516/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.8160 - inner: 66.8143 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2517/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.8046 - inner: 66.8030 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2518/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2519/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2520/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2521/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2522/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2523/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2524/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2525/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2526/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2527/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2528/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2529/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2530/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2531/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2532/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2533/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2534/100000\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2535/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 66.8016 - inner: 66.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2536/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 66.7953 - inner: 66.7936 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2537/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 66.7675 - inner: 66.7659 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2538/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 66.7479 - inner: 66.7463 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2539/100000\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 66.7324 - inner: 66.7308 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2540/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 66.7192 - inner: 66.7175 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2541/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 66.7070 - inner: 66.7054 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2542/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2543/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2544/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2545/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2546/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2547/100000\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2548/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2549/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2550/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2551/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2552/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2553/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2554/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2555/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2556/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2557/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2558/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2559/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.7016 - inner: 66.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2560/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.7015 - inner: 66.6998 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2561/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.6773 - inner: 66.6757 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2562/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.6539 - inner: 66.6522 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2563/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.6338 - inner: 66.6322 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2564/100000\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 66.5691 - inner: 66.5675 - inner_1: 0.0000e+00 - acc: 0.001 - 0s 31us/step - loss: 66.5958 - inner: 66.5942 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2565/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.5642 - inner: 66.5626 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2566/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.5402 - inner: 66.5386 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2567/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.5265 - inner: 66.5249 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2568/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.5149 - inner: 66.5133 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2569/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4876 - inner: 66.4860 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2570/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4585 - inner: 66.4569 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2571/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4407 - inner: 66.4390 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2572/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4264 - inner: 66.4248 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2573/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4138 - inner: 66.4122 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2574/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4034 - inner: 66.4018 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2575/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2576/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2577/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2578/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2579/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2580/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2581/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2582/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2583/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2584/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2585/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2586/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2587/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2588/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2589/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2590/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2591/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2592/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2593/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2594/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2595/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2596/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2597/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2598/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.4016 - inner: 66.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2599/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.3979 - inner: 66.3963 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2600/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.3708 - inner: 66.3692 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2601/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.3500 - inner: 66.3484 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2602/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.3339 - inner: 66.3323 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2603/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.3204 - inner: 66.3188 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2604/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 66.3084 - inner: 66.3068 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2605/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 66.3017 - inner: 66.3001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2606/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.3016 - inner: 66.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2607/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.3016 - inner: 66.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2608/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 66.3016 - inner: 66.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2609/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.3016 - inner: 66.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2610/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2876 - inner: 66.2860 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2611/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 66.2604 - inner: 66.2588 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2612/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2421 - inner: 66.2405 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2613/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.2273 - inner: 66.2257 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2614/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2144 - inner: 66.2128 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2615/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2036 - inner: 66.2020 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2616/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2617/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2618/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2619/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2620/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2621/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2622/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2623/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2624/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2625/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2626/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2627/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2628/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2629/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2630/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2631/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2632/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2633/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2634/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2635/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2636/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2637/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2638/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2639/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2640/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2641/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2642/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2643/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2644/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2645/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2646/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2647/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2648/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2649/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2650/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2651/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2652/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2653/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2654/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2655/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2656/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2657/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2658/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2659/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2660/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2661/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2662/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2663/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2664/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2665/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2666/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2667/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2668/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.2016 - inner: 66.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2669/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.1932 - inner: 66.1916 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2670/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.1658 - inner: 66.1642 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2671/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.1470 - inner: 66.1454 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2672/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.1322 - inner: 66.1306 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2673/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.1194 - inner: 66.1178 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2674/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.1078 - inner: 66.1062 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2675/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0984 - inner: 66.0968 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2676/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0714 - inner: 66.0698 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2677/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0511 - inner: 66.0495 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2678/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0357 - inner: 66.0341 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2679/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0226 - inner: 66.0210 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2680/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0108 - inner: 66.0092 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2681/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0021 - inner: 66.0006 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2682/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2683/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2684/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2685/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2686/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2687/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2688/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2689/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 29us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2690/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2691/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2692/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2693/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2694/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2695/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2696/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2697/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2698/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2699/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2700/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2701/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2702/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2703/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2704/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2705/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2706/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2707/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2708/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2709/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2710/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2711/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2712/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2713/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2714/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2715/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2716/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2717/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2718/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2719/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2720/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 66.0016 - inner: 66.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2721/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9833 - inner: 65.9817 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2722/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9560 - inner: 65.9544 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2723/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9381 - inner: 65.9365 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2724/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9234 - inner: 65.9218 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2725/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9105 - inner: 65.9089 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2726/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9020 - inner: 65.9004 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2727/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2728/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2729/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2730/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2731/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2732/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2733/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2734/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2735/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2736/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2737/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2738/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2739/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2740/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2741/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2742/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2743/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2744/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.9016 - inner: 65.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2745/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.9015 - inner: 65.8999 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2746/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8822 - inner: 65.8807 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2747/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.8585 - inner: 65.8569 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2748/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8418 - inner: 65.8402 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2749/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8278 - inner: 65.8263 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2750/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.8155 - inner: 65.8139 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2751/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.8045 - inner: 65.8030 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2752/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2753/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2754/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2755/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2756/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2757/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2758/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2759/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2760/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2761/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.8016 - inner: 65.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2762/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.7859 - inner: 65.7843 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2763/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.7598 - inner: 65.7582 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2764/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.7424 - inner: 65.7408 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2765/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.7281 - inner: 65.7266 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2766/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.7155 - inner: 65.7140 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2767/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.7044 - inner: 65.7029 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2768/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.7016 - inner: 65.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2769/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 65.7016 - inner: 65.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2770/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.7016 - inner: 65.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2771/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.7016 - inner: 65.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2772/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6998 - inner: 65.6983 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2773/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6720 - inner: 65.6705 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2774/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6502 - inner: 65.6486 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2775/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.6345 - inner: 65.6330 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2776/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6214 - inner: 65.6199 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2777/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.6097 - inner: 65.6081 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2778/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6019 - inner: 65.6003 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2779/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 65.6016 - inner: 65.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2780/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.6016 - inner: 65.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2781/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6016 - inner: 65.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2782/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6016 - inner: 65.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2783/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.6016 - inner: 65.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2784/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6016 - inner: 65.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2785/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.6016 - inner: 65.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2786/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.6008 - inner: 65.5993 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2787/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5777 - inner: 65.5762 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2788/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5568 - inner: 65.5553 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2789/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5413 - inner: 65.5397 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2790/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5280 - inner: 65.5265 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2791/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5160 - inner: 65.5145 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2792/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5052 - inner: 65.5036 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2793/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2794/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2795/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2796/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2797/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2798/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2799/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2800/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2801/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2802/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2803/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2804/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2805/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2806/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2807/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2808/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2809/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2810/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2811/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2812/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2813/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2814/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2815/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2816/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2817/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2818/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5016 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2819/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2820/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2821/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2822/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2823/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2824/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2825/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2826/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2827/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2828/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2829/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2830/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.5015 - inner: 65.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2831/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.4992 - inner: 65.4977 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2832/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.4744 - inner: 65.4728 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2833/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.4538 - inner: 65.4523 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2834/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.4383 - inner: 65.4368 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2835/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 65.4249 - inner: 65.4234 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2836/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 65.4131 - inner: 65.4116 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2837/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.4032 - inner: 65.4016 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2838/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2839/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2840/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2841/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2842/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2843/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2844/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2845/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 65.4015 - inner: 65.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2846/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.3987 - inner: 65.3972 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2847/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3738 - inner: 65.3723 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2848/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3535 - inner: 65.3520 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2849/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3378 - inner: 65.3363 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2850/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 65.3243 - inner: 65.3228 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2851/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3123 - inner: 65.3108 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2852/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3027 - inner: 65.3011 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2853/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3015 - inner: 65.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2854/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 65.3015 - inner: 65.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2855/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.3015 - inner: 65.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2856/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3015 - inner: 65.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2857/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.3015 - inner: 65.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2858/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.2967 - inner: 65.2951 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2859/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.2703 - inner: 65.2687 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2860/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.2510 - inner: 65.2495 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2861/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.2358 - inner: 65.2342 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2862/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.2229 - inner: 65.2214 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2863/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.2112 - inner: 65.2097 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2864/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.2025 - inner: 65.2009 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2865/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.2015 - inner: 65.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2866/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 65.2015 - inner: 65.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2867/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 65.1950 - inner: 65.1935 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2868/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 65.1678 - inner: 65.1663 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2869/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 65.1500 - inner: 65.1485 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2870/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 65.1354 - inner: 65.1339 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2871/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 65.1226 - inner: 65.1211 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2872/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 65.1062 - inner: 65.1047 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2873/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2874/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2875/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2876/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2877/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2878/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2879/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2880/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2881/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2882/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2883/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2884/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2885/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2886/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2887/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2888/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2889/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2890/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2891/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2892/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 65.1015 - inner: 65.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2893/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.0878 - inner: 65.0862 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2894/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.0627 - inner: 65.0611 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2895/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.0451 - inner: 65.0436 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2896/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.0305 - inner: 65.0290 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2897/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 65.0177 - inner: 65.0162 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2898/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.0060 - inner: 65.0045 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2899/100000\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 65.0015 - inner: 65.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2900/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.0015 - inner: 65.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2901/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.0015 - inner: 65.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2902/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.0015 - inner: 65.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2903/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 65.0015 - inner: 65.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2904/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 65.0007 - inner: 64.9992 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2905/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9763 - inner: 64.9748 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2906/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9535 - inner: 64.9520 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2907/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9368 - inner: 64.9353 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2908/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.9231 - inner: 64.9216 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2909/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9110 - inner: 64.9094 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2910/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9022 - inner: 64.9006 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2911/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9015 - inner: 64.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2912/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9015 - inner: 64.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2913/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 64.9015 - inner: 64.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2914/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9015 - inner: 64.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2915/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.9015 - inner: 64.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2916/100000\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 64.9015 - inner: 64.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2917/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.8884 - inner: 64.8869 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2918/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.8591 - inner: 64.8576 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2919/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.8203 - inner: 64.8188 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2920/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.7862 - inner: 64.7847 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2921/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.7581 - inner: 64.7565 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2922/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 64.7344 - inner: 64.7328 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2923/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.7207 - inner: 64.7192 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2924/100000\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 64.7098 - inner: 64.7083 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2925/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 64.7020 - inner: 64.7005 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2926/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2927/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2928/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2929/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2930/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2931/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2932/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2933/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2934/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2935/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2936/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2937/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2938/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2939/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 64.7015 - inner: 64.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2940/100000\n",
      "10000/10000 [==============================] - 1s 53us/step - loss: 64.6851 - inner: 64.6836 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2941/100000\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 64.6612 - inner: 64.6596 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2942/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 64.6445 - inner: 64.6429 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2943/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 64.6308 - inner: 64.6293 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2944/100000\n",
      "10000/10000 [==============================] - 1s 52us/step - loss: 64.6183 - inner: 64.6168 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2945/100000\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 64.6071 - inner: 64.6055 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2946/100000\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2947/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2948/100000\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2949/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2950/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2951/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2952/100000\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2953/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2954/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2955/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2956/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2957/100000\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2958/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2959/100000\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2960/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2961/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2962/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2963/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2964/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2965/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2966/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2967/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2968/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2969/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.6015 - inner: 64.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2970/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.5943 - inner: 64.5928 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2971/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.5675 - inner: 64.5660 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2972/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.5493 - inner: 64.5478 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2973/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.5346 - inner: 64.5331 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2974/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 64.5219 - inner: 64.5204 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2975/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.5103 - inner: 64.5088 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2976/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.5020 - inner: 64.5005 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2977/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2978/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2979/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2980/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2981/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2982/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2983/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2984/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2985/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2986/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2987/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2988/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2989/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2990/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2991/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2992/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2993/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2994/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2995/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2996/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2997/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2998/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 2999/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3000/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3001/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3002/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3003/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3004/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3005/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.5015 - inner: 64.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3006/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4917 - inner: 64.4902 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3007/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.4652 - inner: 64.4637 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3008/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4467 - inner: 64.4452 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3009/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4320 - inner: 64.4305 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3010/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.4190 - inner: 64.4175 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3011/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4074 - inner: 64.4059 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3012/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3013/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3014/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3015/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3016/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3017/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3018/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3019/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3020/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3021/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3022/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3023/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3024/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3025/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3026/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3027/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3028/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3029/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3030/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3031/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3032/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3033/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3034/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3035/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3036/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3037/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3038/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3039/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3040/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3041/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3042/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3043/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3044/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3045/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3046/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3047/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3048/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.4015 - inner: 64.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3049/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3991 - inner: 64.3976 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3050/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3726 - inner: 64.3711 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3051/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3510 - inner: 64.3495 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3052/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3347 - inner: 64.3333 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3053/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3209 - inner: 64.3194 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3054/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.3085 - inner: 64.3070 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3055/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.3015 - inner: 64.3001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3056/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3057/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3058/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3059/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3060/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3061/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3062/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3063/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3064/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3065/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3066/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3067/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3068/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3069/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3070/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3071/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3072/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3073/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3074/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3075/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3076/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3077/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3078/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.3015 - inner: 64.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3079/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 64.3002 - inner: 64.2987 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3080/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2746 - inner: 64.2731 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3081/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2518 - inner: 64.2503 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3082/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2349 - inner: 64.2334 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3083/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2207 - inner: 64.2193 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3084/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2080 - inner: 64.2065 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3085/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3086/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3087/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3088/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3089/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3090/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3091/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3092/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3093/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3094/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3095/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3096/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3097/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3098/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3099/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3100/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3101/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3102/100000\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3103/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3104/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3105/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3106/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3107/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3108/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3109/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3110/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3111/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3112/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3113/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3114/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3115/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3116/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3117/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3118/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3119/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3120/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3121/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3122/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3123/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3124/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3125/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3126/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3127/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3128/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3129/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3130/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3131/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3132/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3133/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3134/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3135/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3136/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3137/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3138/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3139/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3140/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3141/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3142/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2015 - inner: 64.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3143/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.2010 - inner: 64.1995 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3144/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1781 - inner: 64.1766 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3145/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.1554 - inner: 64.1539 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3146/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.1387 - inner: 64.1373 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3147/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 64.1249 - inner: 64.1234 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3148/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.1127 - inner: 64.1113 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3149/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1027 - inner: 64.1013 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3150/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3151/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3152/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3153/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3154/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3155/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3156/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3157/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3158/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3159/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3160/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3161/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3162/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3163/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3164/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3165/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3166/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3167/100000\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3168/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3169/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3170/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3171/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3172/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3173/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3174/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3175/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3176/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3177/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3178/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3179/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3180/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3181/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3182/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1015 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3183/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3184/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3185/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3186/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3187/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3188/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3189/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3190/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3191/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3192/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3193/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3194/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3195/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3196/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3197/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3198/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3199/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3200/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3201/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3202/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3203/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3204/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3205/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3206/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3207/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3208/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3209/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3210/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3211/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3212/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3213/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3214/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3215/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3216/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3217/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3218/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3219/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3220/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3221/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3222/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3223/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3224/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3225/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3226/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3227/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3228/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.1014 - inner: 64.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3229/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.0932 - inner: 64.0918 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3230/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.0655 - inner: 64.0640 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3231/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.0467 - inner: 64.0453 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3232/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 64.0320 - inner: 64.0306 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3233/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.0191 - inner: 64.0177 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3234/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.0074 - inner: 64.0060 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3235/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.0014 - inner: 64.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3236/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.0014 - inner: 64.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3237/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 64.0014 - inner: 64.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3238/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.0014 - inner: 64.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3239/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.0014 - inner: 64.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3240/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 64.0014 - inner: 64.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3241/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 64.0014 - inner: 64.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3242/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9911 - inner: 63.9897 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3243/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9636 - inner: 63.9622 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3244/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9454 - inner: 63.9439 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3245/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9309 - inner: 63.9294 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3246/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9181 - inner: 63.9166 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3247/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9067 - inner: 63.9053 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3248/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3249/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3250/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3251/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3252/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3253/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3254/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3255/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3256/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3257/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3258/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3259/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3260/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3261/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3262/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3263/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3264/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3265/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3266/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3267/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3268/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3269/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3270/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3271/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3272/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3273/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3274/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3275/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3276/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3277/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3278/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3279/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3280/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3281/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3282/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3283/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3284/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3285/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3286/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3287/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3288/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3289/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3290/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3291/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3292/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3293/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3294/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3295/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3296/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3297/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3298/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3299/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3300/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3301/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3302/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3303/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3304/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3305/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3306/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3307/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3308/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3309/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3310/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3311/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3312/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3313/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3314/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3315/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3316/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3317/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3318/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3319/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3320/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3321/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3322/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3323/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3324/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3325/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3326/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3327/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3328/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3329/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3330/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3331/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3332/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3333/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3334/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3335/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3336/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3337/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3338/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3339/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3340/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3341/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3342/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3343/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3344/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3345/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3346/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3347/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3348/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3349/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3350/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3351/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3352/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3353/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3354/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3355/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3356/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3357/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3358/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3359/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3360/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3361/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3362/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3363/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3364/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3365/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3366/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3367/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3368/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3369/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3370/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3371/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3372/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3373/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3374/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3375/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3376/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3377/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3378/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3379/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3380/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3381/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3382/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3383/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3384/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3385/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3386/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3387/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3388/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3389/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3390/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3391/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3392/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3393/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3394/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3395/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3396/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3397/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3398/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3399/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3400/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3401/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3402/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3403/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3404/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3405/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3406/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3407/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3408/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3409/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3410/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3411/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3412/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.9014 - inner: 63.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3413/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8903 - inner: 63.8889 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3414/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8617 - inner: 63.8603 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3415/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8431 - inner: 63.8417 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3416/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8284 - inner: 63.8270 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3417/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8156 - inner: 63.8142 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3418/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8045 - inner: 63.8031 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3419/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3420/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3421/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3422/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3423/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3424/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3425/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3426/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3427/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3428/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3429/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3430/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3431/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3432/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3433/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3434/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3435/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3436/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3437/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3438/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3439/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3440/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3441/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3442/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3443/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3444/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3445/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3446/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3447/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3448/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3449/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3450/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3451/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3452/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3453/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3454/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3455/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3456/100000\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3457/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3458/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3459/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3460/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3461/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3462/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3463/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3464/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3465/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3466/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3467/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3468/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3469/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3470/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3471/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3472/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3473/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3474/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3475/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3476/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3477/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3478/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3479/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3480/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3481/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3482/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3483/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3484/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3485/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3486/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3487/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3488/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3489/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3490/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3491/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3492/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3493/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3494/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.8014 - inner: 63.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3495/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7951 - inner: 63.7937 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3496/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.7669 - inner: 63.7655 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3497/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7472 - inner: 63.7458 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3498/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7319 - inner: 63.7306 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3499/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7188 - inner: 63.7175 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3500/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7070 - inner: 63.7056 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3501/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3502/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3503/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3504/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3505/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3506/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3507/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3508/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3509/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3510/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3511/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3512/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3513/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3514/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3515/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3516/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3517/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3518/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3519/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3520/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3521/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3522/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3523/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3524/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3525/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3526/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3527/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3528/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3529/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3530/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3531/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3532/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3533/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3534/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3535/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3536/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3537/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3538/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3539/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3540/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3541/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3542/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3543/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3544/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3545/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3546/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.7014 - inner: 63.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3547/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.6989 - inner: 63.6975 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3548/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.6727 - inner: 63.6714 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3549/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.6521 - inner: 63.6507 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3550/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.6364 - inner: 63.6351 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3551/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.6231 - inner: 63.6217 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3552/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.6111 - inner: 63.6097 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3553/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.6021 - inner: 63.6008 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3554/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.6014 - inner: 63.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3555/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.6014 - inner: 63.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3556/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.6014 - inner: 63.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3557/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.5914 - inner: 63.5900 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3558/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.5609 - inner: 63.5596 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3559/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.5418 - inner: 63.5404 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3560/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.5267 - inner: 63.5253 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3561/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.5135 - inner: 63.5122 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3562/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.5029 - inner: 63.5016 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3563/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.5014 - inner: 63.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3564/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.5014 - inner: 63.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3565/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.5014 - inner: 63.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3566/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.5014 - inner: 63.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3567/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.5014 - inner: 63.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3568/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.5014 - inner: 63.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3569/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4818 - inner: 63.4804 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3570/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4559 - inner: 63.4545 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3571/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4389 - inner: 63.4375 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3572/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4248 - inner: 63.4235 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3573/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.4126 - inner: 63.4113 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3574/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4027 - inner: 63.4014 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3575/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3576/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3577/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3578/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3579/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3580/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3581/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3582/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4014 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3583/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3584/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3585/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3586/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3587/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3588/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.4013 - inner: 63.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3589/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.3983 - inner: 63.3970 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3590/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.3718 - inner: 63.3704 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3591/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.3513 - inner: 63.3500 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3592/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.3358 - inner: 63.3344 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3593/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.3223 - inner: 63.3210 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3594/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.3102 - inner: 63.3088 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3595/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.3019 - inner: 63.3005 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3596/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3597/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3598/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3599/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3600/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3601/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3602/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3603/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3604/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3605/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3606/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.3013 - inner: 63.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3607/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.3010 - inner: 63.2997 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3608/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.2790 - inner: 63.2776 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3609/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 63.2555 - inner: 63.2541 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3610/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.2161 - inner: 63.2147 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3611/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 63.1801 - inner: 63.1787 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3612/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.1515 - inner: 63.1502 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3613/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.1274 - inner: 63.1260 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3614/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.1130 - inner: 63.1117 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3615/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.1029 - inner: 63.1016 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3616/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.1013 - inner: 63.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3617/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.1013 - inner: 63.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3618/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0928 - inner: 63.0914 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3619/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0661 - inner: 63.0647 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3620/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0473 - inner: 63.0460 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3621/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0323 - inner: 63.0310 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3622/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0193 - inner: 63.0180 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3623/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0076 - inner: 63.0063 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3624/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0014 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3625/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3626/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3627/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3628/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3629/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3630/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3631/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3632/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3633/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3634/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3635/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3636/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3637/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3638/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3639/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3640/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3641/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3642/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3643/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3644/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3645/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 63.0013 - inner: 63.0000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3646/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.9873 - inner: 62.9860 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3647/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9634 - inner: 62.9621 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3648/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9474 - inner: 62.9461 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3649/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9340 - inner: 62.9327 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3650/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9222 - inner: 62.9208 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3651/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9111 - inner: 62.9098 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3652/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 62.9023 - inner: 62.9010 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3653/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.9013 - inner: 62.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3654/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9013 - inner: 62.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3655/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.9013 - inner: 62.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3656/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9013 - inner: 62.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3657/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 62.9013 - inner: 62.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3658/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.9013 - inner: 62.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3659/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.9013 - inner: 62.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3660/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.9001 - inner: 62.8988 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3661/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.8751 - inner: 62.8738 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3662/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8527 - inner: 62.8514 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3663/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8369 - inner: 62.8355 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3664/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.8231 - inner: 62.8218 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3665/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.8110 - inner: 62.8097 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3666/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8021 - inner: 62.8008 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3667/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3668/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3669/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3670/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3671/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3672/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3673/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3674/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3675/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3676/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3677/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3678/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3679/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.8013 - inner: 62.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3680/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.7868 - inner: 62.7855 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3681/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.7608 - inner: 62.7594 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3682/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.7440 - inner: 62.7427 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3683/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.7298 - inner: 62.7285 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3684/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.7174 - inner: 62.7160 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3685/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.7060 - inner: 62.7047 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3686/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.7013 - inner: 62.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3687/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.7013 - inner: 62.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3688/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.7013 - inner: 62.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3689/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.7013 - inner: 62.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3690/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.7013 - inner: 62.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3691/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.6942 - inner: 62.6929 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3692/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6660 - inner: 62.6647 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3693/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6468 - inner: 62.6455 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3694/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.6316 - inner: 62.6303 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3695/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6187 - inner: 62.6174 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3696/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6072 - inner: 62.6059 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3697/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3698/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3699/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3700/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3701/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3702/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3703/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3704/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3705/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3706/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3707/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3708/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3709/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3710/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3711/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3712/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3713/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3714/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3715/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.6013 - inner: 62.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3716/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5895 - inner: 62.5881 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3717/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5609 - inner: 62.5596 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3718/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.5425 - inner: 62.5412 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3719/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5275 - inner: 62.5261 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3720/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5145 - inner: 62.5132 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3721/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.5036 - inner: 62.5023 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3722/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3723/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3724/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3725/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3726/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3727/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3728/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3729/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3730/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3731/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3732/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3733/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3734/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3735/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3736/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3737/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3738/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3739/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3740/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3741/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3742/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3743/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3744/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3745/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3746/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.5013 - inner: 62.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3747/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.4892 - inner: 62.4879 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3748/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.4608 - inner: 62.4595 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3749/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 62.4431 - inner: 62.4418 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3750/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.4287 - inner: 62.4274 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3751/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.4158 - inner: 62.4145 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3752/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.4045 - inner: 62.4032 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3753/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.4013 - inner: 62.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3754/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.4013 - inner: 62.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3755/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3807 - inner: 62.3794 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3756/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.3571 - inner: 62.3558 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3757/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 62.3405 - inner: 62.3392 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3758/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3269 - inner: 62.3256 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3759/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3151 - inner: 62.3138 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3760/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3042 - inner: 62.3029 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3761/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3762/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3763/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3764/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3765/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3766/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3767/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3768/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3769/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3770/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3771/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3772/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3773/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3774/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3775/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3776/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3777/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3778/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3779/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3780/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3781/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3782/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3783/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3784/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3785/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3786/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3787/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3788/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3789/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3790/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3791/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3792/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3793/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3794/100000\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3795/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3796/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3797/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3798/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3799/100000\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3800/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3801/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3802/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3803/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3804/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3805/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3806/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3807/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3808/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3809/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3810/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3811/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3812/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3813/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3814/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3815/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3816/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3817/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3818/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3819/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3820/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3821/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3822/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3823/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3824/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3825/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3826/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3827/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3828/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3829/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3830/100000\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3831/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3832/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3833/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3834/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3835/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3836/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3837/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3838/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3839/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3840/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3841/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3842/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3843/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3844/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3845/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3846/100000\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3847/100000\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3848/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3849/100000\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3850/100000\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3851/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3852/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3853/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3854/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3855/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3856/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3857/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3858/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.3013 - inner: 62.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3859/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.2880 - inner: 62.2868 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3860/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2606 - inner: 62.2594 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3861/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2425 - inner: 62.2412 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3862/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2281 - inner: 62.2269 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3863/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2156 - inner: 62.2143 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3864/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2043 - inner: 62.2030 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3865/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3866/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3867/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3868/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3869/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3870/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3871/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3872/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3873/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3874/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3875/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3876/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3877/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3878/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3879/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3880/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3881/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3882/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3883/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3884/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3885/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3886/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3887/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3888/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3889/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3890/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3891/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3892/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3893/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3894/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.2013 - inner: 62.2000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3895/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.1994 - inner: 62.1981 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3896/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 62.1739 - inner: 62.1727 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3897/100000\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 62.1382 - inner: 62.1369 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3898/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 62.0923 - inner: 62.0910 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3899/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.0605 - inner: 62.0593 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3900/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 62.0337 - inner: 62.0324 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3901/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 62.0074 - inner: 62.0061 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3902/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.9657 - inner: 61.9645 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3903/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.9157 - inner: 61.9144 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3904/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8803 - inner: 61.8790 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3905/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8516 - inner: 61.8503 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3906/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.8264 - inner: 61.8251 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3907/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8059 - inner: 61.8046 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3908/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3909/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3910/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3911/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3912/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3913/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3914/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3915/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3916/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3917/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3918/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3919/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3920/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3921/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3922/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3923/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3924/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3925/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3926/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.8013 - inner: 61.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3927/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.7855 - inner: 61.7843 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3928/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.7592 - inner: 61.7580 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3929/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 61.7419 - inner: 61.7406 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3930/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 61.7271 - inner: 61.7258 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3931/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.7144 - inner: 61.7131 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3932/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.7035 - inner: 61.7022 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3933/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.7013 - inner: 61.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3934/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.7013 - inner: 61.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3935/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.7013 - inner: 61.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3936/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.7013 - inner: 61.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3937/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.6990 - inner: 61.6978 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3938/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.6723 - inner: 61.6710 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3939/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 61.6508 - inner: 61.6495 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3940/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 61.6347 - inner: 61.6334 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3941/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 61.6209 - inner: 61.6196 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3942/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 61.6087 - inner: 61.6074 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3943/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.6014 - inner: 61.6001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3944/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.6013 - inner: 61.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3945/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.6013 - inner: 61.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3946/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 61.6013 - inner: 61.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3947/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 61.6013 - inner: 61.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3948/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.5975 - inner: 61.5963 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3949/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.5691 - inner: 61.5678 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3950/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.5480 - inner: 61.5467 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3951/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.5322 - inner: 61.5309 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3952/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.5011 - inner: 61.4998 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3953/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4642 - inner: 61.4629 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3954/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4426 - inner: 61.4413 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3955/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 61.4292 - inner: 61.4280 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3956/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4173 - inner: 61.4161 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3957/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 61.4063 - inner: 61.4051 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3958/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3959/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3960/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3961/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3962/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3963/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3964/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3965/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3966/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3967/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3968/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3969/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3970/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3971/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4013 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3972/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3973/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3974/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3975/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3976/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3977/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3978/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3979/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3980/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3981/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3982/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3983/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3984/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3985/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3986/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3987/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3988/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3989/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3990/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3991/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3992/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3993/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3994/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3995/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3996/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3997/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3998/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.4012 - inner: 61.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 3999/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3887 - inner: 61.3875 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4000/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3605 - inner: 61.3593 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4001/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3433 - inner: 61.3420 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4002/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3292 - inner: 61.3279 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4003/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3167 - inner: 61.3155 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4004/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3054 - inner: 61.3041 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4005/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4006/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4007/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4008/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4009/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4010/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4011/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4012/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4013/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4014/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4015/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4016/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4017/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4018/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4019/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4020/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4021/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4022/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4023/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4024/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4025/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4026/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4027/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4028/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4029/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4030/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4031/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4032/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4033/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4034/100000\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4035/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4036/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4037/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4038/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4039/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4040/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4041/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4042/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4043/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4044/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4045/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4046/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4047/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4048/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4049/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4050/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4051/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4052/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4053/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4054/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4055/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4056/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4057/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4058/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4059/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4060/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4061/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4062/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4063/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4064/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4065/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4066/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4067/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4068/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4069/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4070/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4071/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4072/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4073/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4074/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4075/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4076/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4077/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4078/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4079/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4080/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4081/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4082/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4083/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4084/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4085/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4086/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4087/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4088/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4089/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4090/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4091/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4092/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4093/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4094/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4095/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4096/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4097/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4098/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4099/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4100/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4101/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4102/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4103/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4104/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4105/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4106/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4107/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4108/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4109/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4110/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4111/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4112/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4113/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4114/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.3012 - inner: 61.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4115/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.3011 - inner: 61.2999 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4116/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.2818 - inner: 61.2806 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4117/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.2491 - inner: 61.2479 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4118/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.2052 - inner: 61.2040 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4119/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1724 - inner: 61.1712 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4120/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1445 - inner: 61.1433 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4121/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1208 - inner: 61.1196 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4122/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1071 - inner: 61.1059 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4123/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4124/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4125/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4126/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4127/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4128/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4129/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4130/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4131/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4132/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4133/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4134/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4135/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4136/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4137/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4138/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4139/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4140/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4141/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4142/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4143/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4144/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4145/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4146/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4147/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4148/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4149/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4150/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4151/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4152/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4153/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4154/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4155/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4156/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4157/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4158/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4159/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4160/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4161/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4162/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4163/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4164/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4165/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4166/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4167/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4168/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4169/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4170/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4171/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4172/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4173/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4174/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4175/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4176/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4177/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4178/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4179/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4180/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4181/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4182/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4183/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4184/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4185/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4186/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4187/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4188/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4189/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4190/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4191/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4192/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4193/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4194/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4195/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4196/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4197/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4198/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4199/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4200/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4201/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4202/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4203/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4204/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4205/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4206/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4207/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4208/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4209/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4210/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4211/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4212/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4213/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4214/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 61.1012 - inner: 61.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4215/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.1011 - inner: 61.0999 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4216/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 61.0794 - inner: 61.0782 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4217/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.0554 - inner: 61.0542 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4218/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.0384 - inner: 61.0372 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4219/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.0243 - inner: 61.0231 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4220/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 61.0119 - inner: 61.0107 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4221/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9935 - inner: 60.9923 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4222/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9670 - inner: 60.9658 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4223/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9490 - inner: 60.9478 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4224/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9340 - inner: 60.9328 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4225/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.9209 - inner: 60.9197 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4226/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.9090 - inner: 60.9078 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4227/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9014 - inner: 60.9002 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4228/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4229/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4230/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4231/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4232/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4233/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4234/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4235/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4236/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4237/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4238/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4239/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4240/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4241/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4242/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4243/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4244/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4245/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4246/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4247/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4248/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4249/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4250/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4251/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4252/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4253/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4254/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4255/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4256/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4257/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4258/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.9012 - inner: 60.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4259/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.8921 - inner: 60.8909 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4260/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.8655 - inner: 60.8643 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4261/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.8476 - inner: 60.8464 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4262/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.8330 - inner: 60.8318 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4263/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8202 - inner: 60.8190 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4264/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8086 - inner: 60.8074 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4265/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.8013 - inner: 60.8001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4266/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4267/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4268/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4269/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4270/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4271/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4272/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4273/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4274/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4275/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.8012 - inner: 60.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4276/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.7911 - inner: 60.7899 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4277/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.7631 - inner: 60.7619 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4278/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.7449 - inner: 60.7437 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4279/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.7173 - inner: 60.7161 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4280/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6796 - inner: 60.6784 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4281/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6509 - inner: 60.6498 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4282/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6318 - inner: 60.6306 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4283/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6194 - inner: 60.6182 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4284/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6081 - inner: 60.6069 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4285/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6013 - inner: 60.6001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4286/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4287/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4288/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4289/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4290/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4291/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4292/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4293/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4294/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4295/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4296/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4297/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4298/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4299/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4300/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4301/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4302/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4303/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4304/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4305/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4306/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4307/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4308/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4309/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4310/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4311/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4312/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4313/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4314/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4315/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4316/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4317/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4318/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4319/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4320/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4321/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4322/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4323/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4324/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4325/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4326/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4327/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4328/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4329/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4330/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4331/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4332/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4333/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4334/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4335/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4336/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4337/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4338/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4339/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4340/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4341/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4342/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4343/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4344/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4345/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4346/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4347/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4348/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4349/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4350/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.6012 - inner: 60.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4351/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5926 - inner: 60.5914 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4352/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5653 - inner: 60.5642 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4353/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5472 - inner: 60.5460 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4354/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5324 - inner: 60.5313 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4355/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5196 - inner: 60.5184 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4356/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5079 - inner: 60.5068 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4357/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4358/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4359/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4360/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4361/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4362/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4363/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4364/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4365/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4366/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4367/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4368/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4369/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4370/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4371/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4372/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4373/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4374/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4375/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4376/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4377/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4378/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4379/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4380/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4381/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4382/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4383/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4384/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4385/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4386/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4387/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4388/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4389/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4390/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4391/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4392/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4393/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4394/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4395/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4396/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4397/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4398/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4399/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4400/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4401/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4402/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4403/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4404/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4405/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4406/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4407/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4408/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.5012 - inner: 60.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4409/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.4967 - inner: 60.4955 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4410/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4703 - inner: 60.4692 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4411/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.4512 - inner: 60.4500 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4412/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4362 - inner: 60.4351 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4413/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.4234 - inner: 60.4222 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4414/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4119 - inner: 60.4108 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4415/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4025 - inner: 60.4013 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4416/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4417/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4418/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4419/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4420/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4421/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4422/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4423/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4424/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4425/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4426/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4427/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4428/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4429/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4430/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4431/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4432/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4433/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4434/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4435/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4436/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4437/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4438/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4439/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4440/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4441/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4442/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4443/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4444/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4445/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.4012 - inner: 60.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4446/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3990 - inner: 60.3979 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4447/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3736 - inner: 60.3725 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4448/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3529 - inner: 60.3518 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4449/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3375 - inner: 60.3363 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4450/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3244 - inner: 60.3232 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4451/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3127 - inner: 60.3115 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4452/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3028 - inner: 60.3017 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4453/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4454/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4455/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4456/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4457/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4458/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4459/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4460/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4461/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4462/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4463/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4464/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4465/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4466/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4467/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4468/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4469/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4470/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4471/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4472/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4473/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3012 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4474/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4475/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4476/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4477/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4478/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4479/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4480/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4481/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4482/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4483/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4484/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4485/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4486/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4487/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4488/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4489/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4490/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4491/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4492/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4493/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4494/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4495/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4496/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4497/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4498/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4499/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4500/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4501/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4502/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4503/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4504/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4505/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4506/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4507/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4508/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4509/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4510/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4511/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4512/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4513/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4514/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4515/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4516/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4517/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4518/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4519/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4520/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4521/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4522/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4523/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4524/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4525/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4526/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4527/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4528/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4529/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4530/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4531/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4532/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4533/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4534/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4535/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4536/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4537/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4538/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4539/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4540/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4541/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4542/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4543/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4544/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4545/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4546/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4547/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4548/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4549/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4550/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4551/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4552/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4553/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4554/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4555/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4556/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4557/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4558/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4559/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4560/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4561/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4562/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4563/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4564/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4565/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4566/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4567/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4568/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4569/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4570/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4571/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4572/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4573/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4574/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4575/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4576/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4577/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4578/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4579/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4580/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4581/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4582/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4583/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4584/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4585/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4586/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4587/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4588/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4589/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4590/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4591/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4592/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4593/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4594/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4595/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4596/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4597/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4598/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4599/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4600/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4601/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4602/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4603/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4604/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4605/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4606/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4607/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4608/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4609/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4610/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4611/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4612/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4613/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4614/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4615/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4616/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4617/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4618/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4619/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4620/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4621/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.3011 - inner: 60.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4622/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.2973 - inner: 60.2962 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4623/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.2712 - inner: 60.2701 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4624/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.2514 - inner: 60.2503 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4625/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.2231 - inner: 60.2220 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4626/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1838 - inner: 60.1826 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4627/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.1546 - inner: 60.1534 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4628/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1302 - inner: 60.1291 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4629/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1159 - inner: 60.1148 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4630/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.1046 - inner: 60.1035 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4631/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4632/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4633/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4634/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4635/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4636/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4637/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4638/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4639/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4640/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4641/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4642/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4643/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.1011 - inner: 60.1000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4644/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.0907 - inner: 60.0896 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4645/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.0630 - inner: 60.0619 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4646/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 60.0446 - inner: 60.0435 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4647/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 60.0299 - inner: 60.0288 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4648/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 60.0170 - inner: 60.0158 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4649/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9980 - inner: 59.9969 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4650/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9659 - inner: 59.9648 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4651/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9471 - inner: 59.9460 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4652/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9325 - inner: 59.9314 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4653/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9197 - inner: 59.9186 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4654/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9081 - inner: 59.9070 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4655/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9012 - inner: 59.9001 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4656/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4657/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4658/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4659/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4660/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4661/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4662/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4663/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4664/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4665/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4666/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4667/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4668/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4669/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4670/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4671/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4672/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4673/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4674/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4675/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4676/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4677/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4678/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4679/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4680/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4681/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4682/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4683/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4684/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4685/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4686/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4687/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4688/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4689/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4690/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4691/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4692/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4693/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4694/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4695/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4696/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4697/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4698/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4699/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4700/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4701/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4702/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4703/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4704/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4705/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4706/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4707/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4708/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4709/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4710/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4711/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4712/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4713/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4714/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4715/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4716/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4717/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4718/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4719/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4720/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4721/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4722/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4723/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4724/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4725/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4726/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4727/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4728/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4729/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4730/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4731/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4732/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4733/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4734/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4735/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4736/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4737/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4738/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4739/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4740/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4741/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4742/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4743/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4744/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4745/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4746/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4747/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4748/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4749/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4750/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4751/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4752/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4753/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4754/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4755/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4756/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4757/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4758/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4759/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4760/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4761/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4762/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4763/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4764/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4765/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4766/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4767/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4768/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4769/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4770/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4771/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4772/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4773/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4774/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4775/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4776/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4777/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4778/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4779/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4780/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.9011 - inner: 59.9000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4781/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.8953 - inner: 59.8942 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4782/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.8689 - inner: 59.8678 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4783/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.8505 - inner: 59.8494 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4784/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.8354 - inner: 59.8343 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4785/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.8223 - inner: 59.8212 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4786/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.8107 - inner: 59.8096 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4787/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.8018 - inner: 59.8007 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4788/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.8011 - inner: 59.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4789/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.8011 - inner: 59.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4790/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.8011 - inner: 59.8000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4791/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7840 - inner: 59.7829 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4792/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7579 - inner: 59.7568 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4793/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7406 - inner: 59.7395 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4794/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7264 - inner: 59.7253 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4795/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7137 - inner: 59.7126 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4796/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7030 - inner: 59.7019 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4797/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4798/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4799/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4800/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4801/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4802/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4803/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4804/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4805/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4806/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4807/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4808/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4809/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4810/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4811/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4812/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4813/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4814/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4815/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4816/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4817/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4818/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4819/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4820/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4821/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4822/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4823/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4824/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4825/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4826/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4827/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4828/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4829/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4830/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4831/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4832/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.7011 - inner: 59.7000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4833/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6855 - inner: 59.6844 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4834/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.6585 - inner: 59.6574 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4835/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6409 - inner: 59.6398 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4836/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6263 - inner: 59.6252 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4837/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.6136 - inner: 59.6125 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4838/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6030 - inner: 59.6019 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4839/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4840/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4841/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4842/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4843/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4844/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4845/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4846/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4847/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4848/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4849/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4850/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4851/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4852/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4853/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4854/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4855/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.6011 - inner: 59.6000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4856/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.5963 - inner: 59.5952 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4857/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.5700 - inner: 59.5689 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4858/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.5506 - inner: 59.5495 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4859/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.5354 - inner: 59.5343 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4860/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.5219 - inner: 59.5208 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4861/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.5098 - inner: 59.5087 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4862/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 59.5015 - inner: 59.5004 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4863/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.5011 - inner: 59.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4864/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.5011 - inner: 59.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4865/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.5011 - inner: 59.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4866/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.5011 - inner: 59.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4867/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.5011 - inner: 59.5000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4868/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4963 - inner: 59.4952 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4869/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 59.4689 - inner: 59.4678 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4870/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4490 - inner: 59.4479 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4871/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4335 - inner: 59.4325 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4872/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4199 - inner: 59.4188 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4873/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4078 - inner: 59.4067 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4874/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4875/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4876/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4877/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4878/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4879/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4880/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4881/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4882/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4883/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4884/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4885/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4886/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4887/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4888/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4889/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4890/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4891/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4892/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4893/100000\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4894/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4895/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4896/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4897/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4898/100000\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4899/100000\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4900/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4901/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4902/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4903/100000\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4904/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4905/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4906/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4907/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4908/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4909/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4910/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4911/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4912/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4913/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4914/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4915/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4916/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4917/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4918/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4919/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4920/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4921/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4922/100000\n",
      "10000/10000 [==============================] - 0s 35us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4923/100000\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4924/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4925/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4926/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4927/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4928/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4929/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4930/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4931/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4932/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4933/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4934/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4935/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4936/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4937/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4938/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4939/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4940/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4941/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4942/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4943/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4944/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4945/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4946/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4947/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4948/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4949/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4950/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4951/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4952/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4953/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4954/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4955/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4956/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4957/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4958/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4959/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4960/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4961/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4962/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.4011 - inner: 59.4000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4963/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.3900 - inner: 59.3890 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4964/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3615 - inner: 59.3605 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4965/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3427 - inner: 59.3417 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4966/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.3281 - inner: 59.3271 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4967/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.3155 - inner: 59.3144 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4968/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3042 - inner: 59.3031 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4969/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4970/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4971/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4972/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4973/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4974/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4975/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4976/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4977/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4978/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4979/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4980/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4981/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4982/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4983/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4984/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4985/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4986/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4987/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4988/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4989/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4990/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4991/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4992/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4993/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4994/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4995/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4996/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4997/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4998/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 4999/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5000/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5001/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5002/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5003/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5004/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5005/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5006/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5007/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5008/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5009/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5010/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5011/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5012/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5013/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5014/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5015/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5016/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5017/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5018/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5019/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5020/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5021/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5022/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5023/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5024/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5025/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5026/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5027/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5028/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5029/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5030/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5031/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5032/100000\n",
      "10000/10000 [==============================] - 0s 34us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5033/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5034/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5035/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5036/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5037/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5038/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5039/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5040/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5041/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5042/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5043/100000\n",
      "10000/10000 [==============================] - 0s 29us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5044/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5045/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5046/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5047/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5048/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5049/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5050/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5051/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5052/100000\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5053/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5054/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5055/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5056/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5057/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5058/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5059/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5060/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5061/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5062/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5063/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5064/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3010 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5065/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5066/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5067/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5068/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5069/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5070/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5071/100000\n",
      "10000/10000 [==============================] - 0s 31us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5072/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3010 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5073/100000\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 5074/100000\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 59.3011 - inner: 59.3000 - inner_1: 0.0000e+00 - acc: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa402895b38>"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa410cc3630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup_vals = numpy.random.beta(2,2, size=(n_students*n_questions))\n",
    "setup_vals = numpy.random.normal(0.5, 1/6, size=(n_students*n_questions))\n",
    "setup_vals = numpy.clip(setup_vals, 0,1)\n",
    "plt.hist(setup_vals)\n",
    "from keras.callbacks import EarlyStopping\n",
    "print(len(all_qz), len(all_sz))\n",
    "# wz = m.get_weights()\n",
    "m = generate_qs_model(qn_table, s_table, Adam(), comp_lims=True)\n",
    "# m.set_weights(wz)\n",
    "es = EarlyStopping(monitor=\"loss\", restore_best_weights=True, patience=10)\n",
    "m.fit(x=[all_qz,all_sz], y=numpy.array(setup_vals).reshape(-1,1), batch_size=100, shuffle=True, epochs=100000, verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.    0.    0.    0.    0.    0.    0.    0.    4.95  0.    0.    0.\n",
      "   0.    0.    2.12  0.    0.    0.    0.    2.85  0.    0.    0.    4.5\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.84  0.    0.    4.28  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.31  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.03  0.    5.45  0.    0.    0.    0.    5.53  0.    6.36  0.\n",
      "   2.86  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    6.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    5.56  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.06  4.11  1.68  0.    4.42  0.    0.    0.    2.94  0.    0.    3.26\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.45  0.    0.    0.    4.27  0.    0.    0.    0.    7.36  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.88  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.97  0.    0.\n",
      "   0.    0.    0.    0.    0.    3.23  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.62  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    5.17  0.    0.    0.    0.\n",
      "   0.    0.    0.    1.66  0.    0.    3.02  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    1.52  0.    0.    0.    0.    0.    0.\n",
      "   0.    5.11  0.    0.    0.    0.    0.    0.    0.    0.    3.48  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.9   4.27  0.    0.\n",
      "   0.    0.    0.    5.17  8.06  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.79  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    3.96  1.55  5.13  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.18  0.    0.    0.    0.    0.    0.    0.\n",
      "   4.51  4.86  0.    0.    0.    0.    0.    0.    0.    5.1   0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    6.02  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    6.6   0.    0.    0.    6.07\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.38  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    3.76  0.    0.    0.    4.16  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.56  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.06  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    3.51  4.47  0.    0.    0.    0.    0.    0.\n",
      "   7.33  0.    0.    5.49  0.    0.    0.    1.19  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    1.78  0.    6.03  0.    0.    5.31  0.  ]\n",
      " [ 0.    0.    0.    0.    5.15  0.    0.    0.    0.    7.11  0.    0.    0.\n",
      "   0.    5.55  4.3   0.    0.    0.    2.8   0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    1.59  0.    0.    0.    0.    5.58  0.\n",
      "   3.84  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.87  4.51  0.    0.    3.71  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    6.07  0.    0.    0.    0.  ]\n",
      " [ 0.    6.64  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.    0.    0.    2.    5.75  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.97  0.    0.    0.    4.63  4.92  0.    0.    0.\n",
      "   5.9   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.62  0.\n",
      "   3.47  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.45  0.    0.    0.    0.    0.    0.    3.21  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.02  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.92  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.52  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.45  0.    0.    0.    0.    0.    0.    0.    0.    0.    4.4   0.    0.\n",
      "   0.    0.    0.    0.    0.    5.38  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.22  2.84  7.39  0.    0.  ]\n",
      " [ 5.68  0.    0.    0.    0.    0.    5.56  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.65  0.    0.    6.94  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.78  0.    0.    0.    0.    0.    3.43  0.    4.12  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.16  0.    2.26  0.    0.    0.    0.    0.    0.\n",
      "   4.92  0.    0.    0.    0.    0.    0.    2.5   0.    0.  ]\n",
      " [ 7.49  0.    0.    0.    0.    0.    0.    0.    3.76  0.    0.    0.    0.\n",
      "   0.    0.    5.02  0.    0.    0.    0.    0.    0.    0.    0.    3.6\n",
      "   0.    5.35  0.    0.    0.    0.    0.    0.    0.    0.    0.    4.98\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.06  0.    4.19  0.    0.    0.\n",
      "   0.    0.    4.82  3.43  0.    0.    0.    2.98  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.17  0.    2.29  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    2.68  0.    0.    0.    3.01  0.    4.31  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    5.36  0.    0.    7.2   0.    4.09  4.21  0.    2.89\n",
      "   0.    3.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.93  0.    0.    0.    1.74  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.33  0.    0.    0.    1.76  2.33  0.    0.    0.    0.    4.33\n",
      "   0.    0.    0.    0.    0.    0.    0.    2.51  1.69  0.    0.    0.    0.\n",
      "   0.    3.98  0.    3.66  0.    0.    0.    0.    0.    0.    0.    3.38\n",
      "   0.    0.    0.    0.    5.01  4.75  0.    0.    2.42  0.    0.    0.  ]\n",
      " [ 0.    0.    4.72  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.67  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    6.33  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.98  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.63  0.    1.49\n",
      "   0.    0.    4.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.11  0.    0.    0.    0.    0.    7.12  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.55  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.45  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    8.09  0.    0.    6.    0.    0.    0.    0.\n",
      "   0.    3.98  0.    0.    0.    0.    0.    0.    0.    0.    1.82  0.\n",
      "   1.16  0.    0.    0.    0.    0.    0.    0.    4.61  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.75  0.    2.28  1.05\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 3.94  4.82  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.52  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.81  4.26  0.    0.    4.69\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.64  0.    6.92  0.    0.    0.    0.\n",
      "   0.    6.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.44  0.    0.    0.    0.    0.    1.57  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.99  5.6   0.    0.    0.    0.    0.    5.29  0.    0.    0.\n",
      "   1.93  3.96  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.85\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.39  0.    0.    0.    8.03  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.42  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.49  0.    0.    0.    0.    4.61]\n",
      " [ 0.    3.52  0.    0.    0.    0.    0.    6.92  0.    0.    0.    0.    0.\n",
      "   0.    2.08  0.    0.    0.    0.    0.    3.58  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.6   0.    0.    0.    0.    5.24  4.66\n",
      "   0.    4.78  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.63  0.    0.    0.    0.    0.\n",
      "   0.    3.64  0.    0.    0.    0.    4.3   0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.05  0.    0.    0.    0.    0.\n",
      "   4.35  0.    0.    0.    0.    5.64  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.23  3.77  7.45  0.    0.    0.\n",
      "   0.    0.    4.28  4.16  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    1.96  5.51  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.25  0.\n",
      "   1.64  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.55  0.    0.    0.    0.    0.    0.    0.    4.5 ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    5.96  0.    0.    0.    0.    0.\n",
      "   0.    0.    4.36  5.09  0.    0.    0.    0.    5.37  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.32  0.    0.    0.    0.    0.    0.    0.    1.76  0.    2.14  0.    0.\n",
      "   0.    1.99  0.    4.55  0.    0.    0.    0.    0.    4.54  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.37\n",
      "   0.    0.    0.    0.    0.    5.25  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.53  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    5.6   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.37  0.    0.    0.    0.    0.    0.    0.    5.95  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    7.73  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    1.24  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    1.19  0.    0.    0.    0.    0.    4.95\n",
      "   0.    0.    1.79  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.15  3.72  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 3.91  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.13  5.36  0.    4.04  0.    0.    0.    4.74  0.    0.\n",
      "   7.64  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.04  0.    0.    0.    4.38  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    2.14  0.    0.    0.    0.    0.\n",
      "   2.33  0.    0.    3.57  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.29  5.35  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.81  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    4.24  5.47  4.65  0.    0.    0.    0.    0.    0.    0.    3.54\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.81  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    2.04  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    6.87  0.    0.    0.    5.54  0.    0.\n",
      "   0.    0.    0.    5.38  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    5.82  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.63  0.    0.    0.    0.    0.\n",
      "   0.    0.    2.04  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.27  0.    0.    0.    4.68  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.41  0.    0.    4.66  0.    0.    3.67  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.25  5.01  0.    0.    0.\n",
      "   6.67  0.    0.    5.19  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    3.65  3.66  0.    0.    0.    0.    0.    0.\n",
      "   2.52  4.23  4.8   0.    0.    0.    0.    0.    0.    0.    5.39  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.9   0.    0.    0.    0.    0.    0.    0.\n",
      "   7.67  3.28  0.    0.    0.    4.07  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.73  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 1.68  3.02  0.    0.    7.93  0.    4.16  0.    4.33  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    1.73  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.42  0.    0.    0.    1.65  0.    0.    0.    3.9   0.    0.    0.    0.\n",
      "   0.    5.61  0.    0.    0.    1.9   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.06  0.    0.\n",
      "   4.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.07\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    5.48  0.    0.    0.    4.92  0.    0.    0.    0.    0.    0.    0.\n",
      "   3.84  5.13  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.38  0.    0.    0.    0.    7.48  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.89  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.29  0.    0.    0.    0.    0.    3.27  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    3.21  0.    0.    0.    0.    0.    4.92  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 2.91  3.57  0.    0.    0.    0.    0.    3.9   0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.93  0.\n",
      "   3.09  0.    0.    0.    4.98  0.    0.    0.    4.84  0.    4.73  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.69  0.    4.81\n",
      "   0.    0.    0.    4.59  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.44  2.99  0.    0.    0.    0.    0.    6.79  0.    0.\n",
      "   0.    0.    4.78  0.    0.    1.33  5.33  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    2.47  0.    0.    0.\n",
      "   2.58  0.    3.78  0.    0.    0.    0.    3.96  5.46  0.    3.95  0.    0.\n",
      "   0.    4.58  0.    0.    0.    0.    0.    0.    0.    0.    0.    3.06\n",
      "   0.    0.    0.    5.41  0.    0.    0.    0.    3.96  0.    2.79  0.    0.\n",
      "   0.    3.41  0.    0.    0.    0.    0.    0.    0.    0.    7.16  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    2.8   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.61]\n",
      " [ 0.    0.    0.    0.    2.06  0.    5.29  4.79  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.97  2.97  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.05  0.    0.    0.    3.69  0.    5.91  4.37  0.    0.\n",
      "   1.82  0.    0.    0.    0.    0.    7.32  3.69  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.08  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.61  0.    0.    4.26  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    4.99  3.62  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.27  0.    4.29  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.65  0.    0.    0.    0.    0.    0.    0.    0.    5.17  3.97\n",
      "   0.    8.17  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.62  0.    0.    0.    0.    0.    0.    2.47  0.    0.    0.    0.\n",
      "   4.8   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    1.18  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    4.69  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    6.22  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.5   0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.92  0.    0.    0.    0.    0.\n",
      "   0.    5.77  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.18  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.77  0.    0.    0.    0.    5.09  0.    0.  ]\n",
      " [ 5.67  0.    0.    0.    0.    0.    4.52  0.    0.    0.    0.    4.51\n",
      "   6.84  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.09  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.82  0.    5.28  0.    1.67\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    1.18  0.    0.    0.\n",
      "   5.81  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.88\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.15  0.    0.    0.    0.\n",
      "   3.88  0.    0.    0.    0.    0.    0.    0.    0.    0.    4.    0.    0.\n",
      "   0.    0.    0.    3.05  0.    0.    0.    0.    1.9   1.56  0.    0.    0.\n",
      "   0.    0.    5.24  4.42  0.    0.    0.    0.    0.    0.    0.    4.14\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.47  0.    0.    0.    0.\n",
      "   0.    0.    0.    4.59  5.44  0.    0.    0.    0.    0.    0.    1.46\n",
      "   0.    0.    5.28  0.    0.    0.    0.    4.95  5.3   3.31  0.    0.    0.  ]\n",
      " [ 3.96  0.    0.    4.23  0.    3.39  0.    0.    0.    0.    0.    0.    0.\n",
      "   1.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.51  0.    0.    4.87  4.24  0.    0.    0.    0.    0.    0.    7.49\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.11  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.7\n",
      "   0.    0.    5.14  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    3.96  0.    0.    4.88  0.    0.\n",
      "   0.    6.93  0.    0.    5.29  0.    0.    0.    0.    4.33  0.    0.\n",
      "   5.1   0.    0.    1.71  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.5   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.02  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.98  0.\n",
      "   2.94  0.    5.55  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.2   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.7 ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.26  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.83  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.19  0.    4.79  0.    0.    7.81\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.47  0.    0.    0.    0.    0.\n",
      "   0.    5.26  2.82  0.    0.    0.    0.    0.    1.97  0.    4.05]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    2.61  0.    0.    0.    2.09\n",
      "   0.    2.22  0.    3.18  0.    0.    0.    0.    5.25  6.77  0.    0.    0.\n",
      "   0.    0.    0.    3.9   0.    0.    0.    0.    0.    5.8   0.    0.    0.\n",
      "   0.    0.    0.    6.21  0.    0.    0.    0.    0.    1.1   0.    0.    0.\n",
      "   0.    0.    1.85  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.18  0.    0.    3.58  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.48  0.    2.54  1.91  0.    0.    0.    3.82  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    4.54  0.    6.03  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.6   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.49  5.08  0.    0.    0.    3.21  0.    3.95  0.    4.23  4.48  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    5.21  0.    0.    0.    0.\n",
      "   3.06  0.    0.    0.    0.    0.    0.    0.    0.    0.    2.43  0.\n",
      "   3.95  2.42  0.    0.    0.    0.    0.    6.34  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.41  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    3.22  0.    0.    0.    0.    0.\n",
      "   0.    0.    1.92  0.    0.    0.    4.77  0.    0.    3.49  5.77  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    6.13  0.    0.    3.57  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.08\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.34  0.    0.\n",
      "   0.    4.94  0.    0.    0.    3.28  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    6.16  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.19  0.    5.18  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.31  0.    6.64  1.08  0.    0.    0.    0.    0.    0.    2.7   0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.01\n",
      "   0.    4.34  0.    0.    0.    0.    0.    0.    3.91  0.    0.    3.62\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.73  0.    0.    0.\n",
      "   1.27  0.    0.    0.    0.    0.    0.    0.    6.15  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    2.94  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    3.02  0.    0.    0.    0.    0.    0.    0.\n",
      "   4.05  0.    0.    0.    0.    0.    0.    0.    0.    0.    1.49  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    2.4   0.    0.    0.    0.    0.    0.    0.    6.33\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.14\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.65  0.    0.    0.    0.    0.    5.75  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    7.28  2.99  0.    4.65  0.    0.    0.    0.  ]\n",
      " [ 4.75  0.    0.    4.16  0.    5.98  0.    5.56  0.    3.87  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.15  0.    0.    0.\n",
      "   0.    0.    0.    0.    5.98  0.    0.    0.    0.    0.    0.    4.76\n",
      "   0.    0.    0.    4.67  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.22  0.    0.    0.    6.01  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.91  0.    0.    1.56  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    6.39  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.37  0.    0.    0.    0.\n",
      "   4.56  0.    0.    6.13  0.    0.    0.    0.    0.    0.    0.    6.43\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.52  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.51  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.73  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    4.58  0.    0.    0.    0.    0.    0.    5.44  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.82  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.35  3.81  0.    0.    0.    0.    4.73  1.14  0.    0.\n",
      "   0.    0.    0.    0.    0.    3.68  0.    0.    0.    0.    0.    0.    0.\n",
      "   4.05  0.    0.    0.    0.    0.    0.    0.    0.    4.31  0.    0.    0.\n",
      "   0.    8.32  3.67  0.    4.24  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.74  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.17  0.  ]\n",
      " [ 0.    0.    0.    2.83  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.16  3.58  0.    0.    0.    0.    0.    0.    0.    0.    0.    3.52\n",
      "   0.    2.04  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.67  5.34\n",
      "   4.88  0.    0.    4.35  0.    0.    0.    0.    5.82  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    1.88  0.    0.    0.    0.    0.    0.    4.23\n",
      "   0.    0.    0.    0.    1.1   0.    0.    0.    0.    1.01  0.    0.    0.\n",
      "   6.16  0.    0.    0.    0.    4.64  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.65  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.11  0.    0.    0.    0.    4.78  0.    0.    0.\n",
      "   0.    0.    0.    4.95  0.    0.    0.    2.46  0.    0.    0.    0.\n",
      "   6.7   0.    0.    0.    0.    3.4   2.22  0.    0.    0.    0.    0.\n",
      "   3.49  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.92  0.    5.54  3.74  5.73  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    6.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.34  0.    0.    0.    0.    0.    6.96  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    6.06  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.03  0.    0.    0.    5.23  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    6.08  2.74  0.    0.    0.    0.    0.    2.98  5.17  0.    0.\n",
      "   0.    0.    0.    0.    2.78  0.    0.    0.    1.98  0.    0.    5.6\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.74\n",
      "   1.71  0.    0.    0.    0.    0.    1.33  0.    0.    0.    0.    3.2\n",
      "   1.44  0.    0.    0.    1.86  0.    0.    0.    0.    2.54  4.71  0.\n",
      "   6.35  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.61  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    1.65  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.09  0.    2.26  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.41  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    6.01  0.    0.    0.    4.12  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.11  0.    0.    0.    0.    0.    0.    0.    7.12\n",
      "   5.35  0.    0.    0.    4.08  0.    0.    0.    0.    4.92  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 3.55  0.    0.    0.    0.    2.94  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    2.75  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.32  4.31  0.    2.28  5.57  0.    0.    0.    7.28  0.\n",
      "   3.88  0.    0.    0.    0.    0.    0.    0.    3.98  0.    2.32  0.    0.\n",
      "   0.    5.01  2.33  3.56  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.84  4.4\n",
      "   0.    0.    3.38  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    2.42  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 2.26  0.    0.    3.31  5.75  4.43  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.42  0.    0.    0.    0.    4.89  0.    7.14\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.8   4.35  0.    0.\n",
      "   0.    0.    0.    2.53  5.29  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.07  0.    0.    0.    0.    0.    0.    2.51  0.    0.    0.    0.    0.\n",
      "   5.12  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    1.08  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    3.88  0.    0.    0.    0.    0.    0.\n",
      "   4.43  0.    0.    6.72  0.    4.08  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.    4.57  5.02  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.52  0.    0.    4.91  0.    0.    0.    4.87  4.34  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.17  0.    0.    0.    0.    6.44  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    3.8   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.43  0.    0.    0.\n",
      "   7.55  0.    0.    0.    0.    0.    0.    0.    0.    0.    1.24  0.    0.\n",
      "   5.19  0.    0.    0.    4.41  0.    5.67  0.    0.    0.    0.    0.\n",
      "   4.32  4.09  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.16  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.73  0.    0.\n",
      "   1.8   5.06  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    3.54  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.19  0.    0.    4.07  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    1.55  5.89  0.    0.    4.35  0.    4.35  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.15  0.    0.    0.    0.    0.    0.    0.    0.    3.34  0.    0.\n",
      "   0.    0.    4.    0.    2.01  0.    0.    0.    1.38  0.    1.97  2.54\n",
      "   0.    0.    3.78  0.    0.    7.93  0.    2.79  0.    3.31  0.    0.    0.\n",
      "   0.    4.43  0.    0.    0.    4.93  0.    0.    0.    0.  ]\n",
      " [ 3.9   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.3   7.43  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.93  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.19  0.    5.72  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.9   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    4.77  0.    0.    0.    3.32  0.    6.47\n",
      "   0.    0.    0.    5.44  6.41  0.    0.    0.    2.86  0.    0.    0.    0.\n",
      "   3.6   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    3.24  0.    0.    0.    0.    0.    0.    3.9\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.84  0.    5.16  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.49  0.    0.    0.    0.    0.    0.    4.13  0.    0.    0.\n",
      "   2.27  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.27  0.    5.63  0.    0.    0.    0.    0.    3.55  0.    0.    0.    0.\n",
      "   0.    0.    3.69  0.    5.01  0.    0.    5.    5.28  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.99  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    1.02  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.65  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.82  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    4.2   4.01  0.    0.    0.    0.    0.\n",
      "   3.5   0.    0.    0.    5.59  0.    0.    6.83  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.59  0.    0.    0.    3.02  0.\n",
      "   2.96  0.    4.45  0.    0.    0.    3.6   0.    0.    0.    4.82  0.    0.\n",
      "   4.55  0.    0.    4.03  1.07  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.72  5.1   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.11  0.    4.54  0.    0.    0.    1.97  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    5.29  4.34  0.    0.\n",
      "   4.43  0.    0.    0.    0.    0.    0.    0.    1.62  0.    0.    0.    0.\n",
      "   0.    4.25  0.    0.    0.    0.    0.    0.    7.28  0.    0.    2.64\n",
      "   0.    0.    0.    4.59  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.8   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.46  0.    0.\n",
      "   5.13  0.    2.94  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    2.74  0.    0.    0.    0.    0.    0.    0.    4.59  0.  ]\n",
      " [ 0.    0.    4.72  0.    2.49  0.    0.    0.    2.94  0.    0.    2.18\n",
      "   0.    0.    0.    1.71  0.    0.    0.    0.    0.    0.    4.44  0.    0.\n",
      "   0.    0.    1.36  0.    0.    3.8   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.02  0.    0.    0.    0.    0.    4.66  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   7.18  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.33  0.    0.    0.    0.    0.    0.    0.    0.    3.67  0.    0.\n",
      "   4.21  0.    0.    0.    5.08  0.    0.    1.04  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    7.33  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.34  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.62  3.78  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.34  0.    0.    0.\n",
      "   0.    0.    0.    0.    3.47  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.96  3.77  0.    4.99  0.    0.    0.    0.    0.    0.    0.    4.17\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 5.7   0.    0.    0.    0.    0.    0.    3.41  0.    0.    2.11  0.    0.\n",
      "   0.    0.    1.67  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    2.04  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.47  4.74  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.93  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.92  6.48\n",
      "   1.41  0.    0.    0.    4.5   0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    3.75  0.    0.    3.23  0.    0.    0.    0.    0.\n",
      "   0.    0.    2.38  0.    0.    7.8   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.4   2.16  0.    0.    0.    0.    0.    0.    2.13  0.    5.59\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.77  4.26  0.    0.    0.    0.    3.13  0.    0.\n",
      "   0.    0.    1.47  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.67  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.03  4.63  3.36  0.    5.09  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.57  0.    0.    0.    4.83  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.22  0.    0.    0.    0.    0.    4.36\n",
      "   0.    0.    0.    0.    0.    3.14  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.79  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    7.04  0.    0.    3.95  0.    0.    0.    3.03\n",
      "   0.    0.    0.    5.68  0.    4.95  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    3.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.94  0.    0.    4.18  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    6.54  0.    0.    0.\n",
      "   0.    3.47  0.    0.    0.    0.    3.92  0.    6.06  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.95  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.28  0.    5.16  0.    4.15  0.    0.    0.    0.    0.    0.    0.\n",
      "   4.31  0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.46  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.21  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    2.24  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.03  0.    0.    7.87]\n",
      " [ 0.    0.    1.22  0.    0.    0.    0.    0.    0.    2.95  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    2.95  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.72  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.45  3.56  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.18  0.    0.    6.1   4.51  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.51  4.99  0.    2.03  0.    0.    0.\n",
      "   0.    0.    0.    0.    4.99  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.92  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    1.38  0.    3.69  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.31  0.    0.    3.79  0.    0.    0.    0.    0.    0.\n",
      "   5.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.78  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.26  4.19  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.58  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    8.26  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.02  1.25  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.62\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.41  0.    3.12  0.    0.    0.\n",
      "   2.17  0.    0.    0.    5.48  0.    0.    3.34  0.    7.41  0.    0.\n",
      "   6.02  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.86  0.    0.    0.    4.32  0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    5.44  2.82  0.    0.    0.    0.\n",
      "   0.    0.    5.52  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.71  4.42  0.    3.34  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.61  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.61\n",
      "   0.    0.    0.    0.    0.    0.    5.89  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.1   0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.6   0.    0.    0.    0.    0.    0.    0.    0.    3.48\n",
      "   0.    0.    0.    0.    0.    5.9   0.    0.    0.    5.46  5.27  5.4\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.38  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    2.96  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    2.71  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    5.55  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.84  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.8   0.    0.    0.    0.    3.91  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    2.71  3.85  0.    1.42  0.    0.    0.\n",
      "   0.    3.84  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.57  5.92  6.04  6.24  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    5.05  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.2   0.    0.    0.    2.65  0.    2.66  0.    0.    0.    2.87\n",
      "   0.    0.    2.73  5.42  2.96  0.    0.    0.    0.    4.76  0.    0.    0.\n",
      "   0.    0.    1.66  0.    0.    0.    0.    0.    0.    0.    0.    3.9\n",
      "   0.    0.    0.    0.    0.    0.    3.26  0.    0.    0.    0.    0.    0.\n",
      "   0.    3.22  0.    0.    0.    0.    0.    4.54  0.    0.    0.    0.\n",
      "   1.78  0.    0.    0.    0.    0.    0.    2.97  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    8.8   0.    0.    0.    0.    2.96  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    7.63  0.    3.68  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.56  0.    6.4   0.    0.    0.    0.    0.    0.\n",
      "   3.24  0.    0.    0.    0.    0.    0.    0.    0.    5.08  0.    3.81\n",
      "   0.    0.    0.    4.86  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.48  0.    0.    0.    0.    0.    4.09  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    3.57  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.95  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    1.05  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.75  0.    0.    0.    0.    0.    0.    0.    3.66\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.75  0.    0.\n",
      "   5.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    8.2   0.    1.83  0.    0.    0.    0.    0.    2.2   0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.27  0.    0.    0.    0.\n",
      "   0.    0.    0.    1.09  0.    3.97  0.    4.33  0.    0.  ]\n",
      " [ 0.    0.    0.    5.21  0.    0.    0.    0.    0.    4.86  0.    0.    0.\n",
      "   3.12  0.    5.77  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.3   2.37  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.05  0.    4.58  0.    0.    0.    0.    5.07  0.    0.    0.    0.\n",
      "   3.52  0.    0.    0.    0.    3.88  0.    0.    0.    4.5   0.    0.    0.\n",
      "   0.    0.    7.38  0.    0.    0.    0.    0.    4.83  0.    0.    0.    0.\n",
      "   0.    0.    2.59  3.18  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    1.55  0.    0.    3.61  0.    3.19  0.    0.    0.    0.\n",
      "   4.37  0.    4.88  4.53  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.85  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    7.56  0.    0.    0.    0.    0.    0.    3.91\n",
      "   0.    0.    0.    0.    0.    3.96  0.    0.    0.    0.    0.    0.\n",
      "   3.75  0.    0.    5.54  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.73  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.09\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    6.5   0.    0.    3.95  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.8   1.74  0.    0.    0.    0.    0.    3.7   0.    0.    0.    0.\n",
      "   5.08  0.    5.83  0.    0.    0.    0.    0.    0.    5.4   0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.73  0.    0.    0.    0.    0.    0.    0.\n",
      "   2.36  0.    5.01  0.    0.    0.    0.    0.    0.    0.    0.    4.29\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.05  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    4.94  0.    0.    0.    0.\n",
      "   3.9   0.    0.    2.04  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.47  0.    0.    0.    0.    4.93  0.    0.    0.    0.    0.    4.44\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.95  0.    0.\n",
      "   4.4   0.    5.17  0.    0.    0.    6.55  0.    0.    0.    0.    0.\n",
      "   2.76  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    2.48  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    3.06  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    1.68  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.07  0.    1.08  0.    1.95  0.    0.    0.    3.81\n",
      "   0.    0.    3.64  0.    0.    7.35  0.    0.    0.    1.81  0.    0.    0.\n",
      "   0.    0.    0.    4.84  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.77  0.    0.    0.    5.08  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    4.15  0.    0.    0.\n",
      "   0.    0.    5.81  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.94  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    7.    0.    4.26  3.62  0.    4.7   0.    0.\n",
      "   5.55  0.    0.    0.    0.    0.    0.    1.87  0.    0.    4.67  0.\n",
      "   3.53  0.    0.    4.55  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    3.55  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.17  0.    0.    0.\n",
      "   0.    0.    0.    0.    3.47  0.    0.    0.    5.44  0.    0.    0.    0.\n",
      "   1.3   0.    4.56  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.54  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    6.84  0.    0.    0.    0.    0.    4.1\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.42  0.    0.\n",
      "   0.    0.    5.02  0.    0.    0.    0.    0.    5.49  0.  ]\n",
      " [ 0.    0.    0.    2.14  0.    0.    0.    0.    0.    0.    0.    1.32\n",
      "   0.    0.    2.21  0.    0.    0.    0.    2.89  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.62  0.    0.    0.    0.    1.59  0.    0.    0.\n",
      "   0.    0.    1.68  0.    0.    2.27  0.    0.    0.    1.11  0.    0.    0.\n",
      "   0.    0.    0.    1.74  1.09  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.81  0.    0.    0.    0.    3.83  0.    0.\n",
      "   4.4   0.    0.    0.    0.    0.    0.    0.    0.    9.07  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.14]\n",
      " [ 0.    1.96  0.    0.    0.    0.    0.    0.    4.78  0.    4.14  0.\n",
      "   4.38  0.    4.22  0.    0.    0.    4.13  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.03  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.07  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.13  0.    0.    7.85  0.    0.    0.    4.95  0.    0.    0.    0.\n",
      "   0.    0.    0.    5.19  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    3.88  0.    1.87  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.58  0.    1.19  0.    0.    5.89  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.35  0.    5.32  0.    0.    0.    0.    0.    5.33  0.    5.08  0.    0.\n",
      "   0.    0.    2.67  0.    0.    0.    0.    0.    6.19  0.    0.    0.    0.\n",
      "   5.49  0.    0.    0.    4.21  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.25  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    3.75  0.    0.    0.    0.    0.    0.\n",
      "   4.25  0.    0.    0.    0.    0.    0.    0.    4.99  0.    0.    0.    0.\n",
      "   0.    1.7   3.54  0.    0.    0.    0.    0.    0.    6.3   0.    3.69\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.15  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.17  5.49  0.    0.    0.\n",
      "   0.    0.    0.    5.27  0.    0.    0.    0.    0.    0.    3.13  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.41  0.    0.\n",
      "   0.    0.    4.26  0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    3.47  0.    0.    0.    0.    0.    0.\n",
      "   5.59  0.    0.    2.2   0.    0.    0.    0.    0.    4.55  2.44  0.    0.\n",
      "   3.79  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.36\n",
      "   0.    0.    0.    0.    2.39  0.    0.    0.    0.    0.    4.24  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.43  0.\n",
      "   3.98  0.    0.    0.    0.    0.    4.55  0.    0.    1.24  0.    0.    0.\n",
      "   0.    0.    0.    4.31  0.    0.    0.    0.    6.94  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    5.96  0.    4.73  0.    0.    3.82  0.    0.    0.\n",
      "   0.    0.    4.45  0.    0.    0.    3.98  0.    2.2   0.    0.    0.\n",
      "   4.29  1.38  0.    0.    3.69  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.76  0.    0.    0.    4.39  0.    0.    0.    0.    0.    0.    5.25\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    7.16  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 3.36  0.    5.6   0.    0.    0.    0.    0.    0.    4.89  3.84  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.26  0.    0.    0.\n",
      "   5.32  6.03  6.97  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.64  0.    0.    0.    3.64  0.    0.    3.76  0.    0.    5.3   0.\n",
      "   1.21  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.05  0.    0.  ]\n",
      " [ 0.    0.    0.    5.19  0.    0.    0.    0.    2.98  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.18  0.    0.    0.    0.    0.    1.15  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    7.2   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.34  0.    0.    0.    0.    0.    1.65  0.    0.    0.    0.    5.58\n",
      "   0.    4.12  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.89  0.    3.48  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    6.62  0.    0.    0.    0.    4.06  0.    0.    0.    0.\n",
      "   0.    4.75  0.    0.    0.    0.    0.    0.    4.86  0.    0.    0.    0.\n",
      "   4.71  5.14  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.21  0.    0.    3.13  5.32  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    2.53  0.    0.    0.    3.06  5.64  0.    0.\n",
      "   0.    0.    1.79  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.92  0.    0.    0.    2.17  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    5.03  0.    0.    0.    0.    4.53  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.07  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.59  3.9   3.9   0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.74\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    7.29  0.    0.    4.73  0.    0.    0.    0.    0.    0.\n",
      "   0.    3.69  4.5   0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    4.78  0.    0.    5.02  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.51  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.02  0.    4.14  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    2.23  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    7.66  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.55  0.    5.48  0.\n",
      "   3.95  4.52  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    5.45  0.    0.    0.    0.    1.32  6.77  0.    5.86  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.64  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.93  1.49\n",
      "   0.    0.    0.    0.    0.    0.    4.49  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.69  0.    0.    0.    0.    0.\n",
      "   5.03  0.    0.    0.    0.    0.    0.    0.    0.    4.51  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.88  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    2.82  0.    0.    0.    0.    0.    7.4   0.    0.    4.1\n",
      "   0.    0.    0.    0.    5.1   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.13  4.99  0.    4.73  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.09  0.    0.    1.63  0.    0.    5.71  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.    0.    0.    0.    0.    0.    0.    0.    4.28  4.46  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    6.7   4.71  0.    0.    0.    0.    0.    0.    0.\n",
      "   4.6   5.23  0.    0.    5.38  0.    3.6   0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.83  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    1.62  0.    0.    0.    0.    0.    0.    4.62  0.    0.    0.\n",
      "   4.43  0.    5.18  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    2.25  7.15  0.    0.\n",
      "   0.    0.    0.    0.    0.    5.51  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.22  0.    0.    0.    0.    4.7   0.    0.    1.76  0.    0.\n",
      "   0.    0.    5.11  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.36  0.    0.    0.    5.05  0.    0.    0.    0.  ]\n",
      " [ 4.11  5.89  0.    0.    0.    0.    2.96  0.    0.    0.    5.69  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    2.14  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.2   0.    0.    0.    0.    0.    0.    0.    0.    0.    6.11\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    5.07  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.32  3.89  0.    0.    0.    6.63  0.    0.    0.    4.02]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.74  0.    0.\n",
      "   0.    0.    0.    0.    2.07  2.83  0.    0.    0.    0.    4.48  5.47\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.7   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.53  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.31  0.    5.43  0.    0.    7.7\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    4.24  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.91  0.    0.\n",
      "   0.    0.    7.64  0.    0.    0.    4.72  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    6.07  0.    3.64  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.92  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.46  0.    0.    0.    4.2 ]\n",
      " [ 0.    0.    0.    0.    1.79  0.    0.    0.    0.    0.    0.    2.57\n",
      "   0.    0.    0.    1.56  1.92  0.    0.    0.    0.    0.    0.    0.\n",
      "   5.14  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    8.17  0.    0.    2.85  0.    0.    0.    3.86  0.    0.\n",
      "   4.06  0.    0.    0.    1.08  4.92  0.    3.83  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    3.98  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.31  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.02  0.    0.    0.    0.    4.44  0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "qws = qn_table.get_weights()[0]\n",
    "sws = s_table.get_weights()[0]\n",
    "print(qws)\n",
    "# print(sws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0044 14.3564\n",
      "6.0 20.748\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAD31JREFUeJzt3X+s3XV9x/HnS/DHok5Auoa03YqzZsE/RNJAjWYRiVDYsrJECWaZjSHp/qiJGpMN/IdNZeofs85kknSjsRoViT9GY8iwqTVuyUQuyvg55A5F2hR6pRU1Rpfie3+cT92h9HrP5Z6ec7mf5yO5OZ/v+/s53/P5fnNyX/f786aqkCT15wXTHoAkaToMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnTp/2AH6bs88+u9avXz/tYUjS88pdd93146patVC/ZR0A69evZ2ZmZtrDkKTnlSSPjtLPQ0CS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktSpZX0n8FLt2Pv9sS/zfW99zdiXKUnT4B6AJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp0YKgCQ/THJvkruTzLTaWUn2Jnm4vZ7Z6knyySSzSe5JcsHQcra2/g8n2XpqVkmSNIrF7AFcXFXnV9XGNn0tsK+qNgD72jTA5cCG9rMNuBEGgQFcD1wEXAhcfzw0JEmTt5RDQFuA3a29G7hyqP6ZGvg2cEaSc4DLgL1VdaSqjgJ7gc1L+HxJ0hKMGgAFfD3JXUm2tdrqqjrU2o8Dq1t7DfDY0HsPtNp89WdIsi3JTJKZubm5EYcnSVqsUf8j2Juq6mCS3wP2Jvnv4ZlVVUlqHAOqqp3AToCNGzeOZZmSpGcbaQ+gqg6218PAVxkcw3+iHdqhvR5u3Q8C64bevrbV5qtLkqZgwQBI8tIkLz/eBi4F7gP2AMev5NkK3Nrae4B3tquBNgFPtUNFtwOXJjmznfy9tNUkSVMwyiGg1cBXkxzv//mq+rckdwK3JLkGeBS4qvW/DbgCmAV+AbwLoKqOJPkQcGfr98GqOjK2NZEkLcqCAVBVjwCvO0n9SeCSk9QL2D7PsnYBuxY/TEnSuHknsCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp0YOgCSnJflekq+16XOT3JFkNskXk7yo1V/cpmfb/PVDy7iu1R9Kctm4V0aSNLrF7AG8B3hwaPpjwI6qejVwFLim1a8Bjrb6jtaPJOcBVwOvBTYDn0py2tKGL0l6rkYKgCRrgT8B/qVNB3gL8KXWZTdwZWtvadO0+Ze0/luAm6vqV1X1A2AWuHAcKyFJWrxR9wA+Afw18Os2/UrgJ1V1rE0fANa09hrgMYA2/6nW/zf1k7znN5JsSzKTZGZubm4RqyJJWowFAyDJnwKHq+quCYyHqtpZVRurauOqVasm8ZGS1KXTR+jzRuDPklwBvAT4XeAfgTOSnN7+yl8LHGz9DwLrgANJTgdeATw5VD9u+D2SpAlbcA+gqq6rqrVVtZ7BSdxvVNVfAPuBt7VuW4FbW3tPm6bN/0ZVVatf3a4SOhfYAHxnbGsiSVqUUfYA5vM3wM1JPgx8D7ip1W8CPptkFjjCIDSoqvuT3AI8ABwDtlfV00v4fEnSEiwqAKrqm8A3W/sRTnIVT1X9Enj7PO+/AbhhsYOUJI2fdwJLUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwsGQJKXJPlOkv9Kcn+Sv2v1c5PckWQ2yReTvKjVX9ymZ9v89UPLuq7VH0py2alaKUnSwkbZA/gV8Jaqeh1wPrA5ySbgY8COqno1cBS4pvW/Bjja6jtaP5KcB1wNvBbYDHwqyWnjXBlJ0ugWDIAa+HmbfGH7KeAtwJdafTdwZWtvadO0+ZckSavfXFW/qqofALPAhWNZC0nSoo10DiDJaUnuBg4De4H/AX5SVcdalwPAmtZeAzwG0OY/BbxyuH6S90iSJmykAKiqp6vqfGAtg7/a/+hUDSjJtiQzSWbm5uZO1cdIUvcWdRVQVf0E2A+8ATgjyelt1lrgYGsfBNYBtPmvAJ4crp/kPcOfsbOqNlbVxlWrVi1meJKkRRjlKqBVSc5o7d8B3go8yCAI3ta6bQVube09bZo2/xtVVa1+dbtK6FxgA/Cdca2IJGlxTl+4C+cAu9sVOy8AbqmqryV5ALg5yYeB7wE3tf43AZ9NMgscYXDlD1V1f5JbgAeAY8D2qnp6vKsjSRrVggFQVfcArz9J/RFOchVPVf0SePs8y7oBuGHxw5QkjdsoewCSdHL7P3JqlnvxdadmuXoGHwUhSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTi0YAEnWJdmf5IEk9yd5T6uflWRvkofb65mtniSfTDKb5J4kFwwta2vr/3CSradutSRJCxllD+AY8P6qOg/YBGxPch5wLbCvqjYA+9o0wOXAhvazDbgRBoEBXA9cBFwIXH88NCRJk7dgAFTVoar6bmv/DHgQWANsAXa3bruBK1t7C/CZGvg2cEaSc4DLgL1VdaSqjgJ7gc1jXRtJ0sgWdQ4gyXrg9cAdwOqqOtRmPQ6sbu01wGNDbzvQavPVJUlTMHIAJHkZ8GXgvVX10+F5VVVAjWNASbYlmUkyMzc3N45FSpJOYqQASPJCBr/8P1dVX2nlJ9qhHdrr4VY/CKwbevvaVpuv/gxVtbOqNlbVxlWrVi1mXSRJizDKVUABbgIerKqPD83aAxy/kmcrcOtQ/Z3taqBNwFPtUNHtwKVJzmwnfy9tNUnSFJw+Qp83An8J3Jvk7lb7APBR4JYk1wCPAle1ebcBVwCzwC+AdwFU1ZEkHwLubP0+WFVHxrIWkqRFWzAAquo/gMwz+5KT9C9g+zzL2gXsWswAJUmnhncCS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE6Nch+Anod27P3+2Jf5vre+ZuzLnJj9Hxn/Mi++bvzLlCbIPQBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTPgtI6sWpeB6SntfcA5CkThkAktQpA0CSOmUASFKnPAmskflPZqSVxT0ASeqUASBJnfIQkKTl51Tds+D/cX4G9wAkqVMGgCR1asEASLIryeEk9w3VzkqyN8nD7fXMVk+STyaZTXJPkguG3rO19X84ydZTszqSpFGNsgfwaWDzCbVrgX1VtQHY16YBLgc2tJ9twI0wCAzgeuAi4ELg+uOhIUmajgUDoKq+BRw5obwF2N3au4Erh+qfqYFvA2ckOQe4DNhbVUeq6iiwl2eHiiRpgp7rOYDVVXWotR8HVrf2GuCxoX4HWm2+uiRpSpZ8EriqCqgxjAWAJNuSzCSZmZubG9diJUkneK4B8EQ7tEN7PdzqB4F1Q/3Wttp89Wepqp1VtbGqNq5ateo5Dk+StJDneiPYHmAr8NH2eutQ/d1JbmZwwvepqjqU5Hbg74dO/F4KeEeGnt+8WUnPcwsGQJIvAG8Gzk5ygMHVPB8FbklyDfAocFXrfhtwBTAL/AJ4F0BVHUnyIeDO1u+DVXXiiWXJ/1olTdCCAVBV75hn1iUn6VvA9nmWswvYtajRSZJOGe8ElqROGQCS1CmfBiotN54H0YS4ByBJnTIAJKlTHgJaBk7F/9qVpIW4ByBJnTIAJKlTBoAkdcoAkKROeRJ4kTxhK2mlcA9AkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTvn/ADRVJ/5/hU0/enLJy3zDq1655GVIPXAPQJI65R6AnrNNP9o57SFIWoKJ7wEk2ZzkoSSzSa6d9OdLkgYmGgBJTgP+CbgcOA94R5LzJjkGSdLApPcALgRmq+qRqvpf4GZgy4THIEli8ucA1gCPDU0fAC6a8Bi0wv3nI0u/kuhEXlm0Quz/yPiXefF141/mhCy7k8BJtgHb2uTPkzy0hMWdDfx46aNa0dxGC3MbjabT7fSBxXSe1Db6g1E6TToADgLrhqbXttpvVNVOYCyXlySZqaqN41jWSuU2WpjbaDRup4Utt2006XMAdwIbkpyb5EXA1cCeCY9BksSE9wCq6liSdwO3A6cBu6rq/kmOQZI0MPFzAFV1G3DbhD7OO5UW5jZamNtoNG6nhS2rbZSqmvYYJElT4LOAJKlTKzIAfNzEaJL8MMm9Se5OMjPt8SwHSXYlOZzkvqHaWUn2Jnm4vZ45zTFO2zzb6G+THGzfpbuTXDHNMU5bknVJ9id5IMn9Sd7T6svqu7TiAsDHTSzaxVV1/nK6NG3KPg1sPqF2LbCvqjYA+9p0zz7Ns7cRwI72XTq/nevr2THg/VV1HrAJ2N5+Dy2r79KKCwB83ISWoKq+BRw5obwF2N3au4ErJzqoZWaebaQhVXWoqr7b2j8DHmTwJIRl9V1aiQFwssdNrJnSWJa7Ar6e5K52B7ZObnVVHWrtx4HV0xzMMvbuJPe0Q0RdHyYblmQ98HrgDpbZd2klBoBG96aquoDB4bLtSf542gNa7mpw2ZyXzj3bjcAfAucDh4B/mO5wlockLwO+DLy3qn46PG85fJdWYgAs+LgJDVTVwfZ6GPgqg8NnerYnkpwD0F4PT3k8y05VPVFVT1fVr4F/xu8SSV7I4Jf/56rqK628rL5LKzEAfNzECJK8NMnLj7eBS4H7fvu7urUH2NraW4FbpziWZen4L7Xmz+n8u5QkwE3Ag1X18aFZy+q7tCJvBGuXoH2C/3/cxA1THtKyk+RVDP7qh8Ed4Z93O0GSLwBvZvDUxieA64F/BW4Bfh94FLiqqro9CTrPNnozg8M/BfwQ+KuhY93dSfIm4N+Be4Fft/IHGJwHWDbfpRUZAJKkha3EQ0CSpBEYAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkder/AE88JskNd47hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4006eb2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4006f9b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBS SSHAPE (100, 100)\n",
      "tvt: 10000 9000 1000\n",
      "len all_pfz 10000\n",
      "9000 [ 4560.]\n"
     ]
    }
   ],
   "source": [
    "print(numpy.min(qws), numpy.min(qws[qws>=1]), numpy.max(qws))\n",
    "print(numpy.min(sws), numpy.max(sws))\n",
    "\n",
    "plt.hist(qws.flatten(), alpha=0.5)\n",
    "plt.hist(sws.flatten(), alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "sig = lambda z : 1/(1+numpy.exp(-z))\n",
    "obs = numpy.zeros((len(sws), len(qws)))\n",
    "probs = numpy.zeros((len(sws), len(qws)))\n",
    "#obs = numpy.matmul(viewers, movies.T)/n_factors\n",
    "vz = []\n",
    "mz = []\n",
    "scz =[]\n",
    "for vi in range(len(sws)):\n",
    "    for mi in range(len(qws)):\n",
    "        zmask = (qws[mi]<1).astype(int)\n",
    "        deltas = sws[vi]-qws[mi]\n",
    "        prs = sig(deltas)\n",
    "        prs = numpy.maximum(zmask,prs)\n",
    "\n",
    "#             print(vi,mi)\n",
    "#             print(\"S\", students[vi])\n",
    "#             print(\"Q\", questions[mi])\n",
    "#             print(\"Z\", zmask)\n",
    "#             print(\"D\", deltas)\n",
    "#             print(\"p\", prs)\n",
    "#             print(\"P\", numpy.prod(prs))\n",
    "        pr = numpy.prod(prs)\n",
    "        obs[vi,mi] = (random.random() < pr)\n",
    "        probs[vi,mi] = numpy.prod(prs)\n",
    "#             print(vi,mi, numpy.prod(prs))\n",
    "\n",
    "plt.hist(probs.flatten())\n",
    "plt.show()\n",
    "\n",
    "print(\"OBS SSHAPE\", obs.shape)\n",
    "\n",
    "all_pfz=obs\n",
    "\n",
    "frak=1\n",
    "all_pairs = [(s,q) for s,q in zip(all_sz,all_qz)]\n",
    "all_pair_ixs = list(range(len(all_pairs)))\n",
    "# ixs_to_use = numpy.random.choice(all_pair_ixs, size=int(max(frak*len(all_pairs),10)), replace=True)\n",
    "# pairs_to_use = numpy.array(all_pairs)[ixs_to_use]\n",
    "\n",
    "all_ixs = all_pair_ixs\n",
    "val_ixs = numpy.random.choice(all_pair_ixs, size=int(len(all_pair_ixs)/10), replace=False) #len(attempts)//100, replace=False)\n",
    "trn_ixs = list(set(all_ixs) - set(val_ixs))\n",
    "test_ixs = val_ixs\n",
    "print(\"tvt:\", len(all_ixs), len(trn_ixs), len(test_ixs))\n",
    "\n",
    "all_sz = numpy.array(all_sz).reshape([-1,1])\n",
    "all_qz = numpy.array(all_qz).reshape([-1,1])\n",
    "all_pfz = numpy.array(all_pfz).reshape([-1,1])\n",
    "print(\"len all_pfz\", len(all_pfz))\n",
    "\n",
    "tsz = all_sz[test_ixs]\n",
    "tqz = all_qz[test_ixs]\n",
    "tpfz = all_pfz[test_ixs]\n",
    "\n",
    "sz = all_sz[trn_ixs]\n",
    "qz = all_qz[trn_ixs]\n",
    "pfz = all_pfz[trn_ixs]\n",
    "\n",
    "\n",
    "print(len(pfz), sum(pfz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 6.0 14.5556326859\n",
      "6.0 12.0\n",
      "---\n",
      "0.0 1.00788 9.02509\n",
      "6.0 16.538\n",
      "[[ 0.    0.    0.    0.    0.    0.    4.39  0.    0.    0.    0.    3.93\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.65  0.    0.    3.03  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.74  4.3   0.    0.    3.78  0.    0.    0.    5.08  0.    0.\n",
      "   6.14  0.    0.    7.47  3.98  0.    0.    0.    2.4   0.    0.  ]\n",
      " [ 0.    7.39  4.58  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.79  0.    2.07  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.19  4.82  0.    0.    0.    0.    0.    0.    0.    0.    4.55  0.    0.\n",
      "   4.56  0.    0.    0.    1.69  0.    0.    0.    0.    5.39  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.16  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.16  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.47  0.    0.    0.    1.73\n",
      "   0.    0.    4.95  0.    0.    0.    0.    0.    0.    0.    1.9   0.    0.\n",
      "   2.91  3.1   0.    0.    0.    0.    0.    8.2   0.    2.41  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.01  0.    3.26  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.52  3.51  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.55  5.27  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.97  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.05  0.    0.    0.    6.09  1.78  0.    0.    6.13  0.    2.1   0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.47  0.    0.    4.37  4.88  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.5   0.    0.    0.    0.    3.92\n",
      "   0.    0.    0.    5.08  0.    0.    2.67  0.    0.    0.    4.37  5.21\n",
      "   0.    0.    0.    0.    4.21  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    3.8   4.22  0.    0.    0.    0.\n",
      "   8.12  0.    0.    1.83  0.    0.    0.    4.02  0.    0.    0.    0.    0.\n",
      "   2.19  0.    0.    0.    0.    0.    0.    0.    4.76  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.28  0.    0.    0.    0.\n",
      "   0.    0.    5.15  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.13  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.57  0.    0.    0.  ]\n",
      " [ 0.    2.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.21  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.26  0.    0.    0.    0.    0.    0.    6.42  4.04\n",
      "   0.    5.98  0.    0.    0.    0.    0.    0.    0.    0.    4.17  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.32  3.2   4.11  0.    0.    0.    0.\n",
      "   0.    6.21  3.14  0.    0.    0.    0.    2.84  0.    0.    0.    0.    0.\n",
      "   4.12  0.    0.    0.    0.    5.35  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.    0.    0.    0.    0.    0.    6.13  0.    3.81  0.    0.    0.\n",
      "   0.    1.3   0.    0.    3.55  0.    0.    0.    0.    0.    0.    0.\n",
      "   6.39  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.01\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.38  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.32  0.    0.    0.    0.    0.    0.    0.    6.08  0.    2.64  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.19  3.8   0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    5.28  0.    3.53  2.75\n",
      "   0.    0.    0.    0.    0.    1.63  0.    0.    0.    0.    1.75  0.\n",
      "   3.64  4.21  5.07  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.22  0.    0.    4.41  0.    0.    5.06  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.86  0.    0.    0.    0.    0.    0.\n",
      "   4.79  0.    0.    4.7   0.    0.    0.    0.    5.16  0.    0.    0.    0.\n",
      "   3.75  0.    5.15  5.09  5.01  0.    0.    0.    0.    0.    0.    4.05\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.54\n",
      "   0.  ]\n",
      " [ 6.29  0.    0.    2.53  0.    0.    4.35  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.53  4.8   0.    0.    0.\n",
      "   2.82  0.    0.    0.    1.69  0.    0.    0.    0.    0.    0.    1.85\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.25  0.    5.86  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.71\n",
      "   0.    2.32  0.    0.    0.    4.11  4.94  4.83  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.94  0.    0.    0.    0.    0.    0.    0.    4.06  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    6.25  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    6.11  0.    0.    0.    0.\n",
      "   4.56  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.79  5.02  0.    0.    0.    0.    4.13  0.    0.    0.    2.97  4.23\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.2   0.    0.    0.\n",
      "   0.    0.    0.    3.44  0.    6.29  0.    0.    0.    0.    0.    1.58\n",
      "   0.    3.26  0.    0.    0.    0.    0.    5.24  0.    0.    0.    0.  ]\n",
      " [ 4.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.54  0.\n",
      "   1.04  0.    4.3   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.95  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.33  3.71  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.33  0.    0.    0.    0.    0.    0.    0.    0.    0.    3.7\n",
      "   5.34  4.86  5.05  0.    0.    6.85  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    4.38  0.    5.24  0.    0.    0.    0.    0.    0.    0.    3.97\n",
      "   0.    4.22  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.14  0.    0.    0.    0.    0.    5.27  0.\n",
      "   5.95  0.    1.73  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.43  0.    0.    4.82  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.1   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   7.98  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.75  5.9   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.41  0.    0.    0.    2.45  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.76  0.    0.    4.8   0.    0.    0.    4.18  0.    0.    6.99\n",
      "   0.    0.    0.    0.    0.    4.7   0.    0.    0.    0.    5.45  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.51  0.    0.\n",
      "   0.    0.    0.    0.    0.    3.98  0.    0.    0.    0.  ]\n",
      " [ 5.35  0.    4.44  0.    4.64  0.    0.    0.    0.    1.04  0.    4.93\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    1.64  0.    0.    0.\n",
      "   0.    0.    6.35  0.    0.    0.    2.74  6.08  0.    0.    0.    0.    0.\n",
      "   0.    4.6   0.    0.    5.55  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.76  3.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.26  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    1.59  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.89  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.71  0.    0.    0.    3.65  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.96  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.41  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.87\n",
      "   0.    5.75  0.    0.    4.39  0.    0.    4.58  0.    0.    0.    0.    0.\n",
      "   0.    0.    7.75  0.    0.    0.    0.    0.    0.    0.    0.    0.    4.\n",
      "   2.41  0.    0.    0.    3.45  0.    4.15  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    5.86  6.77  0.    0.    0.    4.56  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.35  0.    4.87  0.    0.    0.\n",
      "   0.    0.    0.    1.53  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.53\n",
      "   0.    0.    5.8   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.7   0.    4.83  0.    0.    0.    0.\n",
      "   2.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    3.75  0.    0.    6.88  0.    0.    0.\n",
      "   2.91  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.01  0.    0.    0.    0.    5.48  0.    0.    0.    0.    0.    2.77\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.97  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.93  1.23  0.    4.3   0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.13  4.84  0.    0.    0.    0.    3.55  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.53  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    5.53  0.    0.    4.64  0.    2.03\n",
      "   0.    0.    3.56  0.    6.42  0.    0.    0.    0.    0.    4.62  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.26  4.97  0.    0.    0.    0.\n",
      "   4.38  0.    0.    0.    0.    0.    0.    5.22  4.62  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.24  2.65  0.    0.    0.    4.92  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.9   0.    0.  ]\n",
      " [ 0.    0.    0.    4.51  0.    0.    0.    0.    0.    6.23  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.53  0.    0.    0.    0.\n",
      "   0.    0.    0.    6.27  0.    0.    3.01  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.38  0.    0.    4.47  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.94  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.99  0.    2.14  0.    5.96  0.    0.    0.    0.\n",
      "   0.    4.68  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    2.41  0.    0.    0.\n",
      "   0.    2.58  0.    0.    0.    0.    4.27  0.    0.    0.    0.    6.06\n",
      "   0.    0.    4.18  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    2.04  0.    0.    0.    0.    0.    2.28  0.    0.    0.\n",
      "   4.85  0.    0.    0.    3.34  0.    0.    5.72  0.    0.    0.    0.    0.\n",
      "   0.    0.    4.1   0.    0.    0.    6.98  0.    2.87  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.74  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.98  0.    0.    0.    0.    0.    0.    1.41  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.87\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.46  0.    0.    0.    0.    0.\n",
      "   5.18  0.    0.    4.11  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.49  6.03  4.98  0.    0.    0.    0.    0.    0.    0.    0.    1.04\n",
      "   0.    0.    0.    0.    0.    3.88  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.2   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    5.14  0.    0.    0.\n",
      "   4.58  0.    0.    0.    0.    0.    2.5   3.83  0.    4.08  0.    0.    0.\n",
      "   0.    3.    3.3   5.11  0.    5.18  4.45  0.    3.51  0.    0.    0.    0.\n",
      "   0.    0.    0.    7.48  0.    0.    0.    0.    0.    0.    4.25  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.45  0.    0.    0.    3.22  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    1.75  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.81  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.54  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    6.08  0.    4.14  5.24  0.    0.    6.36  0.\n",
      "   1.34  0.    0.    0.    0.    0.    0.    1.76  0.    0.    1.79  0.\n",
      "   3.84  0.    5.72  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.5   0.    0.    2.23  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    1.84  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    3.99  0.    0.    0.\n",
      "   4.66  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.47  0.    0.    0.    0.    0.    3.94  0.    0.\n",
      "   0.    4.63  0.    0.    0.    0.    3.67  4.29  3.71  0.    0.    5.37\n",
      "   2.23  0.    0.    0.    7.34  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.36  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.04  0.    0.    2.18  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    5.73  0.    0.    0.    0.    4.41  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.64  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    6.15  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.83  0.    0.    0.    0.    0.    0.    0.    4.88  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    2.84  0.    0.    0.    4.77  5.56  0.    0.\n",
      "   0.    0.    0.    0.    5.63  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    3.73  0.    0.    5.23  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.15  0.    0.    6.33  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    3.67  5.71  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.79  4.2\n",
      "   0.    0.    0.    0.    0.    2.38  0.    0.    0.    0.    0.    0.    0.\n",
      "   5.43  0.    0.    0.    4.48  0.    0.    0.    0.    4.28  0.    0.    0.\n",
      "   0.    0.    0.    0.    2.23  0.    0.    0.    0.    0.    0.    2.13\n",
      "   5.46  0.    0.    0.    0.    0.    0.    3.89  0.    0.    2.29]\n",
      " [ 4.87  4.43  0.    0.    0.    0.    0.    4.8   0.    0.    0.    3.94\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.88  0.    4.82  0.    2.82  0.    0.    0.    0.    7.74  0.    0.\n",
      "   3.72  0.    0.    0.    5.04  0.    0.    0.    0.    0.    0.    0.\n",
      "   3.64  0.    0.    0.    0.    2.06  0.    0.    0.    0.    4.83  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.88  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.3   0.    0.    0.\n",
      "   3.08]\n",
      " [ 0.    4.69  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.23  0.    4.42  0.\n",
      "   3.81  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.26  0.    0.    0.    3.76  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.13  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.28  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    7.33  4.76  5.57  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.17  0.    5.52  0.  ]\n",
      " [ 0.    0.    0.    0.    4.96  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.35  0.    0.    0.    4.15  0.    2.72  0.    0.    0.    0.\n",
      "   0.    0.    0.    5.59  0.    0.    0.    1.94  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.87  0.    0.    0.    0.\n",
      "   6.24  0.    0.    0.    3.46  5.51  0.    0.    0.    0.    0.    2.52\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.93  0.    0.    0.\n",
      "   4.46  4.48  0.    0.    0.    0.    0.    0.    0.    3.97  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    5.57  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.11  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    7.93  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.49  0.    0.    2.4   0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    2.24  0.    0.\n",
      "   0.    4.69  5.06  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    5.61  0.    0.    0.    0.    0.    3.97  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    3.61  0.    0.    0.    0.    0.    2.29  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.78  0.    0.    4.83  0.    0.    0.\n",
      "   2.55  0.    0.    0.    5.28  1.84  0.    0.    0.    0.    0.    4.66\n",
      "   0.    0.    0.    4.97  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.96  0.    0.    0.    0.    0.    0.    0.    2.06  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.86  3.76  6.88  0.  ]\n",
      " [ 0.    0.    4.73  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.36  0.    0.    0.    0.    0.    0.    0.    0.    4.7   0.    0.\n",
      "   6.32  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.34  5.56  0.    0.    0.    0.    0.    4.18  0.    0.    0.    2.58\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.63  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.21  0.    0.    0.    0.    0.    0.    0.    0.    5.04\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.41\n",
      "   0.    1.03]\n",
      " [ 0.    0.    2.2   5.88  0.    0.    0.    4.93  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.09  0.    1.9   0.    0.    0.    0.\n",
      "   0.    0.    4.32  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    6.9   0.    0.    0.    1.47  0.    0.    0.\n",
      "   4.03  0.    0.    0.    0.    0.    3.94  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.24  5.74  1.08  0.    5.01\n",
      "   0.    0.    0.    0.    0.    1.39  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.77  0.    0.    0.    0.    4.38  0.    3.5   0.    0.    0.    0.    0.\n",
      "   2.99  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.6   0.    0.    0.    3.78  0.    0.    0.    0.    0.    0.    0.\n",
      "   6.19  0.    0.    0.    3.82  0.    4.59  4.6   0.    4.27  0.    0.\n",
      "   3.65  0.    6.13  0.    0.    0.    0.    2.45  6.25  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    1.92  0.    5.11  4.72  0.\n",
      "   2.24  5.24  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    6.17  0.    0.    0.\n",
      "   5.02  4.67  0.    4.27  0.    3.04  0.    0.    0.    5.94  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    2.56  0.    0.    4.07  0.    0.    0.    5.47  0.    0.\n",
      "   0.    0.    0.    0.    1.53  0.    0.    0.    2.77  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.54  0.    0.    2.03  2.02  0.    0.    0.    0.    3.36  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.16  0.    0.    0.    4.79  3.    4.04  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    6.96  3.82  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    2.42  0.    3.56\n",
      "   0.    0.    0.    0.    0.    4.67  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.95  0.    0.    0.    0.    4.96  1.59  3.92  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    4.73  0.    0.    0.    5.36  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.14  0.    3.23  0.    4.76\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.72\n",
      "   0.    3.01  2.39  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.96  0.    0.    5.16  0.    0.    4.57  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.11  0.    0.    0.    0.    0.    0.    0.    0.    0.    2.67  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 3.52  0.    5.82  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.4   0.    0.    4.4   0.    1.76  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    1.56  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.07  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.39  0.    0.\n",
      "   0.    0.    4.9   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.2   0.    0.    0.    0.    6.62  0.    0.    5.4   0.    0.    0.\n",
      "   0.    0.    3.62  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    1.18  0.    0.    5.89  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.17  0.    0.    7.26  4.49  0.    0.    0.\n",
      "   0.    0.    4.39  0.    0.    0.    0.    4.53  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    5.57  0.    0.    0.    0.\n",
      "   4.31  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.29  0.    2.14  0.    0.    0.    0.    0.    0.    4.07\n",
      "   0.    0.    0.    0.    0.    3.24  0.    0.    4.75  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    3.78  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.3   0.    0.    4.52  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.15  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.97  0.    0.    0.    0.    0.\n",
      "   4.84  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.05  0.    0.    0.    0.    0.    0.    9.03  0.    4.47  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    2.05  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.61  0.    0.    0.    0.    0.    0.    5.18  0.    0.    4.31  0.    0.\n",
      "   0.    0.    0.    0.    5.75  0.    0.    0.    0.    0.    0.    5.36\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.73  3.37  4.51  0.    0.\n",
      "   0.    0.    4.59  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    6.73  0.    0.    0.    0.    0.    6.    0.    0.\n",
      "   0.    1.77  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    5.03  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    6.23  0.    0.    0.\n",
      "   0.    4.94  0.    0.    0.    0.    0.    0.    0.    5.57  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.8   4.97  2.03  0.    2.23\n",
      "   0.    0.    0.    5.34  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.73  0.    0.    0.    0.    0.    0.    4.95  3.79\n",
      "   0.    3.77  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    1.89  0.  ]\n",
      " [ 0.    4.43  0.    4.27  0.    0.    0.    0.    0.    1.58  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.34  0.    0.    0.    0.    0.    0.    0.    5.02  0.    0.    0.    0.\n",
      "   1.93  0.    3.48  4.77  0.    3.66  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.27  0.    0.    2.32  7.94  0.\n",
      "   3.86  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.88  0.    0.    0.    0.    3.42  0.  ]\n",
      " [ 0.    0.    3.68  0.    0.    0.    0.    0.    5.91  0.    0.    0.    0.\n",
      "   5.01  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.06\n",
      "   0.    1.66  0.    0.    0.    0.    0.    3.33  0.    0.    0.    0.    0.\n",
      "   4.8   0.    0.    0.    3.57  3.64  0.    0.    5.51  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    6.82  0.    0.    0.\n",
      "   0.    3.75  0.    0.    0.    0.    3.57  0.    0.    0.    1.54  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    5.72  0.    0.    0.    0.    6.99  1.36  0.    0.    0.\n",
      "   2.62  0.    0.    0.    0.    0.    0.    0.    0.    2.42  0.    0.    0.\n",
      "   0.    5.04  0.    3.54  0.    0.    0.    0.    4.5   0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.82  0.    0.    0.    0.\n",
      "   0.    3.41  0.    0.    0.    4.71  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.99  0.    4.68  0.    0.    0.    0.\n",
      "   3.53  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.94  1.32  0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.79  0.    0.    0.    0.    0.    2.4\n",
      "   0.    0.    5.06  0.    2.31  0.    2.74  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.11  0.    0.    0.    3.44\n",
      "   7.19  0.    0.    0.    1.95  0.    0.    2.97  0.    0.    0.    0.    0.\n",
      "   1.46  0.    0.    1.12  0.    0.    3.32  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.71  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.4   0.    4.91]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.83  2.91  0.    0.    0.    4.88  5.33  0.    0.    0.    0.    0.    0.\n",
      "   5.55  0.    0.    0.    0.    0.    0.    0.    0.    3.81  0.    0.    0.\n",
      "   0.    0.    0.    1.88  0.    0.    0.    4.67  4.06  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.28  4.06  0.    5.77  0.    0.    0.    0.    5.41  0.    0.\n",
      "   0.    0.    0.    5.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.55  0.    0.    0.    0.    0.    6.43  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    6.17  0.    0.    0.    0.    0.\n",
      "   5.56  0.    0.    0.    0.    0.    0.    0.    0.    4.72  0.    0.    0.\n",
      "   0.    0.    6.66  0.    2.16  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.5   0.    0.    4.34  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    3.87  0.    0.    0.    0.    0.    0.    4.29\n",
      "   0.    0.    0.    0.    5.13  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.53  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.89  0.    0.    0.    0.    0.    3.55  0.    0.    0.    0.    0.  ]\n",
      " [ 3.88  0.    0.    0.    3.5   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.11  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.44  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.11  0.    0.    3.78  0.    0.\n",
      "   5.07  0.    7.11  0.    0.    5.87  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.64  0.    0.    0.    0.    1.54  4.9   0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.05  0.    0.    0.    0.    4.91  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.08  0.    0.    0.    6.67  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.62  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    6.45  0.    0.    0.    0.\n",
      "   4.59  0.    0.    4.23  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    5.25  4.16  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.52  0.    0.\n",
      "   0.    3.63  0.    0.    1.65  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.58  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.77  0.    0.    4.97  0.    0.    0.    0.    4.86\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.96  0.    0.\n",
      "   0.    5.37  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.17  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.28  0.    4.95\n",
      "   0.    0.    0.    0.    0.    0.    0.    2.98  0.    4.5   3.43  4.23\n",
      "   0.    0.    0.    5.78  0.    0.    3.68  2.89  0.    0.    0.    0.    0.\n",
      "   5.22  0.    0.    0.    0.    0.    0.    3.98  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.36  0.    0.    0.    0.    1.41  5.31  0.    0.\n",
      "   5.54  0.    0.    0.    0.    0.    0.    5.63  4.59  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.52\n",
      "   1.21  0.    4.57  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.08  3.62  0.    0.    3.44  0.    0.    0.    0.    7.56  4.34\n",
      "   0.    0.    0.    4.23  0.    3.75  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.38  0.    0.    3.45  3.92\n",
      "   0.    0.    0.    0.    3.02  1.66  0.    0.    0.    0.    0.    4.12]\n",
      " [ 4.74  0.    0.    0.    0.    0.    3.97  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.06  3.9   0.    3.71  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.48  0.    0.    1.04  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.88  0.    0.    0.\n",
      "   0.    0.    5.36  0.    5.39  1.98  4.97  0.    0.    0.    1.45  0.    0.\n",
      "   0.    0.    0.    0.    0.    3.38  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.48  0.    2.4   6.03]\n",
      " [ 0.    0.    0.    0.    4.4   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.64  6.05  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.03  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    2.41  0.    5.72  6.38  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.78  5.86  0.    0.    0.    0.    2.2   0.    0.\n",
      "   0.    0.    0.    0.    4.91  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    4.09  1.44  3.07  0.    0.    0.    0.\n",
      "   6.5   0.    0.    0.    3.89  0.    0.    4.22  5.07  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.2   4.31  2.7\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.83  0.    0.    0.    5.48  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.88  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.58  0.    3.58\n",
      "   0.    4.29  0.    0.    0.    0.    0.    0.    0.    0.    0.    4.3 ]\n",
      " [ 0.    0.    0.    0.    0.    4.31  0.    0.    4.43  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.59  0.    0.    0.    3.81  0.\n",
      "   4.43  5.64  4.13  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.27  0.    0.    0.    0.    1.58  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.39\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.37  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.38  0.    0.    0.    0.    0.    0.    0.    0.    6.45  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    2.1   0.    0.    0.    0.    0.    0.    0.\n",
      "   5.23  0.    0.    0.    3.03  0.    0.    0.    0.    0.    5.08  0.    0.\n",
      "   0.    0.    0.    0.    0.    7.68  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.14  1.49  0.    0.    3.98  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    1.26  0.    0.    0.    0.    0.\n",
      "   5.12  0.    0.    0.    0.    2.18  0.    0.    4.78  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 1.13  1.35  0.    4.44  0.    0.    0.    0.    6.36  0.    0.    0.    0.\n",
      "   0.    0.    6.09  4.65  2.19  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.69  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.74  0.    0.    0.    0.    0.\n",
      "   4.14  0.    0.    0.    0.    6.47  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.5   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    3.6   0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.88  6.41  6.08  5.29  0.    0.    0.    0.    0.\n",
      "   4.38  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.08\n",
      "   0.    0.    0.    0.    3.02  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.9   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    2.38  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.41  0.    0.    0.    0.    0.    0.    0.    0.    0.    2.62\n",
      "   0.    0.    0.    4.56  5.08  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.99  0.    0.    0.    0.    0.    0.\n",
      "   3.05  0.    0.    0.    7.09  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.35  0.    0.    0.    4.06\n",
      "   0.    0.    3.92  0.    4.83  0.    0.    6.19  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    3.74  0.    0.    0.    0.    0.    0.    0.    4.7\n",
      "   0.    0.    3.32  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.26  0.    0.    0.    0.    0.    6.53  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    6.47  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.8   0.    0.\n",
      "   2.34  0.    1.62  0.    3.15  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.34  0.    5.04  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.42  2.8   0.    0.    0.    0.    0.    0.    0.    0.    2.91  0.    0.\n",
      "   0.    4.77  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.09\n",
      "   4.61  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    1.05  0.    7.11  0.    0.    4.63  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.99\n",
      "   0.    0.    0.    0.    5.33  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.44  0.    0.\n",
      "   5.35  0.    0.    0.    0.    0.    0.    0.    4.42  0.    0.    0.    0.\n",
      "   0.    0.    0.    4.6   0.    0.    5.63  0.    0.    0.    1.75  0.    0.\n",
      "   0.    0.    0.    0.    5.63  0.    6.69  0.    0.    0.    0.    4.06\n",
      "   0.    0.    1.25  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.66  0.    0.    0.    0.    5.23  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.57  0.    0.    3.86  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    4.68  4.78  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    2.36  0.    4.51  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.89  5.46  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.09\n",
      "   0.    0.    0.    5.84  0.    0.    0.    0.    0.    0.    0.    6.26\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 3.69  0.    0.    0.    5.65  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.97  0.    0.    0.    0.    0.    3.81  0.    0.\n",
      "   3.85  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.32  0.    0.    0.    0.    4.62  0.    2.85  0.    3.26  0.    0.    0.\n",
      "   0.    0.    0.    0.    3.58  0.    0.    5.8   0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.86\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   7.3   5.26  0.    0.    0.    3.45  0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    1.73  0.    0.    3.64  0.    2.75  1.96  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    3.45  0.    0.    5.61  0.    0.    0.\n",
      "   0.    0.    4.25  0.    4.89  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.65  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    1.11  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.2\n",
      "   0.    0.    0.    0.    7.16  4.77  4.82  3.01  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.68  7.43\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.43  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.84  0.    0.    4.77  0.    0.\n",
      "   4.18  0.    0.    3.86  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.25  2.47  3.18  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.8   0.    0.    0.    3.79  5.56  0.    0.    0.    0.    0.    2.71\n",
      "   4.26  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.97\n",
      "   0.    0.    0.    0.    3.3   0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    7.72  0.    0.    0.    0.    0.    0.    3.79  0.\n",
      "   4.3   0.    4.91  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.97  0.    3.47  0.    0.    0.    0.    0.    0.    3.85  4.12  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.16  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.04  3.64  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    4.98  0.    0.    3.12  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.34  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    5.06  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.82  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.81  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.25  5.37  0.    0.    0.    0.    0.    0.    2.05  0.    0.\n",
      "   5.36  0.    4.91  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    5.74  0.    0.    0.    1.74  0.    0.\n",
      "   0.    0.    0.    2.74  0.    0.    0.    3.14  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    5.71  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.38  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    1.01  0.    0.    0.    0.    5.98  0.    0.\n",
      "   0.    0.    0.    0.    0.    4.94  0.    0.    5.41  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.7   0.    0.    0.    0.    0.    4.91  0.    0.    0.    4.9\n",
      "   0.    0.    0.    0.    0.    5.09  0.    4.32  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.55  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    3.27  0.    0.    0.    0.    0.    0.    0.    0.    2.53  0.    0.\n",
      "   0.    0.    0.    0.    4.69  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.52  0.    0.    2.81  0.    0.    4.01  0.    4.2   0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    1.41  0.    0.    0.    1.44\n",
      "   0.    4.37  3.79  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.9   0.    0.    0.    0.    0.    0.    0.    0.    5.59  0.    0.    0.\n",
      "   0.    0.    0.    7.57  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    2.88  0.    0.    0.    0.    0.    0.    2.85  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.33  0.    0.    0.    5.42  0.    0.    0.    0.    0.\n",
      "   5.75  0.    0.    0.    0.    0.    0.    0.    6.01  0.    0.    4.76\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.7   0.    0.    0.    0.    0.    4.27  0.    0.    2.2   0.    0.\n",
      "   0.    0.    0.    0.    5.52  0.    0.    0.    0.    5.48  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.98  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.34  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.75\n",
      "   0.    0.    4.91  1.17  0.    4.2   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.97  0.    3.37  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.58  0.    5.29\n",
      "   0.    0.    6.72  0.    4.75  4.18  0.    0.    0.    0.    0.    0.    0.\n",
      "   5.75  0.    0.    0.    1.81  0.    0.    0.    4.3   0.    0.  ]\n",
      " [ 0.    0.    0.    4.4   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.07  0.    0.\n",
      "   0.    4.08  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    4.54  0.    0.    4.66  0.    0.    0.    0.    0.    0.\n",
      "   2.78  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   2.81  0.    0.    0.    4.18  0.    0.    5.29  0.    0.    5.98  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    6.71]\n",
      " [ 0.    0.    0.    0.    0.    0.    3.16  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.77  2.8   0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    5.7   0.    0.    0.    0.\n",
      "   4.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.51\n",
      "   0.    0.    5.13  0.    0.    3.72  0.    0.    2.54  4.9   0.    0.\n",
      "   6.53  0.    0.    0.    0.    0.    0.    0.    0.    5.47  0.    3.92\n",
      "   0.    0.    0.    4.32  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    1.12  4.35  0.    1.02\n",
      "   0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.1   4.89\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.33  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.78  0.    0.    0.    3.21  0.    2.94  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    7.16  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    6.12  0.    0.    0.    0.    0.    0.    0.\n",
      "   5.68  0.    4.03  0.    3.61  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.58  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    4.01  0.    0.    0.\n",
      "   4.03  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.27  0.    5.13  0.    0.    0.    0.    0.    0.    0.    0.    2.59\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.37  7.21  0.    0.    5.48  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.66  3.75  5.44  0.    0.    0.    3.5   0.    0.    0.    0.    0.\n",
      "   3.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    7.2   0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.09  0.    0.    5.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.86  0.    0.    4.64  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.27  0.    0.\n",
      "   0.    0.    0.    0.    5.46  0.    4.87  0.    0.  ]\n",
      " [ 0.    0.    0.    4.62  0.    1.84  0.    0.    0.    4.59  0.    0.    0.\n",
      "   0.    0.    0.    4.1   4.47  0.    5.2   0.    4.34  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.87  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    6.87  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    3.45  0.    1.67  0.    4.03  4.26  0.\n",
      "   6.55  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    3.89  0.    0.    0.    0.    0.    0.    2.96  0.    0.    0.    0.\n",
      "   0.    8.24  0.    0.    0.    0.    0.    0.    0.    0.    4.57  0.    0.\n",
      "   0.    0.    0.    3.3   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    2.64  0.    0.    0.    0.    0.    4.04  0.    0.    0.    5.41\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    3.27  0.    0.\n",
      "   4.49  0.    0.    0.    4.43  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.1   0.    0.    0.    0.    0.    4.15  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    2.94  0.    0.    4.52  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.99  0.    5.63  0.    0.    4.6   0.    0.    5.69  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    4.65  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.23  0.    0.    0.    0.    0.    0.\n",
      "   1.49  0.    0.    1.2   0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.47  0.    0.    0.    0.    0.    4.98  0.    0.    4.57  0.    0.\n",
      "   0.    0.    0.    4.63  0.    0.    0.    0.    3.73  0.    0.  ]\n",
      " [ 1.44  0.    0.    0.    0.    0.    5.45  0.    0.    4.59  0.    0.\n",
      "   1.37  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.68  0.    0.\n",
      "   0.    0.    0.    0.    0.    5.47  0.    0.    0.    0.    0.    0.    0.\n",
      "   2.37  0.    0.    1.01  0.    0.    0.    0.    0.    4.48  0.    0.\n",
      "   1.99  3.81  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.56  0.    0.    0.    4.71\n",
      "   0.    5.69  0.    0.    4.01  4.22  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 2.74  0.    0.    0.    0.    3.56  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    6.68  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    3.75  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    6.76  5.86  3.34  0.    0.    0.\n",
      "   0.    0.    0.    0.    1.55  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    4.28  0.    6.17  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   5.08  0.    0.    0.    0.    0.    0.    3.66  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.31  0.    0.    0.    0.    0.    5.12  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.28  0.    0.    5.06  1.77  0.    0.    0.\n",
      "   0.    0.    4.48  0.    0.    0.    3.83  0.    0.    5.07  0.    0.\n",
      "   4.09  5.38  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.75  0.    0.    0.    0.    0.    0.    3.07]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.87  0.    5.91  0.    4.93  0.    0.    0.\n",
      "   3.3   0.    0.    0.    0.    0.    0.    4.05  0.    0.    0.    0.    0.\n",
      "   4.67  0.    0.    4.54  0.    6.01  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.12  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   4.33  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    3.62\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.1   4.8   0.    0.    0.    2.85  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    6.18  0.    2.36  0.    0.    0.    0.    0.    0.    4.11\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.72  0.    0.    0.    0.    0.    5.52  0.    6.77\n",
      "   5.51  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.76  0.    0.    0.    0.    1.48  0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    1.39  0.    0.    0.    7.04  0.\n",
      "   2.31  0.    0.    0.    0.    0.    0.    0.    0.    0.    4.53  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    3.25  0.    0.    0.    5.79\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    4.22\n",
      "   0.    0.    4.97  0.    0.    0.    0.    0.    1.43  0.    0.    0.\n",
      "   3.82  0.    0.    0.    0.    0.    0.    0.    0.    0.    5.36  0.\n",
      "   4.84  0.    0.    0.    0.    0.    0.    2.63  4.24  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    2.54  0.    0.    0.    0.    0.    3.82  0.    0.\n",
      "   0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    1.59  0.    0.    0.    0.    0.    0.    0.    5.02\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.75  0.    0.    6.01\n",
      "   0.    0.    0.    0.    0.    3.12  0.    0.    0.    0.    0.    0.\n",
      "   5.71  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    6.59\n",
      "   0.    0.    0.    0.    0.    0.    1.64  5.07  0.    0.    0.    0.    0.\n",
      "   0.    0.    1.24  1.18  0.    0.    0.    0.    3.31  0.    0.    0.    0.\n",
      "   0.    0.    0.    5.86  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    5.48  0.    0.    5.1\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    6.65  0.    0.    0.\n",
      "   2.63  0.    0.    0.    0.    0.    0.    0.    0.    4.5   0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    6.32  0.    0.    2.71  0.    0.    0.\n",
      "   4.43  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.65  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    5.52  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 6.46  0.    0.    0.    0.    0.    0.    0.    5.72  0.    0.    0.    0.\n",
      "   3.    5.49  0.    0.    0.    5.22  0.    0.    0.    5.71  0.    4.37\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    1.04  0.    0.    3.92  1.34  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    4.06  0.    0.    0.    0.    4.38  0.    0.    0.\n",
      "   1.23  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   1.8   0.    0.    0.    0.    0.    0.    0.    0.    5.4   0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.41  0.    0.    0.    0.    0.    0.    0.    0.    5.83  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    5.53\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    3.48  0.    0.    0.\n",
      "   1.3   4.72  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    5.19  0.    0.    0.\n",
      "   0.    0.    0.    0.    5.    0.    0.    2.81  0.    0.    0.    0.    0.\n",
      "   0.    4.28  6.4   0.    5.56  0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   6.34  0.    0.    0.    0.    0.    0.    0.    0.    0.    4.23  3.79\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    4.68  0.    3.12  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    6.37  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.12  0.    0.    0.    0.    0.    0.    0.    6.65  0.\n",
      "   4.94  0.    3.97  3.39  0.    4.25  0.    0.    0.    4.43  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    4.64  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    5.6   3.88  6.13  0.    0.    0.    0.    0.\n",
      "   0.    2.93  0.    0.    0.    3.21  2.25  0.    0.    0.    0.    0.    0.\n",
      "   0.    6.66  3.55  0.    1.45  2.06  0.    0.    0.    5.15  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    5.57  0.    4.89  0.    2.77  1.33  0.  ]\n",
      " [ 0.    0.    0.    0.    0.    5.19  6.11  0.    0.    0.    0.    0.    0.\n",
      "   3.21  0.    0.    0.    0.    0.    3.88  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    7.56  3.65  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.84  4.72  4.34  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    2.04  0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    1.6   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    1.9   0.    3.28  0.    3.99  0.    0.    3.44\n",
      "   0.    0.    0.    5.39  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    6.73  0.    0.    0.    0.    4.35  0.    0.    0.    3.95  0.    0.\n",
      "   3.91  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    5.26  0.    3.87  0.    0.    0.    1.28  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    4.2   0.    0.    0.    0.\n",
      "   4.06  0.    0.    0.    4.58  0.    0.    4.12  0.    0.    4.93]\n",
      " [ 0.    3.91  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    3.5   0.    5.72  0.    0.    0.    0.    0.    0.    0.\n",
      "   5.53  0.    4.59  4.89  0.    0.    0.    0.    0.    3.22  0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    4.07  0.    0.    0.    0.    7.04\n",
      "   0.    0.    0.    0.    0.    4.65  0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.91  0.    0.    0.    0.    0.    0.    0.\n",
      "   2.83  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    2.51  0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    4.19  0.    3.67  0.    0.\n",
      "   0.    0.    0.    1.75  0.    0.    0.    2.75  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.82  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    3.12  0.    0.    0.    4.42  0.    5.15  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   7.01  0.    0.    0.    0.    0.    0.    0.    1.71  0.    0.    3.33\n",
      "   0.    0.    0.    0.    0.    0.    2.86  0.    0.    0.    0.    5.19\n",
      "   0.    0.    5.53  0.    0.    0.    0.    5.29  0.    0.    0.    0.  ]\n",
      " [ 0.    0.    3.65  0.    0.    0.    0.    0.    0.    0.    5.42  0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    3.72  0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   3.13  0.    0.    0.    0.    0.    0.    4.7   0.    0.    0.    0.\n",
      "   3.35  0.    0.    0.    0.    0.    5.26  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    5.68  0.    0.    0.    0.    0.    0.    3.77\n",
      "   0.    5.52  0.    0.    0.    0.    0.    0.    0.    0.    0.    5.01\n",
      "   0.    0.    2.1   7.07  0.    0.    0.    0.    0.    0.    0.    0.    0.  ]\n",
      " [ 0.    0.    6.79  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    4.54  0.    3.81  0.    0.    5.02  0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    4.47  5.44  0.    6.06  0.    0.    2.81\n",
      "   0.    0.    0.    0.    3.11  0.    5.17  0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAELxJREFUeJzt3X+sX3V9x/Hna1Tc/JFRxrXDtqxoiks1E0iHOLbFjvFzxuI/BrJppyQ1Czg0ZIa6ZBgNg2wq08yxVOmoGYMQxdEsndh1zYyJIIUhUFC5QX60K7SKQzcSHfjeH99T+VLu7f317T0XPs9H8s33fN/nc859f9ve+7rnc875NlWFJKk9v9B3A5KkfhgAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYt6ruBQznmmGNqxYoVfbchSS8qd9555/eramyqcQs6AFasWMHOnTv7bkOSXlSSPDKdcU4BSVKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUqCkDIMnyJDuS3J9kV5JLuvpHk+xJcnf3OHdomw1JxpN8J8lZQ/Wzu9p4kssOz1uSJE3HdG4Eewa4tKruSvJq4M4k27p1V1fVJ4YHJ1kFnA+8EXgt8G9JTuhWfxY4A9gN3JFkS1XdP4o3IkmamSkDoKr2Anu75R8neQBYeohN1gI3VtVPgO8lGQdO6daNV9VDAElu7MYaAJqZHVeOfp9rNox+n9ICN6NzAElWACcBt3eli5Pck2RTksVdbSnw2NBmu7vaZHVJUg+mHQBJXgV8CfhgVf0IuAZ4PXAigyOET46ioSTrk+xMsnP//v2j2KUkaQLTCoAkL2Pww//6qroZoKqeqKpnq+pnwOd4bppnD7B8aPNlXW2y+vNU1caqWl1Vq8fGpvwwO0nSLE3nKqAA1wIPVNWnhurHDg17J3Bft7wFOD/Jy5McD6wEvgncAaxMcnySIxmcKN4ymrchSZqp6VwFdBrwbuDeJHd3tY8AFyQ5ESjgYeD9AFW1K8lNDE7uPgNcVFXPAiS5GLgVOALYVFW7RvheJEkzMJ2rgL4OZIJVWw+xzRXAFRPUtx5qO0nS/PFOYElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjpgyAJMuT7Ehyf5JdSS7p6kcn2Zbkwe55cVdPks8kGU9yT5KTh/a1rhv/YJJ1h+9tSZKmMp0jgGeAS6tqFXAqcFGSVcBlwPaqWgls714DnAOs7B7rgWtgEBjA5cBbgFOAyw+EhiRp/k0ZAFW1t6ru6pZ/DDwALAXWApu7YZuB87rltcAXauA24KgkxwJnAduq6smq+iGwDTh7pO9GkjRtMzoHkGQFcBJwO7CkqvZ2qx4HlnTLS4HHhjbb3dUmq0uSejDtAEjyKuBLwAer6kfD66qqgBpFQ0nWJ9mZZOf+/ftHsUtJ0gSmFQBJXsbgh//1VXVzV36im9qhe97X1fcAy4c2X9bVJqs/T1VtrKrVVbV6bGxsJu9FkjQD07kKKMC1wANV9amhVVuAA1fyrANuGaq/p7sa6FTgqW6q6FbgzCSLu5O/Z3Y1SVIPFk1jzGnAu4F7k9zd1T4CXAXclORC4BHgXd26rcC5wDjwNPBegKp6MsnHgTu6cR+rqidH8i4kSTM2ZQBU1deBTLL69AnGF3DRJPvaBGyaSYOSpMPDO4ElqVEGgCQ1ygCQpEZN5ySw9NK348rR7m/NhtHuTzoMPAKQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSo6YMgCSbkuxLct9Q7aNJ9iS5u3ucO7RuQ5LxJN9JctZQ/eyuNp7kstG/FUnSTEznCOA64OwJ6ldX1YndYytAklXA+cAbu23+LskRSY4APgucA6wCLujGSpJ6smiqAVX1tSQrprm/tcCNVfUT4HtJxoFTunXjVfUQQJIbu7H3z7hjSdJIzOUcwMVJ7ummiBZ3taXAY0Njdne1yeqSpJ5MeQQwiWuAjwPVPX8SeN8oGkqyHlgPcNxxx41il+rbjiv77kDSBGZ1BFBVT1TVs1X1M+BzPDfNswdYPjR0WVebrD7RvjdW1eqqWj02Njab9iRJ0zCrAEhy7NDLdwIHrhDaApyf5OVJjgdWAt8E7gBWJjk+yZEMThRvmX3bkqS5mnIKKMkNwNuAY5LsBi4H3pbkRAZTQA8D7weoql1JbmJwcvcZ4KKqerbbz8XArcARwKaq2jXydyNJmrbpXAV0wQTlaw8x/grgignqW4GtM+pOknTYeCewJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktSoRX03IEmHtOPK0e9zzYbR7/NFyCMASWqUASBJjTIAJKlRBoAkNWrKAEiyKcm+JPcN1Y5Osi3Jg93z4q6eJJ9JMp7kniQnD22zrhv/YJJ1h+ftSJKmazpHANcBZx9UuwzYXlUrge3da4BzgJXdYz1wDQwCA7gceAtwCnD5gdCQJPVjygCoqq8BTx5UXgts7pY3A+cN1b9QA7cBRyU5FjgL2FZVT1bVD4FtvDBUJEnzaLbnAJZU1d5u+XFgSbe8FHhsaNzurjZZXZLUkzmfBK6qAmoEvQCQZH2SnUl27t+/f1S7lSQdZLYB8EQ3tUP3vK+r7wGWD41b1tUmq79AVW2sqtVVtXpsbGyW7UmSpjLbANgCHLiSZx1wy1D9Pd3VQKcCT3VTRbcCZyZZ3J38PbOrSZJ6MuVnASW5AXgbcEyS3Qyu5rkKuCnJhcAjwLu64VuBc4Fx4GngvQBV9WSSjwN3dOM+VlUHn1iWJM2jKQOgqi6YZNXpE4wt4KJJ9rMJ2DSj7iRJh413AktSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaNeWNYJJmYceVo9/nmg2j36ea5hGAJDXKAJCkRhkAktQoA0CSGmUASFKjvApI0ugcjqufdNh4BCBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNmlMAJHk4yb1J7k6ys6sdnWRbkge758VdPUk+k2Q8yT1JTh7FG5Akzc4ojgDWVNWJVbW6e30ZsL2qVgLbu9cA5wAru8d64JoRfG1J0iwdjimgtcDmbnkzcN5Q/Qs1cBtwVJJjD8PXlyRNw1wDoICvJrkzyfqutqSq9nbLjwNLuuWlwGND2+7uapKkHiya4/a/XVV7krwG2Jbk28Mrq6qS1Ex22AXJeoDjjjtuju1JkiYzpyOAqtrTPe8DvgycAjxxYGqne97XDd8DLB/afFlXO3ifG6tqdVWtHhsbm0t7kqRDmHUAJHllklcfWAbOBO4DtgDrumHrgFu65S3Ae7qrgU4FnhqaKpIkzbO5TAEtAb6c5MB+/qmqvpLkDuCmJBcCjwDv6sZvBc4FxoGngffO4WtL7dlxZd8d6CVm1gFQVQ8Bb56g/gPg9AnqBVw0268nSRot7wSWpEbN9SogSXrxGfV02poNo93fPPEIQJIaZQBIUqMMAElqlAEgSY0yACSpUV4F9BJ19bbvznrbD51xwgg7kbRQeQQgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGuVloAvUXC7jlKTp8AhAkhplAEhSo5wC0gvMdfrJO4mlFwePACSpUQaAJDXKAJCkRhkAktQoA0CSGuVVQIeJN3JJWug8ApCkRhkAktQoA0CSGvWSPgfg/4srSZN7SQfAXHgSd/YO/rM79dEfzGj7t77uV0bZjqRJOAUkSY0yACSpUQaAJDVq3s8BJDkb+DRwBPD5qrpqvnvQwvaNh2Z2zmCY5w+k6ZvXI4AkRwCfBc4BVgEXJFk1nz1IkgbmewroFGC8qh6qqp8CNwJr57kHSRLzPwW0FHhs6PVu4C3z3INewuYyfQROIWmWdlw5+n2u2TD6fR5kwd0HkGQ9sL57+T9JvtNnP0OOAb7fdxOTWMi9wcLuz95mx95mZwa9fWQuX+fXpjNovgNgD7B86PWyrvZzVbUR2DifTU1Hkp1VtbrvPiaykHuDhd2fvc2Ovc3OQuttvs8B3AGsTHJ8kiOB84Et89yDJIl5PgKoqmeSXAzcyuAy0E1VtWs+e5AkDcz7OYCq2gpsne+vOwILblpqyELuDRZ2f/Y2O/Y2Owuqt1RV3z1IknrgR0FIUqMMgCkkWZ5kR5L7k+xKcknfPR0syRFJ/jPJv/Tdy7AkRyX5YpJvJ3kgyVv77umAJB/q/j7vS3JDkl/suZ9NSfYluW+odnSSbUke7J4XL6De/rr7e70nyZeTHLVQehtad2mSSnLMQuotyQe6P7tdSf6qj94OMACm9gxwaVWtAk4FLlqAH19xCfBA301M4NPAV6rq14E3s0B6TLIU+FNgdVW9icEFCef32xXXAWcfVLsM2F5VK4Ht3es+XMcLe9sGvKmqfgP4LnD471qa2HW8sDeSLAfOBB6d74aGXMdBvSVZw+DTD95cVW8EPtFDXz9nAEyhqvZW1V3d8o8Z/BBb2m9Xz0myDPgD4PN99zIsyS8DvwtcC1BVP62q/+63q+dZBPxSkkXAK4D/6rOZqvoa8ORB5bXA5m55M3DevDbVmai3qvpqVT3TvbyNwT09826SPzeAq4EPA72d5Jyktz8Brqqqn3Rj9s17Y0MMgBlIsgI4Cbi9306e528Y/EP/Wd+NHOR4YD/wD9301OeTvLLvpgCqag+D37weBfYCT1XVV/vtakJLqmpvt/w4sKTPZg7hfcC/9t3EAUnWAnuq6lt99zKBE4DfSXJ7kv9I8pt9NmMATFOSVwFfAj5YVT/qux+AJG8H9lXVnX33MoFFwMnANVV1EvC/9DeF8TzdXPpaBiH1WuCVSf6o364OrQaX6y24S/aS/DmDadLr++4FIMkrGHyGwl/03cskFgFHM5hO/jPgpiTpqxkDYBqSvIzBD//rq+rmvvsZchrwjiQPM/hk1d9L8o/9tvRzu4HdVXXgaOmLDAJhIfh94HtVtb+q/g+4GfitnnuayBNJjgXonnudLjhYkj8G3g78YS2c68lfzyDYv9V9XywD7kryq7129ZzdwM018E0GR+69nKQGA2BKXTpfCzxQVZ/qu59hVbWhqpZV1QoGJzH/vaoWxG+yVfU48FiSN3Sl04H7e2xp2KPAqUle0f39ns4COUF9kC3Aum55HXBLj708T/cfO30YeEdVPd13PwdU1b1V9ZqqWtF9X+wGTu7+PS4E/wysAUhyAnAkPX5wnQEwtdOAdzP47fru7nFu3029SHwAuD7JPcCJwF/23A8A3VHJF4G7gHsZfB/0eodmkhuAbwBvSLI7yYXAVcAZSR5kcNTSy/+eN0lvfwu8GtjWfU/8/QLqbUGYpLdNwOu6S0NvBNb1efTkncCS1CiPACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmN+n+ly2ehxDF7SAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4006c8240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa4006544e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(numpy.min(questions), numpy.min(questions[questions.nonzero()]), numpy.max(questions))\n",
    "print(numpy.min(students), numpy.max(students))\n",
    "print(\"---\")\n",
    "qws = qn_table.get_weights()[0]\n",
    "sws = s_table.get_weights()[0]\n",
    "print(numpy.min(qws), numpy.min(qws[qws>=1]), numpy.max(qn_table.get_weights()[0]))\n",
    "print(numpy.min(sws), numpy.max(s_table.get_weights()[0]))\n",
    "\n",
    "import sys\n",
    "numpy.set_printoptions(precision=2, suppress=True, threshold=sys.maxsize)\n",
    "\n",
    "print(qws)\n",
    "\n",
    "plt.hist(qws[qws>=1].flatten(), alpha=0.5)\n",
    "plt.hist(sws.flatten(), alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "sig = lambda z : 1/(1+numpy.exp(-z))\n",
    "obs = numpy.zeros((len(sws), len(qws)))\n",
    "probs = numpy.zeros((len(sws), len(qws)))\n",
    "#obs = numpy.matmul(viewers, movies.T)/n_factors\n",
    "vz = []\n",
    "mz = []\n",
    "scz =[]\n",
    "for vi in range(len(sws)):\n",
    "    for mi in range(len(qws)):\n",
    "        zmask = (qws[mi]<1).astype(int)\n",
    "        deltas = sws[vi]-qws[mi]\n",
    "        prs = sig(deltas)\n",
    "        prs = numpy.maximum(zmask,prs)\n",
    "\n",
    "#             print(vi,mi)\n",
    "#             print(\"S\", students[vi])\n",
    "#             print(\"Q\", questions[mi])\n",
    "#             print(\"Z\", zmask)\n",
    "#             print(\"D\", deltas)\n",
    "#             print(\"p\", prs)\n",
    "#             print(\"P\", numpy.prod(prs))\n",
    "        pr = numpy.prod(prs)\n",
    "        obs[vi,mi] = (random.random() < pr)\n",
    "        probs[vi,mi] = numpy.prod(prs)\n",
    "#             print(vi,mi, numpy.prod(prs))\n",
    "\n",
    "plt.hist(probs.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0] 13\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0] 14\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0] 11\n",
      "[0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 11\n",
      "[0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] 12\n",
      "[0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0] 12\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 12\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0] 9\n",
      "[1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0] 11\n",
      "[1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0] 16\n",
      "[0 0 0 1 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0] 20\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0] 10\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 10\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0] 11\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1] 11\n",
      "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0] 14\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1] 11\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0] 13\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 10\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0] 14\n",
      "[0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0] 10\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0] 12\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0] 11\n",
      "[1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0] 14\n",
      "[0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0] 12\n",
      "[1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0] 17\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] 15\n",
      "[0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0] 15\n",
      "[0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0] 12\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0] 8\n",
      "[1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0] 10\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0] 18\n",
      "[1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0] 11\n",
      "[0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1] 14\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1] 10\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0] 17\n",
      "[0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0] 16\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0] 12\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] 14\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0] 11\n",
      "[1 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0] 13\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0] 8\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0] 15\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0] 16\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 13\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 6\n",
      "[0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] 17\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0] 11\n",
      "[1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0] 18\n",
      "[1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] 15\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0] 13\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0] 13\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1\n",
      " 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0] 20\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 7\n",
      "[0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0] 14\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0] 11\n",
      "[0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0] 19\n",
      "[0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0] 14\n",
      "[0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0] 16\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0] 10\n",
      "[1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0] 12\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0] 17\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0] 11\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 8\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1] 10\n",
      "[0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0] 14\n",
      "[0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0] 10\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0] 12\n",
      "[0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0] 9\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] 10\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0] 12\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0] 18\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0] 12\n",
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0] 12\n",
      "[0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0] 16\n",
      "[0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0] 14\n",
      "[0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 13\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0] 12\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0] 12\n",
      "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 12\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0] 12\n",
      "[0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1] 16\n",
      "[0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 12\n",
      "[0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] 14\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0] 14\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0] 15\n",
      "[0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 13\n",
      "[1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0] 14\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0] 11\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0] 15\n",
      "[0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0] 11\n",
      "[0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0] 11\n",
      "[0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0] 12\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 10\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0] 11\n",
      "[0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0] 13\n",
      "[1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1] 12\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 10\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1] 9\n",
      "[0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0] 16\n"
     ]
    }
   ],
   "source": [
    "for ix in range(len(qws)):\n",
    "    flags = (qws[ix]>1).astype(int) \n",
    "    print(flags, sum(flags))\n",
    "# print((qws>=1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vi,mi,sc in zip(all_sz,all_qz,all_pfz):\n",
    "    print(vi,mi,sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sw = s_table.get_weights()[0]\n",
    "# qw = qn_table.get_weights()[0]\n",
    "\n",
    "# print(sw.shape)\n",
    "# print(qw.shape)\n",
    "\n",
    "# mm = numpy.dot(qw, sw.T)/n_factors\n",
    "# # mm = numpy.sum(mm, axis=1)\n",
    "# print(mm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0224 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0219 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0214 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0211 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0209 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0206 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0205 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0202 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0199 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0195 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0182 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0179 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0179 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0164 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0163 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0162 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0161 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0160 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0159 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0157 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0156 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0155 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0154 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0153 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0152 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0150 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0149 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0147 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0146 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0146 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0146 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0146 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0146 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0145 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0142 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0141 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0140 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0139 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0138 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0137 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0136 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0135 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0134 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0133 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0132 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0131 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0130 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0129 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0128 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0127 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0126 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0125 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0124 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0123 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0122 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0121 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0120 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 411/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0119 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 434/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0118 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0117 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 476/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0116 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 497/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0115 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "8000/8000 [==============================] - 0s 12us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0114 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 542/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 547/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0113 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 564/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 565/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 566/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 567/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 568/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 569/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 570/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 571/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 573/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 574/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 575/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 577/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 579/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 580/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 583/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0112 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 586/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 587/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 588/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 590/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 591/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 594/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 595/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 596/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 597/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 598/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 600/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 602/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 603/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 604/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 605/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 606/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 607/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 609/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 610/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 611/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 612/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 613/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 617/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 618/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0111 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 620/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 623/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 624/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 625/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 626/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 627/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 628/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 629/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 630/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 631/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 632/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 634/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 635/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 636/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 638/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 639/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 640/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 641/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 642/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 644/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 645/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 646/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 647/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 648/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 650/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 652/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 654/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 655/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 656/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 657/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 658/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0110 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 661/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 662/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 663/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 664/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 665/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 666/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 667/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 668/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 669/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 670/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 671/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 675/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 676/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 677/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 678/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 679/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 680/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 681/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 682/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 683/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 684/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 685/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 687/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 688/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 689/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 690/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 691/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 692/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 693/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 694/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 695/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 696/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 697/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 698/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 699/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 700/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 701/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 702/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 703/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 704/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0109 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 705/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 706/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 707/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 708/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 709/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 710/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 711/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 712/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 713/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 714/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 715/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 716/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 717/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 718/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 720/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 721/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 722/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 723/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 724/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 725/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 726/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 727/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 728/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 729/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 730/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 731/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 732/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 733/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 734/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 735/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 736/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 737/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 738/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 739/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 740/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 741/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 742/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 743/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 744/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 745/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 746/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 747/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 748/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 749/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 750/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 751/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 752/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 753/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 754/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 755/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 756/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 757/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 758/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 759/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 760/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0108 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 761/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 762/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 763/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 764/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 765/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 766/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 767/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 768/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 769/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 770/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 771/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 772/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 773/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 774/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 775/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 776/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 777/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 778/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 779/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 780/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 782/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 783/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 784/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 786/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 787/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 788/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 789/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 790/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 791/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 792/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 793/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 794/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 795/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 796/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 797/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 798/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 799/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 800/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 801/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 802/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 803/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 804/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 805/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 806/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 807/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 808/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 809/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 810/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 811/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 812/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 813/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 814/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 815/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 816/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 817/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 818/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 819/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 820/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 821/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 822/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 823/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 824/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 825/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 826/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 827/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 828/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 829/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 830/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 831/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 832/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 833/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 834/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 835/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 836/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 837/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 838/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 839/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 840/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 841/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 842/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 843/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 844/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 845/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 846/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 847/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 848/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 849/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 850/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 851/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 852/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 853/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 854/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 855/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 856/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 857/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 858/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 859/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 860/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 861/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 862/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 863/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 864/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 865/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 866/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 867/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 868/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 869/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 870/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 871/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 872/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 873/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 874/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 875/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 876/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 877/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 878/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 879/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 880/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 881/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 882/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 883/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 884/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 885/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 886/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 887/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 888/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 889/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 890/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 891/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 892/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 893/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 894/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 895/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 896/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 898/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 899/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 900/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 901/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 902/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 903/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 904/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 905/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 906/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 907/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 908/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 909/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 910/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 911/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 912/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 913/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 914/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 915/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 916/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 917/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 918/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 919/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 920/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0106 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 921/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 922/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 923/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 924/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 925/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 926/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 927/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 928/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 929/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 930/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 931/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 932/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 933/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 934/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 935/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 936/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 937/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 938/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 939/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 940/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 941/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 942/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 943/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 944/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 945/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 946/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 947/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 948/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 949/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 950/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 951/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 952/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 953/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 954/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 955/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 956/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 957/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 958/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 959/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 960/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 961/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 962/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 963/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 964/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 965/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 966/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 967/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 968/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 969/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 970/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 971/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 972/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 973/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 974/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 975/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 976/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 977/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 978/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 979/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 980/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 981/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 982/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 983/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 984/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 985/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 986/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 987/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 988/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 989/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 990/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 991/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 992/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 993/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 994/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 995/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 996/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 997/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 998/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 999/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 1000/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.0105 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa43a4778d0>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor=\"loss\", restore_best_weights=True, patience=10)\n",
    "initpfz = [0.5 for _ in range(len(pfz))]\n",
    "m.fit(x=[qz,sz], y=numpy.array(initpfz).reshape(-1,1), batch_size=1000, shuffle=True, epochs=1000, verbose=1, callbacks=[es], validation_split=1000/len(initpfz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 6.0 16.7617400138\n",
      "6.0 12.0\n",
      "---\n",
      "0.0 1.88467 10.0476\n",
      "6.0 17.289\n",
      "[[  0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     3.55   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.02   0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.02   0.     0.     0.09   0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.02   0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.02   0.     0.     0.     0.     8.79   0.     0.\n",
      "    4.02   0.     0.     0.  ]\n",
      " [  0.     0.35   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    7.19   0.     0.     0.03   0.     0.     0.16   0.     0.     0.     0.\n",
      "    0.     0.24   0.     0.     0.     0.     0.19   0.     0.     0.35\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.02   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.32   0.     0.     0.\n",
      "    0.     0.     0.31   0.13   0.     0.     7.13   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     3.05   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    4.26   0.     0.     0.     0.     9.23   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     6.43   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.01   0.     0.     0.     0.01   0.     0.     0.     0.     4.29\n",
      "    0.     0.     0.     0.     0.     0.01   0.01   0.02   0.     0.     0.\n",
      "    0.     0.     0.     0.02   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.\n",
      "    9.33   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.04   0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     4.41   0.\n",
      "    0.01   0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.01   0.01   0.     0.     0.     0.     0.     0.     0.02\n",
      "    0.     0.     0.     0.     0.     0.01   0.01   0.01   0.01   0.01\n",
      "    0.     0.01   0.     0.     0.01   7.02   0.     0.01   0.     0.\n",
      "    6.22   0.     0.     0.01   0.     0.     0.01   0.     0.     0.     0.\n",
      "    0.01   0.     0.46   0.01   0.     0.     0.01   0.     0.13   0.     0.\n",
      "    0.01   0.     0.     0.02   0.     0.01   0.02   0.     0.01   0.     0.\n",
      "    0.     0.13   0.02   0.01   0.     0.     0.     0.     0.     0.03\n",
      "    6.05   0.     0.01   0.     0.     0.01   0.     0.01   0.     0.01\n",
      "    0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.01   0.     0.     0.63   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.02   0.     0.     0.     0.35\n",
      "    0.     0.     0.     0.     0.     0.     0.14   6.79   0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     7.47   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.08   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.     0.     0.01   0.16\n",
      "    0.     0.     0.     0.     0.     0.     0.04   0.     0.     0.05\n",
      "    0.     0.     0.     0.     0.     0.03   0.     0.     0.07   0.     0.\n",
      "    0.     6.5    0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.05   0.01\n",
      "    0.     0.     0.17   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.04   0.     0.01   0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.09   0.     0.     0.     0.07   0.     0.17   0.     5.76\n",
      "    0.     6.85   0.     0.     0.     0.     0.     7.38   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.15   0.05   0.     0.\n",
      "    0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     5.3    0.     0.     6.39   0.     0.\n",
      "    0.     0.     6.36   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     6.35\n",
      "    0.87   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.08   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     7.5    0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.1    0.     0.     0.02   0.\n",
      "    3.71   6.57   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.24   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     5.85   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.  ]\n",
      " [  0.22   0.02   0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.07   0.     0.     0.     0.     0.04   0.01   0.01   0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.25   0.     0.     0.     0.     0.     0.     0.     0.19\n",
      "    0.     0.04   0.19   0.     0.     0.     0.05   0.01   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.08   0.     0.     0.\n",
      "    0.     0.01   0.01   0.     9.51   0.     0.     0.01   0.02   0.02\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.17   0.     0.\n",
      "    0.18   0.     0.     0.12   0.     0.     0.     0.01   0.     0.     0.\n",
      "    0.     0.04   0.     0.     0.  ]\n",
      " [  0.     0.02   0.01   0.     0.     0.01   0.     0.     0.01   0.02\n",
      "    0.     0.     0.     0.     0.     0.     0.02   0.     0.     0.02\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.01   0.     0.     0.01   0.\n",
      "    0.01   0.     0.03   0.     0.     0.     0.     0.     0.04   0.\n",
      "    8.49   0.01   0.     0.01   0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.01   0.     0.     0.29   0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.01   0.     6.62   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.27   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.05   0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.15   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     6.38   0.     0.     0.     0.\n",
      "    0.     0.     0.05   0.     0.     0.     6.98   0.42   6.88   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.27   0.     0.     0.     0.13   0.     0.     0.     0.     0.01\n",
      "    0.     0.12   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.02   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.03   0.     0.01   0.  ]\n",
      " [  0.     0.43   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     6.54   0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.01   0.     0.01   0.01   0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.13\n",
      "    0.     0.     0.     0.     0.     0.     0.     5.8    0.01   0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     6.19   0.14   0.     0.\n",
      "    0.     0.     0.     0.     6.66   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.18   0.     0.01   0.     0.01\n",
      "    0.     0.     0.     0.     0.     6.79   0.     0.     0.     0.     0.\n",
      "    7.02   0.     0.     0.     0.     0.     0.01   0.01   0.     0.     0.\n",
      "    0.     0.01   0.     0.01   0.     0.01   0.     5.44   0.     0.\n",
      "    0.01   0.01   0.     0.     0.     0.01   0.01   0.     0.01   0.     0.\n",
      "    0.01   0.     0.02   0.01   0.     0.     0.     0.01   0.     0.\n",
      "    0.03   0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.01   0.     0.     0.     0.01   0.     0.\n",
      "    7.14   0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.05   0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     8.02\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     4.88\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.05   6.01   0.     0.     0.     0.01   0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.02\n",
      "    0.     0.     0.     0.     0.     0.     0.01   0.     0.08   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     6.81   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     6.74   0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.84   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     6.51   0.     0.     0.     7.61   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     5.48   0.     0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.02   0.     0.     0.01   0.     0.08   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.02   0.     0.     0.     0.\n",
      "    0.01   0.     0.02   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.     0.01   0.     0.     0.     0.\n",
      "    0.     0.04   0.     0.     0.     0.03   0.     4.18   0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.01   0.     0.08   0.04\n",
      "    0.21   0.07   0.02   0.     0.     0.     0.     0.     0.16   0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.03   0.     0.11  10.05   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     6.05\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.05\n",
      "    0.     0.     0.     0.     0.     6.78   0.     0.05   0.     0.     0.\n",
      "    0.     0.     0.15   0.     0.     0.     0.     0.     0.     0.\n",
      "    6.06   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     6.38\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.06   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.01   0.     0.     0.01   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     0.01   0.03\n",
      "    0.01   0.     0.     0.     0.01   0.     0.01   0.     0.     0.04\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     7.23   0.     0.     0.03\n",
      "    0.     0.01   0.     0.     0.     8.71   0.     0.01   0.     0.05\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.04   0.05   0.     5.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.21   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     6.2    0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.04   0.     0.     0.     0.     0.     0.\n",
      "    0.08   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    4.98   9.55   0.     3.26   0.     0.     0.     0.     0.03   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     5.86\n",
      "    0.     0.     0.     0.     0.73   0.     0.     0.     0.     6.14\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     7.01   0.     6.47   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     4.42   0.     0.     0.     0.     0.     0.     0.\n",
      "    5.98   0.     0.     0.     0.     0.     0.     0.     3.85   0.     0.\n",
      "    0.     0.     6.62   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     6.86   0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.     7.96   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.02   0.     0.     0.\n",
      "    0.05   0.05   0.     0.     0.     0.     0.     0.01   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.07   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    7.07   0.     0.     0.     0.02   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.09   0.04   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.01   4.91\n",
      "    0.     0.     0.  ]\n",
      " [  6.91   0.01   0.     0.     0.     0.     0.01   0.01   0.     0.01\n",
      "    0.01   0.     0.     0.     0.     0.01   0.01   0.01   0.01   0.02\n",
      "    0.     0.     0.02   0.01   0.     0.32   0.     0.07   0.     0.01\n",
      "    0.     0.     0.     0.     0.01   6.63   0.01   0.05   0.     0.08\n",
      "    0.     0.     0.     0.01   0.02   0.01   0.     0.01   0.01   0.01\n",
      "    0.     0.     0.01   0.01   0.     0.01   0.     0.02   0.01   0.     0.\n",
      "    0.     0.     0.     0.01   0.01   0.     0.     0.02   0.     0.01\n",
      "    0.23   0.     0.03   0.     0.     0.     0.     0.01   0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.01   0.01   0.16   0.     0.\n",
      "    7.31   0.     0.01   0.     0.13   0.     0.     0.  ]\n",
      " [  0.     0.01   0.     0.     0.     0.     0.     0.     0.01   0.01\n",
      "    0.01   0.     0.     0.     0.     0.     0.01   0.     0.01   0.01\n",
      "    0.     0.01   0.     0.     0.01   0.     0.01   0.01   0.     0.01\n",
      "    0.     0.     0.     0.01   0.     0.01   0.     0.01   0.01   0.     0.\n",
      "    0.     0.     5.82   0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.01   0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.     6.73   0.02   6.64   0.     0.     0.     0.02   5.99   0.01\n",
      "    0.01   0.     0.01   0.     0.02   0.     0.     0.01   0.     0.\n",
      "    0.04   0.3    0.     0.     0.     0.     0.01   0.     0.05   0.01\n",
      "    0.     0.     0.01   0.     0.     0.1    0.  ]\n",
      " [  7.21   0.37   0.06   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.02   0.     0.     0.32   0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.09   0.     7.8    0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.13   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.     0.01   0.\n",
      "    0.08   0.     0.     0.     0.     0.     0.     0.01   0.01   0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.44   0.04   0.     0.17\n",
      "    0.     0.06   0.     0.     0.     0.     0.01   0.01   0.     0.27\n",
      "    0.     0.     0.     0.13   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     6.13   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.02   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     6.73   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     5.88   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.04   0.     6.68\n",
      "    0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     6.34   0.51   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.07   0.     0.     0.     0.21   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     6.96   0.     0.     0.     6.58\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.06   0.     0.     0.45   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.03\n",
      "    0.     0.     0.  ]\n",
      " [  0.13   0.01   0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.1    0.     0.17   0.     0.     0.     0.     0.01   0.01   0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.01   0.     0.01\n",
      "    0.01   0.     0.     0.01   0.     0.     0.     0.01   0.     0.\n",
      "    0.03   0.     0.     0.     0.21   0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.01   0.     0.01   0.04   0.     0.     0.\n",
      "    0.     0.01   0.01   0.     0.01   0.     0.     0.     0.     0.\n",
      "    6.94   0.01   0.     0.     0.     0.     0.01   0.02   0.     0.\n",
      "    0.01   0.     6.69   0.     0.01   0.     0.01   0.     0.     0.\n",
      "    0.01   0.     0.     0.     6.53   0.13   0.01   0.  ]\n",
      " [  0.54   0.     0.     0.     0.04   0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.01   0.     0.     0.     0.05   0.     0.07\n",
      "    0.     0.     0.06   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.02   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.02   0.     0.     0.01   0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.04   0.01   0.     6.66\n",
      "    0.     0.     0.     6.98   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     7.49   0.     0.01   0.02   0.     0.\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.07   0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     6.92   0.     0.\n",
      "    0.     0.     0.     0.     0.     2.93   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     5.87\n",
      "    0.11   0.     0.     0.     0.     0.05   0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.02   0.     0.02   0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     8.6\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.08   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     9.05   0.     0.     0.     0.11   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     2.85   0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.11   0.     0.     0.     3.15   0.     4.25   0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.45   0.     0.     0.     0.     0.     0.01   0.     0.01   0.01\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.01   0.     0.     0.\n",
      "    0.     8.2    0.01   0.     0.     0.01   0.     0.     0.     0.\n",
      "    0.07   0.     0.     0.05   0.1    0.08   0.     0.     0.     0.14\n",
      "    0.     0.01   0.     0.06   0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.01   0.     0.     0.     0.     0.     0.01\n",
      "    0.01   0.01   0.     0.     0.     0.     0.     0.02   0.01   0.28\n",
      "    8.13   0.     0.     0.     0.     0.     0.05   0.     0.     0.13\n",
      "    0.01   0.     0.     0.01   0.     0.     0.06   0.  ]\n",
      " [  0.     0.     5.55   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.09   0.     0.     0.39   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.47\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     8.82\n",
      "    0.     0.     0.     0.     0.05   0.     0.     0.     0.     0.44\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     5.57   0.  ]\n",
      " [  0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.49   8.09   0.     0.     0.     0.\n",
      "    0.43   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.05   6.38   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     6.48   0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.05   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.02   0.08   0.     0.01   0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.01   0.01   0.     0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     7.7    0.     0.01   0.     0.01   0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     0.01   0.     0.\n",
      "    0.01   0.     0.     0.     6.44   0.05   0.01   0.01   0.     0.     0.\n",
      "    0.01   0.     0.     0.01   0.     0.01   0.     0.     0.01   0.     0.\n",
      "    0.01   0.     0.01   0.     0.     0.01   0.     0.     0.01   0.     5.4\n",
      "    0.09   0.     0.     0.     0.17   0.     0.01   0.     0.     0.01\n",
      "    0.     0.     0.01   0.01   0.01   0.     0.01   0.     0.     0.\n",
      "    0.01   0.     6.11   0.     0.     0.01   0.     0.     0.01   0.01\n",
      "    0.     0.     0.09   0.  ]\n",
      " [  0.     0.18   0.12   0.     0.     0.     0.     0.     7.79   0.     0.\n",
      "    0.     0.     0.     0.     0.15   0.01   0.     0.     0.03   0.\n",
      "    0.16   0.     0.     0.     0.     0.     0.04   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.5    0.01   0.     0.     0.     0.     0.     0.     0.     0.3\n",
      "    0.     0.01   0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.15   0.     0.\n",
      "    0.     0.     0.     0.     0.21   0.08   0.     0.     0.16   0.\n",
      "    0.12   7.36   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.  ]\n",
      " [  0.09   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.06   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.     8.7    0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.12   0.     0.     0.     0.     0.\n",
      "    3.77   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.49   0.     0.15   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.04   0.     0.\n",
      "    0.     0.     0.     0.     6.64   0.     0.     0.     0.     0.\n",
      "    0.04   0.     0.     0.1    0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    9.2    0.01   0.     0.     0.     0.     0.01   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     4.26   0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     2.64   0.     0.     0.     0.     0.\n",
      "    0.     0.03   0.     0.     0.     0.     0.     0.01   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.02   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.03   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    6.6    0.     0.     0.     0.     1.88   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     6.29   6.27\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     5.8    0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.01   0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.05   0.01   0.01   0.     0.     0.\n",
      "    0.     0.33   0.     0.     0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.11   0.     0.     0.     0.01   0.05   0.     0.17   0.     0.     0.\n",
      "    0.     0.     0.     7.45   0.     0.     0.     0.     0.     0.18\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.14\n",
      "    0.     6.05   0.01   0.     0.     0.     0.     0.     0.01   0.01\n",
      "    0.     0.01   0.     0.     0.01   0.     0.01   0.     0.     0.\n",
      "    0.01   0.     0.01   0.     0.01   6.62   0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.01   0.  ]\n",
      " [  0.     0.     0.     0.     0.     6.14   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     5.99   6.29\n",
      "    0.     5.72   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    5.92   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     7.48   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.28   0.     0.     0.     0.     0.     0.     0.14   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.06   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.52   0.     0.     0.     0.     0.     0.     0.     0.     0.07\n",
      "    0.02   6.97   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.19   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.75   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.01   0.     0.     0.\n",
      "    0.     0.     0.01   0.01   0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     5.94   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    7.32   0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.     0.     0.04   0.     0.\n",
      "    0.     0.19   0.01   0.01   6.29   0.     0.     7.86   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.14   0.01\n",
      "    0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     7.64   0.     0.     0.01   0.     0.01   0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.01   0.     0.     0.01   0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.02   0.     0.     0.01\n",
      "    6.31   0.     6.06   0.     0.     0.01   0.     0.05   0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.     0.     0.04   0.01\n",
      "    0.     5.91   0.     0.     0.     0.     0.     0.     0.01   0.\n",
      "    0.11   0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.  ]\n",
      " [  0.     0.     0.     5.85   0.     0.     0.     0.01   0.     0.01\n",
      "    0.     0.     0.01   0.     0.     0.01   0.01   6.17   0.     0.01\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     6.89   0.     0.01   0.     0.     0.01   0.     0.     0.\n",
      "    0.     6.32   0.02   0.01   0.     0.01   0.01   0.01   0.     0.     0.\n",
      "    0.01   0.     0.01   0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.01   0.01   0.     0.01   0.     0.     0.     0.01   0.     0.\n",
      "    0.02   0.     0.     0.     0.     0.01   0.02   0.4    0.     0.01\n",
      "    0.     0.01   0.     0.01   0.01   0.01   0.     0.     0.01   0.     0.\n",
      "    0.     0.19   0.     0.     0.01   0.  ]\n",
      " [  0.     0.02   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.06   0.     0.02   0.     0.     0.     0.01   0.2    0.     0.09\n",
      "    0.     0.     0.06   0.     0.     0.     0.     0.05   0.     0.\n",
      "    0.01   0.     0.     0.04   0.     0.     0.     0.     0.09   0.     0.\n",
      "    0.     0.     0.     0.     0.02   0.     0.     0.     0.     7.89\n",
      "    0.     0.     0.23   0.24   0.     0.     6.6    0.     0.     0.01\n",
      "    0.     0.     0.01   0.     0.04   0.03   0.     0.     0.     0.\n",
      "    0.03   0.02   0.14   0.     0.09   0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.08   0.     0.01\n",
      "    0.     0.     0.     0.     0.09   0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     5.12   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     7.37   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     5.13   6.6    0.     0.\n",
      "    0.     0.     0.     0.     6.16   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.     0.01   0.     0.01   0.     0.12   0.     0.01   0.     0.01\n",
      "    0.02   0.     0.     0.     0.     0.     0.01   0.     0.01   0.     0.\n",
      "    0.01   0.     0.01   0.01   0.01   0.     0.39   0.     0.01   0.\n",
      "    0.02   0.     0.     0.     0.01   0.     7.1    0.     0.     0.\n",
      "    0.07   0.     0.     6.85   0.01   0.     0.     0.     0.01   0.01\n",
      "    0.     0.02   0.     0.     0.01   0.     0.     0.     0.     0.16\n",
      "    0.     0.15   0.     0.01   0.01   0.     0.     0.21   0.     0.01\n",
      "    0.     0.     0.01   0.     6.03   0.     0.     0.     0.     0.12\n",
      "    0.01   0.     0.     0.01   0.     0.     0.     0.02   0.01   0.     0.\n",
      "    0.     0.     0.01   0.     0.02   0.     0.     0.  ]\n",
      " [  0.     0.     0.     6.21   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     7.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     5.53   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.03   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.28   0.     0.     0.11   0.     6.89\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.  ]\n",
      " [  0.03   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.31   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     7.93   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.16   0.     0.     0.     0.     0.13   0.     0.     0.03   0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.     0.     6.61   0.     3.12   0.     0.04   0.\n",
      "    0.04   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.1    0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    5.12   0.     0.     0.     6.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     7.87   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     6.58\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    4.48   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     6.89   6.14   6.2    0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     5.42   0.     0.     0.     0.\n",
      "    0.     0.     5.31   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.04   0.     0.     0.     0.     0.01   0.     0.     0.68   0.05\n",
      "    0.     0.     0.     0.     0.     0.     0.23   0.     0.     0.     0.\n",
      "    0.     0.     0.08   0.     0.     0.     0.     0.     0.04   0.\n",
      "    0.07   8.52   0.     0.     0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     7.18   0.     0.     0.     0.     0.     0.\n",
      "    0.04   0.     0.     0.     0.     0.     0.     0.35   0.     0.     0.\n",
      "    0.     0.     0.08   0.     0.01   0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.03   0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.01   0.     6.4    0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.15   0.     0.     0.     6.64\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.03   5.63   0.     0.\n",
      "    0.     6.13   0.     0.     0.     0.09   0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.04   0.     0.     0.     0.     0.     0.     0.     0.     0.1    0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.02   0.     0.     0.     0.03   0.     0.     0.08   0.     0.     0.\n",
      "    0.     0.04   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.09   0.     4.76   0.     0.\n",
      "    0.     8.47   0.     6.19   0.     0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.16   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.1    0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.17   0.     0.     7.28   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.02   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.05   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.03   5.47   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    8.68   0.45   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.6    0.\n",
      "    0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.1    0.     0.     0.\n",
      "    0.     0.     8.41   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     5.83   0.     0.     0.\n",
      "    0.     0.     0.08   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     6.2    0.\n",
      "    0.     0.05   0.     0.     0.     0.     5.92   0.1    0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.     0.     0.01   0.     0.     0.     0.     4.66   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.04   0.     0.     0.     0.     3.99   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.03   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.03   0.     0.01   0.01   0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.03\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.02\n",
      "    0.     0.     9.09]\n",
      " [  0.     0.     0.     0.01   0.     6.98   0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.03   7.38   0.11   0.18   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.02   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     5.42   0.\n",
      "    0.05   0.     0.     0.01   0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.04   0.     0.13   0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.06   0.     0.     0.06   0.     0.03   0.     0.\n",
      "    0.05   0.     0.     0.01]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.04   0.     0.\n",
      "    0.     0.     0.     0.     8.58   0.     0.     0.     0.04   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.04   0.\n",
      "    0.22   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.71   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.06   0.     0.     0.     0.     0.72   0.     0.03   0.     0.\n",
      "    0.     0.     0.12   6.32   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.03   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     5.85   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     7.64   0.     0.     0.     0.     0.     0.\n",
      "    0.04   0.     0.04   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     6.83   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.03   0.     0.     0.     0.     6.49   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.04   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     6.56   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     3.18   0.     5.76   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     6.38   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     7.25   0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     6.54   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     6.69   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     8.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.38   0.     4.45   0.     0.\n",
      "    0.  ]\n",
      " [  6.4    0.     0.     0.02   0.     0.     8.45   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.06   0.     0.     0.08   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.04   0.     0.     0.     0.02   0.     0.     0.     0.     0.\n",
      "    0.06   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.05   0.     0.     2.5\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.09   0.02   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     4.11   0.     0.     0.\n",
      "    0.     7.22   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     4.52   6.54\n",
      "    0.     5.78   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     3.54   0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.02   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.93   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.12   0.     0.     0.     0.     0.     6.64\n",
      "    0.     6.07   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     7.04   0.     0.\n",
      "    0.01   0.     0.  ]\n",
      " [  0.     6.38   0.     0.     0.     0.02   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.47   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.09   7.42   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     6.31   0.02\n",
      "    0.01   0.     0.     0.     0.     0.25   0.     0.     0.35   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.35   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.03   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.07\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.03   5.59   0.     0.     4.8    0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    8.31   0.     0.     0.     0.     0.02   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.03   0.     0.     0.\n",
      "    6.     0.  ]\n",
      " [  0.     6.97   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     7.07   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     4.92   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    3.62   0.     0.     0.     0.     0.     0.     0.     5.57   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.01   0.     0.     0.01   0.     0.01   0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.01   0.     0.01\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     6.03   0.04   0.     0.01\n",
      "    0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.07\n",
      "    0.     0.     0.01   6.88   0.     0.     0.03   0.01   0.     0.     0.\n",
      "    0.     0.01   0.     0.04   0.01   0.     0.     0.     0.     0.01\n",
      "    0.01   0.06   0.     0.     0.     0.     0.01   0.     0.02   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     6.64   0.     0.     0.\n",
      "    0.01   7.14   0.01   0.     0.     0.01   0.  ]\n",
      " [  6.25   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     7.14   0.     0.     0.\n",
      "    0.     0.     0.     0.18   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.02   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.03   0.     0.09   0.\n",
      "    7.22   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.05   0.01   0.     0.13   0.     0.     0.     0.03   0.     0.03\n",
      "    0.     0.     0.     0.     0.     0.     0.05   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.21   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.25   0.     0.     0.  ]\n",
      " [  0.     0.     4.39   0.     0.     0.     0.     0.     5.31   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     8.82   0.     0.\n",
      "    4.83   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.  ]\n",
      " [  0.     0.     0.05   0.     0.     6.76   0.     7.16   0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.01   0.     0.     0.04\n",
      "    0.     0.     0.2    0.     0.     0.     0.     0.01   0.     0.     0.\n",
      "    7.28   0.     0.01   0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.04   0.     0.03   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.06   0.01   0.     0.25   0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.02   0.29   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.01   0.     0.     0.01\n",
      "    0.     0.     0.25   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.  ]\n",
      " [  6.47   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    6.74   0.     0.     0.     0.     0.11   0.     0.     0.25   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     6.25   0.     0.     0.\n",
      "    0.     0.     0.16   0.     0.     0.     0.     0.     0.     4.4    0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.03   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.04   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     6.07   0.03   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     6.87   0.     0.     0.     0.\n",
      "    0.     0.     0.     4.12   0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.2    0.     0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.     6.8    0.     0.09   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    7.11   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     5.43   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     5.18   0.     0.     0.     0.     0.\n",
      "    6.86   0.     0.     0.     0.     0.     0.     0.     0.     3.16\n",
      "    0.     0.     0.     0.  ]\n",
      " [  0.     0.01   0.01   0.     0.     0.     0.     0.01   0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.01   0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     5.78   0.     0.     0.     0.     0.     0.01   0.     0.     0.\n",
      "    0.02   0.01   0.     0.     0.     0.     0.     0.     0.     0.18\n",
      "    0.01   0.     0.01   0.     0.01   6.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     6.82   0.     0.     0.14\n",
      "    0.     6.83   0.     0.     0.01   0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.     0.     0.05   0.     0.     0.     0.\n",
      "    0.01   0.     0.01   0.  ]\n",
      " [  0.08   0.     0.     0.01   0.     0.     0.01   0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.01   7.34   0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     6.7    0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     6.35   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.23   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     6.23   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     5.09\n",
      "    0.     0.     0.     0.     0.04   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     5.36   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     8.63   0.     0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     4.57   0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.     0.     0.     0.01   0.02   0.01   0.     0.     0.01   0.\n",
      "    0.01   0.     0.     0.     0.     0.01   0.     0.     0.     0.05\n",
      "    0.     0.02   0.1    0.19   0.01   0.     0.     0.     0.     0.01\n",
      "    0.01   0.     0.     0.02   0.     0.01   0.     0.     0.01   0.01\n",
      "    0.01   0.01   0.     0.01   0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     6.38   0.01   0.01   0.01   0.     6.72   0.01   0.     0.     0.\n",
      "    0.     0.01   0.     0.01   0.01   0.     0.     0.     0.19   0.\n",
      "    0.01   0.06   0.19   0.     0.     0.     0.01   0.     0.     0.     0.\n",
      "    0.6    6.73   0.     0.     0.     0.02   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.02   0.     0.     0.  ]\n",
      " [  0.     0.02   0.     0.05   0.     0.     0.     0.     0.     0.     4.3\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.01   0.01   8.54\n",
      "    0.     0.     0.     0.01   0.     0.     0.03   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.01   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.01   0.02   0.     0.04   0.     0.     0.02\n",
      "    0.     0.     0.01   0.     0.     0.     0.04   0.05   0.02   0.04\n",
      "    0.     0.     0.     0.     0.     0.01   0.44   0.     0.     0.     0.\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.01   0.     0.     0.\n",
      "    0.01   0.     0.01   0.  ]\n",
      " [  0.     0.08   0.     0.     0.     0.     0.     0.     0.09   6.4    0.\n",
      "    0.     0.01   0.     0.     0.     6.59   0.     0.     0.     0.\n",
      "    0.01   0.     0.01   0.15   0.01   0.     0.01   0.     0.     0.01\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.     0.     6.72\n",
      "    0.     0.     0.23   0.     0.12   0.     0.01   0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.01   0.     0.5    0.14   0.01   0.     0.     0.     0.\n",
      "    0.     0.     0.11   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.33\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     6.73   0.03\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.     0.     0.     5.92   0.     0.41   0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    6.85   0.     0.     0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.26   0.     0.     0.08   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.03\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.04   0.     0.     0.     0.     0.     0.14   0.05\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.06   0.     0.     0.     0.     0.     0.07   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.17   0.     0.02   0.     0.01   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.18   0.     0.     0.     0.     0.     0.     0.03   0.     0.\n",
      "    0.     0.     0.     0.     0.     9.24   0.     0.02   0.     0.     0.\n",
      "    0.     0.     0.     0.08   0.     0.     0.02   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.17   0.     0.19   0.     0.     0.\n",
      "    6.59   0.     0.1 ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    5.15   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     5.69   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     5.64   0.     0.     0.     0.\n",
      "    0.     0.     6.67   0.     0.     0.     0.     0.     0.     0.\n",
      "    8.39   0.     0.  ]\n",
      " [  0.01   0.03   0.01   0.03   0.01   0.02   0.01   0.05   0.     0.88\n",
      "    0.03   0.     0.     0.     0.01   0.02   0.02   0.03   0.01   0.04\n",
      "    0.01   0.03   0.01   0.01   0.01   0.03   0.     0.06   0.     0.01\n",
      "    0.03   0.     0.     0.     0.     0.01   0.01   0.02   0.02   0.01\n",
      "    0.02   0.01   0.     0.01   0.04   0.     0.     0.02   0.01   0.02\n",
      "    0.01   0.01   0.13   0.02   0.01   0.06   0.     0.02   0.04   0.     0.\n",
      "    8.63   0.     0.03   0.03   0.     0.01   0.     0.     0.     0.02\n",
      "    0.01   0.01   0.02   0.     0.     0.     0.01   0.03   0.02   0.01\n",
      "    0.02   0.01   0.     0.04   0.     0.11   0.01   0.04   0.05   0.\n",
      "    0.02   0.     0.     0.01   0.02   0.05   0.     0.03   0.  ]\n",
      " [  0.01   0.     0.     0.02   0.     0.     0.     0.01   0.     6.33\n",
      "    0.01   0.     0.01   0.14   0.     0.     0.01   0.01   0.     0.01\n",
      "    0.     0.     0.01   0.01   0.01   0.01   0.     0.08   0.     0.\n",
      "    7.16   6.6    0.07   0.     0.     0.     0.     0.01   0.01   0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.01   0.02   0.     0.09   0.     0.     0.01   0.     0.     0.\n",
      "    0.     0.01   0.01   5.19   0.01   0.     0.     0.     0.01   0.01\n",
      "    0.01   0.02   0.     0.13   0.     0.     0.01   0.01   0.     0.01\n",
      "    0.     0.     0.01   0.     0.01   0.01   0.01   0.     0.     0.01\n",
      "    0.05   0.     0.     0.     0.     0.     0.     0.  ]\n",
      " [  0.01   0.     0.03   0.     0.     0.     0.     0.     7.42   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.06   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.04   0.     6.19   3.86   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.02   0.     0.     0.     0.01   0.09   0.01   0.     0.01\n",
      "    0.     0.     0.     0.01   0.     7.19   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.03   0.     0.  ]\n",
      " [  0.     0.16   0.01   0.     0.     0.     0.     0.     0.     0.01\n",
      "    5.93   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     5.9    0.     0.01   0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.01   0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.05   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     6.81   0.     0.     0.\n",
      "    0.01   0.09   0.     0.     0.     0.     0.     0.01   0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.04   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     6.84   0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.     0.     0.31   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.07   0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.05   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.01   0.     6.3\n",
      "    6.26   0.     0.     0.     0.     0.     0.     0.     7.46   6.17\n",
      "    0.     0.     0.  ]\n",
      " [  0.     0.     0.     6.32   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     6.68   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     7.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.88   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     4.79   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.  ]\n",
      " [  0.06   0.04   0.     0.     0.     7.11   0.     0.     0.01   0.01\n",
      "    0.01   0.     0.01   0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.02   0.     0.     0.     0.     0.     0.12   0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.25   0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.     0.     0.07   0.\n",
      "    0.15   0.21   0.     5.75   0.     0.     0.     0.     0.01   0.01\n",
      "    0.     0.02   0.     0.     0.     0.     0.     0.02   0.     0.     0.\n",
      "    0.     0.     0.     0.     7.17   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.09   0.     0.  ]\n",
      " [  0.17   0.57   0.52   0.     0.     0.     0.     0.     0.     0.05\n",
      "    0.01   0.     0.02   9.27   0.     0.31   0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.     0.01   0.     0.     0.02   0.     0.01   0.\n",
      "    0.05   0.     0.     0.     0.     0.     0.02   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.01   0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.13   0.     0.03   0.     0.\n",
      "    0.01   0.     0.03   0.     0.     0.     0.     0.05   0.     0.01\n",
      "    0.01   0.     0.     0.     0.     0.     0.01   0.     0.2    0.06\n",
      "    0.     0.04   0.     0.12   0.     0.     0.     0.     0.1    0.     0.\n",
      "    0.05   0.24   0.     0.     0.02   0.  ]\n",
      " [  0.02   0.01   0.01   0.02   0.     0.01   0.     0.     0.01   0.01\n",
      "    0.     0.     0.01   0.     0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.01   0.     0.27   0.03   0.01   0.     0.     0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.01   0.01   0.     0.36   0.01   0.01\n",
      "    0.     0.     0.01   0.07   0.     0.     0.01   0.     7.57   0.01\n",
      "    0.     0.01   0.01   0.01   0.     0.     0.     0.01   0.     0.01\n",
      "    0.     0.     0.01   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.02   0.03   0.32   0.     0.01   0.     0.     0.01   0.01   0.\n",
      "    0.01   0.01   3.57   0.     0.     0.33   0.     0.03   0.     0.     0.\n",
      "    7.3    0.01   0.01   0.     0.01   0.05   0.01   0.  ]\n",
      " [  0.01   0.01   0.01   0.02   0.     0.01   0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.01   0.01   0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.     0.     0.01   0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.01   0.01   0.     0.01   0.     0.\n",
      "    0.     0.     6.49   0.     0.     0.     0.     0.01   0.     0.\n",
      "    5.97   0.01   0.     0.01   0.     0.01   0.33   0.     0.     0.     0.\n",
      "    0.01   0.01   0.01   0.01   0.     0.     0.     0.     0.01   0.     0.\n",
      "    0.     0.01   0.     0.     0.01   0.01   0.01   0.     0.01   0.\n",
      "    0.01   0.     0.     0.     5.2    0.     0.     0.01   7.07   0.     0.\n",
      "    0.01   0.01   0.     0.19   0.  ]\n",
      " [  0.     0.     7.47   0.     0.     0.     0.     0.     0.     0.\n",
      "    7.22   0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.06   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.32   0.     0.     0.     0.     0.     0.7    0.     0.     0.35\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.03   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.62   0.     0.     0.28   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     6.97   0.     0.     0.     0.     0.     0.\n",
      "    7.68   0.     0.     0.02   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.05   0.     4.54   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     6.38   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.32   0.     0.\n",
      "    0.  ]\n",
      " [  0.01   0.     0.     0.01   0.     0.     0.     0.     0.     0.1\n",
      "    0.01   0.     0.     0.     0.     0.     6.81   0.01   0.     0.     0.\n",
      "    0.01   0.     0.     0.     0.01   0.     5.68   0.     0.     0.01\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.01\n",
      "    0.     0.     6.98   0.07   0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.02   0.1    0.     0.01   0.     0.05   0.\n",
      "    0.13   0.     0.01   0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.09   0.     0.27   0.     0.01   0.     0.     0.     0.     0.07\n",
      "    0.     0.     0.01   0.17   0.     0.  ]\n",
      " [  0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.11   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     7.32   0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.11   0.     5.73   0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     6.85   0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "    0.     0.     0.     0.     0.     0.     0.     0.     4.63   0.     0.\n",
      "    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(numpy.min(questions), numpy.min(questions[questions.nonzero()]), numpy.max(questions))\n",
    "print(numpy.min(students), numpy.max(students))\n",
    "print(\"---\")\n",
    "qws = qn_table.get_weights()[0]\n",
    "print(numpy.min(qws), numpy.min(qws[qws>=1]), numpy.max(qn_table.get_weights()[0]))\n",
    "print(numpy.min(s_table.get_weights()[0]), numpy.max(s_table.get_weights()[0]))\n",
    "\n",
    "print(qws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 0.41]\n",
      "[ 0.] [ 0.48]\n",
      "[ 0.] [ 0.46]\n",
      "[ 1.] [ 0.58]\n",
      "[ 1.] [ 0.56]\n",
      "[ 0.] [ 0.58]\n",
      "[ 1.] [ 0.65]\n",
      "[ 1.] [ 0.73]\n",
      "[ 0.] [ 0.57]\n",
      "[ 0.] [ 0.61]\n",
      "[ 0.] [ 0.21]\n",
      "[ 1.] [ 0.31]\n",
      "[ 1.] [ 0.42]\n",
      "[ 0.] [ 0.25]\n",
      "[ 0.] [ 0.38]\n",
      "[ 0.] [ 0.41]\n",
      "[ 0.] [ 0.43]\n",
      "[ 0.] [ 0.63]\n",
      "[ 0.] [ 0.47]\n",
      "[ 0.] [ 0.52]\n",
      "[ 1.] [ 0.69]\n",
      "[ 1.] [ 0.54]\n",
      "[ 1.] [ 0.52]\n",
      "[ 1.] [ 0.55]\n",
      "[ 1.] [ 0.67]\n",
      "[ 1.] [ 0.61]\n",
      "[ 1.] [ 0.47]\n",
      "[ 1.] [ 0.51]\n",
      "[ 0.] [ 0.63]\n",
      "[ 1.] [ 0.76]\n",
      "[ 0.] [ 0.25]\n",
      "[ 0.] [ 0.52]\n",
      "[ 1.] [ 0.7]\n",
      "[ 1.] [ 0.78]\n",
      "[ 1.] [ 0.66]\n",
      "[ 1.] [ 0.48]\n",
      "[ 0.] [ 0.29]\n",
      "[ 0.] [ 0.35]\n",
      "[ 0.] [ 0.34]\n",
      "[ 0.] [ 0.4]\n",
      "[ 1.] [ 0.36]\n",
      "[ 1.] [ 0.42]\n",
      "[ 1.] [ 0.31]\n",
      "[ 1.] [ 0.92]\n",
      "[ 0.] [ 0.29]\n",
      "[ 1.] [ 0.32]\n",
      "[ 0.] [ 0.44]\n",
      "[ 0.] [ 0.64]\n",
      "[ 0.] [ 0.46]\n",
      "[ 1.] [ 0.57]\n",
      "[ 1.] [ 0.74]\n",
      "[ 0.] [ 0.74]\n",
      "[ 0.] [ 0.74]\n",
      "[ 0.] [ 0.51]\n",
      "[ 1.] [ 0.69]\n",
      "[ 1.] [ 0.58]\n",
      "[ 1.] [ 0.67]\n",
      "[ 1.] [ 0.56]\n",
      "[ 0.] [ 0.59]\n",
      "[ 0.] [ 0.44]\n",
      "[ 1.] [ 0.4]\n",
      "[ 0.] [ 0.3]\n",
      "[ 0.] [ 0.57]\n",
      "[ 0.] [ 0.47]\n",
      "[ 0.] [ 0.59]\n",
      "[ 0.] [ 0.56]\n",
      "[ 0.] [ 0.54]\n",
      "[ 0.] [ 0.17]\n",
      "[ 0.] [ 0.42]\n",
      "[ 0.] [ 0.42]\n",
      "[ 0.] [ 0.23]\n",
      "[ 1.] [ 0.5]\n",
      "[ 1.] [ 0.39]\n",
      "[ 0.] [ 0.37]\n",
      "[ 1.] [ 0.8]\n",
      "[ 0.] [ 0.71]\n",
      "[ 0.] [ 0.5]\n",
      "[ 1.] [ 0.96]\n",
      "[ 0.] [ 0.47]\n",
      "[ 0.] [ 0.18]\n",
      "[ 0.] [ 0.59]\n",
      "[ 0.] [ 0.44]\n",
      "[ 1.] [ 0.41]\n",
      "[ 0.] [ 0.17]\n",
      "[ 0.] [ 0.5]\n",
      "[ 1.] [ 0.42]\n",
      "[ 1.] [ 0.45]\n",
      "[ 1.] [ 0.83]\n",
      "[ 0.] [ 0.24]\n",
      "[ 1.] [ 0.57]\n",
      "[ 1.] [ 0.61]\n",
      "[ 1.] [ 0.58]\n",
      "[ 0.] [ 0.24]\n",
      "[ 0.] [ 0.36]\n",
      "[ 0.] [ 0.38]\n",
      "[ 0.] [ 0.23]\n",
      "[ 0.] [ 0.34]\n",
      "[ 1.] [ 0.6]\n",
      "[ 1.] [ 0.52]\n",
      "[ 1.] [ 0.68]\n",
      "0.629111111111\n"
     ]
    }
   ],
   "source": [
    "preds = m.predict(x=[qz,sz])\n",
    "for sc_true, sc_hat in zip(pfz[0:100],preds[0:100]):\n",
    "    print(sc_true, sc_hat)\n",
    "\n",
    "# print(m.evaluate(x=[mz,vz], y=scz))\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "print(accuracy_score(numpy.around(pfz), numpy.around(preds)  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NN_utils.BigTable object at 0x7fa41a6c2240> <NN_utils.BigTable object at 0x7fa41a6c2b00> Tensor(\"psi_select_56:0\", shape=(?, 1), dtype=int32) Tensor(\"q_select_56:0\", shape=(?, 1), dtype=int32)\n",
      "psi_sel shape (?, 1)\n",
      "<keras.initializers.RandomUniform object at 0x7fa41a6f4828>\n",
      "kk (100, 100)\n",
      "selector shape (?, 1)\n",
      "flat selector shape (?,)\n",
      "call kk (100, 100)\n",
      "'rows' shape, (?, 100)\n",
      "<keras.initializers.RandomUniform object at 0x7fa41a68edd8>\n",
      "kk (100, 100)\n",
      "selector shape (?, 1)\n",
      "flat selector shape (?,)\n",
      "call kk (100, 100)\n",
      "'rows' shape, (?, 100)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "psi_select (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "q_select (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "big_table_81 (BigTable)         (None, 100)          10000       psi_select[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "big_table_82 (BigTable)         (None, 100)          10000       q_select[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "subtract_57 (Subtract)          (None, 100)          0           big_table_81[0][0]               \n",
      "                                                                 big_table_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Pr_sigmoid1 (Lambda)            (None, 100)          0           subtract_57[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_196 (Lambda)             (None, 100)          0           big_table_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_197 (Lambda)             (None, 100)          0           Pr_sigmoid1[0][0]                \n",
      "                                                                 lambda_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "score (Lambda)                  (None, 1)            0           lambda_197[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 20,000\n",
      "Trainable params: 20,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 3s 429us/step - loss: 0.2593 - acc: 0.5129 - val_loss: 0.2583 - val_acc: 0.5200\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2586 - acc: 0.5129 - val_loss: 0.2581 - val_acc: 0.5200\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2580 - acc: 0.5129 - val_loss: 0.2579 - val_acc: 0.5200\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2574 - acc: 0.5131 - val_loss: 0.2577 - val_acc: 0.5200\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2569 - acc: 0.5132 - val_loss: 0.2575 - val_acc: 0.5200\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2563 - acc: 0.5131 - val_loss: 0.2573 - val_acc: 0.5200\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2558 - acc: 0.5130 - val_loss: 0.2571 - val_acc: 0.5200\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2553 - acc: 0.5131 - val_loss: 0.2570 - val_acc: 0.5200\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2548 - acc: 0.5131 - val_loss: 0.2568 - val_acc: 0.5200\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2543 - acc: 0.5134 - val_loss: 0.2566 - val_acc: 0.5200\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2539 - acc: 0.5143 - val_loss: 0.2565 - val_acc: 0.5200\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2535 - acc: 0.5145 - val_loss: 0.2563 - val_acc: 0.5200\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2530 - acc: 0.5146 - val_loss: 0.2562 - val_acc: 0.5190\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2526 - acc: 0.5144 - val_loss: 0.2561 - val_acc: 0.5190\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2523 - acc: 0.5140 - val_loss: 0.2559 - val_acc: 0.5190\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2519 - acc: 0.5141 - val_loss: 0.2558 - val_acc: 0.5200\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2515 - acc: 0.5149 - val_loss: 0.2557 - val_acc: 0.5190\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2512 - acc: 0.5155 - val_loss: 0.2556 - val_acc: 0.5190\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2508 - acc: 0.5156 - val_loss: 0.2555 - val_acc: 0.5190\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2505 - acc: 0.5150 - val_loss: 0.2554 - val_acc: 0.5190\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2502 - acc: 0.5162 - val_loss: 0.2553 - val_acc: 0.5170\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2499 - acc: 0.5166 - val_loss: 0.2552 - val_acc: 0.5170\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2496 - acc: 0.5177 - val_loss: 0.2551 - val_acc: 0.5170\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2493 - acc: 0.5189 - val_loss: 0.2550 - val_acc: 0.5180\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2491 - acc: 0.5187 - val_loss: 0.2549 - val_acc: 0.5180\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2488 - acc: 0.5193 - val_loss: 0.2548 - val_acc: 0.5190\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2486 - acc: 0.5193 - val_loss: 0.2548 - val_acc: 0.5190\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2483 - acc: 0.5204 - val_loss: 0.2547 - val_acc: 0.5190\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2481 - acc: 0.5219 - val_loss: 0.2546 - val_acc: 0.5190\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2478 - acc: 0.5230 - val_loss: 0.2546 - val_acc: 0.5170\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2476 - acc: 0.5239 - val_loss: 0.2545 - val_acc: 0.5170\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2474 - acc: 0.5253 - val_loss: 0.2544 - val_acc: 0.5160\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2472 - acc: 0.5257 - val_loss: 0.2544 - val_acc: 0.5170\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2470 - acc: 0.5280 - val_loss: 0.2543 - val_acc: 0.5170\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2468 - acc: 0.5293 - val_loss: 0.2543 - val_acc: 0.5160\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2466 - acc: 0.5301 - val_loss: 0.2542 - val_acc: 0.5160\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2464 - acc: 0.5316 - val_loss: 0.2542 - val_acc: 0.5170\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2463 - acc: 0.5327 - val_loss: 0.2541 - val_acc: 0.5170\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2461 - acc: 0.5333 - val_loss: 0.2541 - val_acc: 0.5170\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2459 - acc: 0.5365 - val_loss: 0.2541 - val_acc: 0.5170\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2457 - acc: 0.5381 - val_loss: 0.2540 - val_acc: 0.5160\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2456 - acc: 0.5390 - val_loss: 0.2540 - val_acc: 0.5140\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2454 - acc: 0.5396 - val_loss: 0.2540 - val_acc: 0.5130\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2453 - acc: 0.5411 - val_loss: 0.2539 - val_acc: 0.5130\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2451 - acc: 0.5425 - val_loss: 0.2539 - val_acc: 0.5140\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2450 - acc: 0.5424 - val_loss: 0.2539 - val_acc: 0.5130\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2448 - acc: 0.5452 - val_loss: 0.2538 - val_acc: 0.5130\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2447 - acc: 0.5470 - val_loss: 0.2538 - val_acc: 0.5120\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2445 - acc: 0.5485 - val_loss: 0.2538 - val_acc: 0.5110\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2444 - acc: 0.5504 - val_loss: 0.2538 - val_acc: 0.5110\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2443 - acc: 0.5510 - val_loss: 0.2538 - val_acc: 0.5100\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2441 - acc: 0.5539 - val_loss: 0.2537 - val_acc: 0.5100\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2440 - acc: 0.5556 - val_loss: 0.2537 - val_acc: 0.5090\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2439 - acc: 0.5577 - val_loss: 0.2537 - val_acc: 0.5090\n",
      "Epoch 55/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2438 - acc: 0.5578 - val_loss: 0.2537 - val_acc: 0.5090\n",
      "Epoch 56/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2437 - acc: 0.5595 - val_loss: 0.2537 - val_acc: 0.5090\n",
      "Epoch 57/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2435 - acc: 0.5609 - val_loss: 0.2537 - val_acc: 0.5090\n",
      "Epoch 58/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2434 - acc: 0.5623 - val_loss: 0.2537 - val_acc: 0.5090\n",
      "Epoch 59/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2433 - acc: 0.5629 - val_loss: 0.2536 - val_acc: 0.5100\n",
      "Epoch 60/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2432 - acc: 0.5633 - val_loss: 0.2536 - val_acc: 0.5100\n",
      "Epoch 61/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2431 - acc: 0.5653 - val_loss: 0.2536 - val_acc: 0.5100\n",
      "Epoch 62/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2430 - acc: 0.5660 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 63/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2429 - acc: 0.5681 - val_loss: 0.2536 - val_acc: 0.5080\n",
      "Epoch 64/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2428 - acc: 0.5701 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 65/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2427 - acc: 0.5715 - val_loss: 0.2536 - val_acc: 0.5080\n",
      "Epoch 66/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2426 - acc: 0.5721 - val_loss: 0.2536 - val_acc: 0.5070\n",
      "Epoch 67/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2425 - acc: 0.5729 - val_loss: 0.2536 - val_acc: 0.5070\n",
      "Epoch 68/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2424 - acc: 0.5724 - val_loss: 0.2536 - val_acc: 0.5070\n",
      "Epoch 69/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2423 - acc: 0.5735 - val_loss: 0.2536 - val_acc: 0.5070\n",
      "Epoch 70/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2422 - acc: 0.5749 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 71/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2421 - acc: 0.5760 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 72/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2420 - acc: 0.5774 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 73/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2419 - acc: 0.5770 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 74/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2418 - acc: 0.5776 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 75/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2417 - acc: 0.5791 - val_loss: 0.2536 - val_acc: 0.5100\n",
      "Epoch 76/1000\n",
      "8000/8000 [==============================] - 0s 6us/step - loss: 0.2416 - acc: 0.5796 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 77/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2415 - acc: 0.5805 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 78/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2414 - acc: 0.5801 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 79/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2413 - acc: 0.5801 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 80/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2412 - acc: 0.5812 - val_loss: 0.2536 - val_acc: 0.5120\n",
      "Epoch 81/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2412 - acc: 0.5828 - val_loss: 0.2536 - val_acc: 0.5120\n",
      "Epoch 82/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2411 - acc: 0.5826 - val_loss: 0.2536 - val_acc: 0.5130\n",
      "Epoch 83/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2410 - acc: 0.5829 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 84/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2409 - acc: 0.5840 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 85/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2408 - acc: 0.5851 - val_loss: 0.2536 - val_acc: 0.5100\n",
      "Epoch 86/1000\n",
      "8000/8000 [==============================] - 0s 9us/step - loss: 0.2407 - acc: 0.5854 - val_loss: 0.2536 - val_acc: 0.5090\n",
      "Epoch 87/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2407 - acc: 0.5867 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 88/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2406 - acc: 0.5867 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 89/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2405 - acc: 0.5873 - val_loss: 0.2536 - val_acc: 0.5120\n",
      "Epoch 90/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2404 - acc: 0.5880 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 91/1000\n",
      "8000/8000 [==============================] - 0s 7us/step - loss: 0.2403 - acc: 0.5886 - val_loss: 0.2536 - val_acc: 0.5110\n",
      "Epoch 92/1000\n",
      "8000/8000 [==============================] - 0s 11us/step - loss: 0.2402 - acc: 0.5883 - val_loss: 0.2537 - val_acc: 0.5120\n",
      "Epoch 93/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2402 - acc: 0.5880 - val_loss: 0.2537 - val_acc: 0.5130\n",
      "Epoch 94/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2401 - acc: 0.5876 - val_loss: 0.2537 - val_acc: 0.5140\n",
      "Epoch 95/1000\n",
      "8000/8000 [==============================] - 0s 8us/step - loss: 0.2400 - acc: 0.5881 - val_loss: 0.2537 - val_acc: 0.5140\n",
      "Epoch 96/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2399 - acc: 0.5884 - val_loss: 0.2537 - val_acc: 0.5130\n",
      "Epoch 97/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2398 - acc: 0.5892 - val_loss: 0.2537 - val_acc: 0.5110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2398 - acc: 0.5896 - val_loss: 0.2537 - val_acc: 0.5130\n",
      "Epoch 99/1000\n",
      "8000/8000 [==============================] - 0s 10us/step - loss: 0.2397 - acc: 0.5905 - val_loss: 0.2537 - val_acc: 0.5130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa41a5c3fd0>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# wz = m.get_weights()\n",
    "s_table =  BigTable((n_students, n_factors), 6, 100, init_hilo=10)#, regulariser=regularizers.l1(10e-6))\n",
    "qn_table = BigTable((n_questions, n_factors), 0, 100, init_hilo=10-p50)#, regulariser=regularizers.l1(10e-6))\n",
    "m = generate_qs_model(qn_table, s_table, Adam(), comp_lims=False)\n",
    "# m.set_weights(wz)\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", restore_best_weights=True, patience=25)\n",
    "m.fit(x=[qz,sz], y=pfz, batch_size=1000, epochs=1000, validation_split=1000/len(pfz), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 1000\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.27] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.33] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.38] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.54] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.36] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.36] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.52] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.35] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.37] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.55] right\n",
      "[ 1.] [ 0.4] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.36] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.4] X\n",
      "[ 0.] [ 0.28] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.36] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.34] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.4] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.56] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.4] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.39] X\n",
      "[ 1.] [ 0.32] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.39] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.56] right\n",
      "[ 1.] [ 0.38] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.38] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.54] right\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.34] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.56] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.36] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.4] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.55] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.36] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.6] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.32] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.38] right\n",
      "[ 0.] [ 0.57] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.58] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 1.] [ 0.37] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.5] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.37] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.31] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.56] X\n",
      "[ 1.] [ 0.35] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.32] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.38] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.37] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.55] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.38] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.38] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.39] X\n",
      "[ 1.] [ 0.59] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.32] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.4] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.6] X\n",
      "[ 1.] [ 0.4] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.31] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.39] X\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.32] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.39] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.37] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.36] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.54] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.57] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.56] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.37] X\n",
      "[ 1.] [ 0.37] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.38] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.39] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.4] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.56] X\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.4] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.58] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.53] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.56] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.56] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.55] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.4] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.38] X\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.32] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.56] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.56] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.55] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.38] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.38] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.36] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 0.] [ 0.36] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.55] right\n",
      "[ 1.] [ 0.56] right\n",
      "[ 1.] [ 0.5] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.54] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.57] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.36] X\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.55] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.36] X\n",
      "[ 1.] [ 0.4] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.36] X\n",
      "[ 1.] [ 0.38] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.52] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.33] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.37] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.39] X\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.] [ 0.52] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.39] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.42] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.37] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.59] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.43] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 1.] [ 0.56] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.43] X\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.31] right\n",
      "[ 0.] [ 0.5] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 1.] [ 0.55] right\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.4] X\n",
      "[ 1.] [ 0.36] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 1.] [ 0.36] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 0.] [ 0.35] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.36] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.53] X\n",
      "[ 1.] [ 0.55] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.51] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.39] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.52] right\n",
      "[ 1.] [ 0.5] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.55] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 0.] [ 0.38] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.39] right\n",
      "[ 1.] [ 0.49] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.5] X\n",
      "[ 0.] [ 0.34] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.38] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 1.] [ 0.44] X\n",
      "[ 0.] [ 0.42] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.32] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.39] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 1.] [ 0.39] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.41] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 0.] [ 0.56] X\n",
      "[ 0.] [ 0.56] X\n",
      "[ 1.] [ 0.52] right\n",
      "[ 0.] [ 0.34] right\n",
      "[ 0.] [ 0.53] X\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.52] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 0.] [ 0.39] right\n",
      "[ 1.] [ 0.46] X\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.51] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 0.] [ 0.48] right\n",
      "[ 0.] [ 0.41] right\n",
      "[ 0.] [ 0.5] right\n",
      "[ 1.] [ 0.42] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 1.] [ 0.5] X\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.54] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.47] X\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.44] X\n",
      "[ 1.] [ 0.45] X\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.4] X\n",
      "[ 0.] [ 0.44] right\n",
      "[ 0.] [ 0.49] right\n",
      "[ 0.] [ 0.4] right\n",
      "[ 0.] [ 0.45] right\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.43] X\n",
      "[ 0.] [ 0.47] right\n",
      "[ 1.] [ 0.48] X\n",
      "[ 0.] [ 0.46] right\n",
      "[ 1.] [ 0.53] right\n",
      "[ 1.] [ 0.41] X\n",
      "[ 1.] [ 0.38] X\n",
      "[ 1.] [ 0.54] right\n",
      "[ 0.] [ 0.53] X\n",
      "(1000, 1)\n",
      "obvsd acc 0.513\n"
     ]
    }
   ],
   "source": [
    "print(len(pfz), len(tpfz))\n",
    "right_ct=0\n",
    "preds = m.predict(x=[tqz,tsz])\n",
    "for sc_obsv, sc_hat in zip(tpfz,preds):\n",
    "#     if ((sc_obsv==0.5 and abs(sc_obsv-sc_hat)<0.33) or abs(sc_obsv-sc_hat)<0.33):\n",
    "#         right_ct+=1\n",
    "#         res = \"right\"\n",
    "#     else:\n",
    "#         res = \"X\"\n",
    "    print(sc_obsv, sc_hat, \"right\" if (numpy.around(sc_obsv)==numpy.around(sc_hat)) else \"X\")\n",
    "#     print(sc_obsv, sc_hat, res)\n",
    "\n",
    "# print(m.evaluate(x=[tmz,tvz], y=tscz))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "print(preds.shape)\n",
    "\n",
    "# print(right_ct / len(tpfz))\n",
    "print(\"obvsd acc\", accuracy_score(numpy.around(tpfz), numpy.around(preds)))\n",
    "# print(\"non-stoch acc\", accuracy_score(numpy.around(t_probz), numpy.around(preds)))\n",
    "# print(mean_absolute_error(t_probz, preds))\n",
    "#0.000302638761699 MSE MxMul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 6.0 16.6164914774\n",
      "6.0 12.0\n",
      "---\n",
      "0.0 1.00032 10.1379\n",
      "6.0 18.0149\n",
      "[[  1.31462240e+00   7.82334089e-01   9.32355993e-04 ...,   1.87579036e-01\n",
      "    6.48720562e-01   4.25799787e-01]\n",
      " [  5.46614170e-01   2.84296840e-01   4.81818207e-02 ...,   4.11244810e-01\n",
      "    1.17232621e+00   0.00000000e+00]\n",
      " [  3.60608399e-02   5.23219204e+00   1.63931280e-01 ...,   3.35171717e-05\n",
      "    0.00000000e+00   3.11339408e-01]\n",
      " ..., \n",
      " [  9.43937823e-02   8.76701474e-01   8.96934271e-01 ...,   6.43221894e-03\n",
      "    5.71834564e-01   2.06799433e-01]\n",
      " [  1.01092458e+00   3.39664556e-02   4.17214441e+00 ...,   3.97692323e-01\n",
      "    7.21869409e-01   7.73381591e-01]\n",
      " [  1.11959314e+00   2.60252468e-02   8.73619556e-01 ...,   1.00694215e+00\n",
      "    5.52023351e-01   1.19834459e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa472569898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(numpy.min(questions), numpy.min(questions[questions.nonzero()]), numpy.max(questions))\n",
    "print(numpy.min(students), numpy.max(students))\n",
    "print(\"---\")\n",
    "qws = qn_table.get_weights()[0]\n",
    "sws = s_table.get_weights()[0]\n",
    "print(numpy.min(qws), numpy.min(qws[qws>=1]), numpy.max(qn_table.get_weights()[0]))\n",
    "print(numpy.min(s_table.get_weights()[0]), numpy.max(s_table.get_weights()[0]))\n",
    "\n",
    "print(qws)\n",
    "\n",
    "plt.hist(qws.flatten(), alpha=.5)\n",
    "plt.hist(sws.flatten(), alpha=.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.2\n",
      "[[1137 3924]\n",
      " [ 335 4604]]\n",
      "0.5741\n",
      " \n",
      "Threshold: 0.3\n",
      "[[1819 3242]\n",
      " [ 724 4215]]\n",
      "0.6034\n",
      " \n",
      "Threshold: 0.4\n",
      "[[2479 2582]\n",
      " [1152 3787]]\n",
      "0.6266\n",
      " \n",
      "Threshold: 0.5\n",
      "[[3138 1923]\n",
      " [1656 3283]]\n",
      "0.6421\n",
      " \n",
      "Threshold: 0.6\n",
      "[[3734 1327]\n",
      " [2265 2674]]\n",
      "0.6408\n",
      " \n",
      "obvsd acc 0.6421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for threshold in [0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "    print(\"Threshold:\", threshold)\n",
    "    bool_preds = (preds >= threshold)\n",
    "    print(confusion_matrix(tpfz, bool_preds))\n",
    "    print(accuracy_score(tpfz, bool_preds))\n",
    "    print(\" \")\n",
    "\n",
    "bool_preds = numpy.around(preds)\n",
    "print(\"obvsd acc\", accuracy_score(tpfz, numpy.around(preds)))\n",
    "#.8263 v 7814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_arr_arr_err(split, real_wgts, pred_wgts, max_iter=10):\n",
    "    from scipy.spatial.distance import cosine\n",
    "# pred_wgts = numpy.round(pred_wgts,1)\n",
    "\n",
    "    out_cols = [None] * len(real_wgts.T)\n",
    "    curr_sel = None\n",
    "    curr_ix = None\n",
    "    n_iters = 10\n",
    "    chosen = None\n",
    "    \n",
    "    indices = range(len(real_wgts.T))\n",
    "\n",
    "    min_total_err = math.inf\n",
    "    best_dis = math.inf\n",
    "    for i in range(max_iter): #len(indices)**2):\n",
    "        real_used = set()\n",
    "        pred_used = set()\n",
    "        while len(pred_used) < len(indices):\n",
    "            curr_err = math.inf\n",
    "            curr_cos = math.inf\n",
    "            for rix in numpy.random.permutation(indices):\n",
    "                if rix in real_used:\n",
    "                    continue\n",
    "                real_col = real_wgts.T[rix]\n",
    "                for cix in numpy.random.permutation(indices):\n",
    "                    if cix in pred_used:\n",
    "                        continue\n",
    "                    pred_col = pred_wgts.T[cix]\n",
    "                    pred_col = pred_col #* pred_q_col\n",
    "                    err = numpy.mean(numpy.abs( pred_col - real_col))\n",
    "                    \n",
    "                    if err < curr_err:\n",
    "                        curr_sel = pred_col\n",
    "                        curr_err = err\n",
    "                        curr_cos = 0#cosine(pred_col, real_col)\n",
    "                        curr_ix = cix\n",
    "                        curr_real_ix = rix\n",
    "            real_used.add(curr_real_ix)\n",
    "            pred_used.add(curr_ix)\n",
    "            out_cols[curr_real_ix] = curr_sel\n",
    "        out_col_arr = numpy.array(out_cols).T\n",
    "        total_err = numpy.mean(numpy.abs( out_col_arr - real_wgts ))\n",
    "        \n",
    "        dis = 0\n",
    "        mean_ll = numpy.mean( out_col_arr - real_wgts )\n",
    "        if total_err < min_total_err:\n",
    "            min_total_err = total_err\n",
    "            total_q_err = numpy.mean(numpy.abs( out_col_arr[0:split] - real_wgts[0:split] ))\n",
    "            total_s_err = numpy.mean(numpy.abs( out_col_arr[split:] - real_wgts[split:] ))\n",
    "            best_ll = mean_ll\n",
    "            chosen = out_col_arr\n",
    "            best_dis = dis\n",
    "    return chosen, min_total_err, total_q_err, total_s_err, mean_ll, best_dis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_wgts = qn_table.get_weights()[0]\n",
    "real_wgts = questions\n",
    "\n",
    "split = 0\n",
    "\n",
    "items_chosen, min_total_err, total_q_err, total_s_err, mean_ll, best_cos_dis = calc_arr_arr_err(0, real_wgts, pred_wgts, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_total_err, total_q_err, total_s_err)\n",
    "\n",
    "print(items_chosen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fig = plt.gcf()\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "# pca = TSNE(n_components=2)\n",
    "\n",
    "itemz_pred = items_chosen\n",
    "n = len(items_chosen)\n",
    "itemz = questions\n",
    "\n",
    "# s_pred_mean = numpy.mean(s_table.get_weights()[0])\n",
    "base = min( numpy.min(itemz_pred), numpy.min(itemz))\n",
    "# ss1 = StandardScaler()\n",
    "# itemz_pred = ss1.fit_transform(itemz_pred)\n",
    "# itemz = ss1.transform(movies)\n",
    "\n",
    "itemz = itemz - base\n",
    "itemz_pred = itemz_pred - base\n",
    "\n",
    "print(itemz)\n",
    "print(itemz_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemz_pred = pca.transform(itemz_pred)\n",
    "\n",
    "itemz_2 = numpy.concatenate([itemz, itemz_pred], axis=0)\n",
    "# itemz_2 = itemz\n",
    "itemz_2 = pca.fit_transform(itemz_2)\n",
    "\n",
    "# itemz_2 = MinMaxScaler().fit_transform(itemz_2)\n",
    "\n",
    "# ixes = itemz_pred < baseline\n",
    "# itemz_pred[ixes] = (baseline-1)\n",
    "# itemz_pred = itemz_pred - (baseline-1)\n",
    "# itemz_pred = MinMaxScaler().fit_transform(itemz_pred)\n",
    "# print(itemz_2)\n",
    "\n",
    "# fig,axs = plt.subplots(1,2)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 10)\n",
    "\n",
    "fig.gca().scatter(itemz_2[0:n,0], itemz_2[0:n,1], alpha=0.7)\n",
    "fig.gca().scatter(itemz_2[n:,0], itemz_2[n:,1], alpha=0.7)\n",
    "j=0\n",
    "for j in range(n):\n",
    "    x,xh,y,yh = itemz_2[j,0], itemz_2[j+n,0], itemz_2[j,1], itemz_2[j+n,1]\n",
    "    fig.gca().plot([x,xh],[y,yh],color=\"#aaaaaa\")\n",
    "    fig.gca().annotate(j, (itemz_2[j+n,0], itemz_2[j+n,1]))\n",
    "\n",
    "# fig.gca().scatter(itemz_pred[:,0], itemz_pred[:,1], alpha=0.5)\n",
    "\n",
    "# for i, txt in enumerate(itemz_2):\n",
    "#     fig.gca().annotate(i, (itemz_2[i,0], itemz_2[i,1]))\n",
    "\n",
    "# fig.gca().axvline(x=baseline, linestyle=\"--\")\n",
    "# fig.gca().axhline(y=baseline, linestyle=\"--\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
