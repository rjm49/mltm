{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigTable MTLM - dataset perplexity testing\n",
    "\n",
    "Aim of this notebook:\n",
    "1. Generate student + question datasets\n",
    "2. Generate N sets of encounters\n",
    "3. Report on agreement between these sets\n",
    "\n",
    "The error between the datasets (for large N) is the inherent probabilistic error in the model\n",
    "- How does this translate to tolerances in the $\\alpha$ and $\\delta$ parameters\n",
    "\n",
    "## Model perplexity\n",
    "A model $q$ is used to predict the values of a set of samples, $\\mathbf{x}$.  Perplexity is defined as:\n",
    "\n",
    "\\\\[{perplex}_{q}(\\mathbf{x}) = b^{-\\frac{1}{N}\\Sigma_{i=1}^{N}{log_{b}(q(x_i))}}\\\\]\n",
    "\n",
    "Perplexity is a measure of `surprise' as a divergence from the predictions that are seen in the true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.954820514989862"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from copy import copy\n",
    "from math import exp, sqrt, log\n",
    "from random import random, shuffle, choice, randint, uniform\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.constraints import non_neg, max_norm\n",
    "from numpy import array, mean, ones\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, multiply, subtract, add, Activation, Lambda, Flatten\n",
    "from keras.layers import Dense, concatenate, MaxPooling1D, LocallyConnected1D, Reshape, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras import constraints\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import generate_student_name, create_qs, create_students, generate_attempts, calculate_pass_probability, attempt_q\n",
    "\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# p = 1 / (1 + e^-z)\n",
    "# -ln((1/ p) - 1) = z\n",
    "-log((1/0.993) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # %%capture\n",
    "# from IPython.display import clear_output\n",
    "\n",
    "# serieses = []\n",
    "# min_errs = []\n",
    "# n_items = 100\n",
    "# n_students = 1000\n",
    "# # desired confusion prop/n mx\n",
    "# # .5  0 \n",
    "# #  0 .5\n",
    "\n",
    "# def gen_run(n_traits, minb, maxb, mu_th, sd_th, min_active_traits, max_active_traits):\n",
    "#     qs = create_qs(n_items, n_traits, (min_active_traits, max_active_traits), minb, maxb)\n",
    "# #     #     qs, q_table = create_qs_from_blobs(n_qs, 2, n_traits)\n",
    "#     ss = create_students(n_students, n_traits, mu_th, sd_th)\n",
    "\n",
    "#     x = []\n",
    "\n",
    "#     for _ in range(1):\n",
    "#         xa, _,_,_ = generate_attempts(qs,ss) # this is our x list of samples\n",
    "#         x.extend(xa)\n",
    "    \n",
    "# #     gaussian_pts = numpy.random.uniform((mu_th-3.0*sd_th),(mu_th+3.0*sd_th), n_students)\n",
    "# #     uniform_pts = numpy.random.uniform(minb, maxb, n_items)\n",
    "# #     gaussian_pts = numpy.repeat(gaussian_pts, n_items)\n",
    "# #     uniform_pts = numpy.tile(uniform_pts, n_students)     \n",
    "    \n",
    "#     tp,fp,tn,fn=0,0,0,0\n",
    "#     base = 2\n",
    "#     summa=0\n",
    "#     N = len(x)\n",
    "#     probs = []\n",
    "#     for tup in x:\n",
    "#         (psi_id, q_id, passed, passed) = tup\n",
    "#         p = calculate_pass_probability(ss[psi_id].thetas, qs[q_id].betas)\n",
    "#         summa += log((p if passed else (1-p)), base)\n",
    "#         probs.append(p)\n",
    "        \n",
    "#         pp = uniform(0,1)\n",
    "#         if pp <= p:\n",
    "#             if passed:\n",
    "#                 tp+=1\n",
    "#             else:\n",
    "#                 fp+=1\n",
    "#         else:\n",
    "#             if passed:\n",
    "#                 fn+=1\n",
    "#             else:\n",
    "#                 tn+=1\n",
    "\n",
    "#     acc = (tp+tn)/len(x)\n",
    "#     print(\"model acc:\",acc)\n",
    "#     print(tp,fp)\n",
    "#     print(fn,tn)\n",
    "\n",
    "#     ppx = pow( base, (-summa/N))\n",
    "#     print(\"perplexity is {}\".format(ppx))\n",
    "#     return ((fn + fp) + abs(tp-tn)), probs\n",
    "    \n",
    "# dims_scores = {}\n",
    "# best_probs = {}\n",
    "# param_freedom = 10\n",
    "# random.seed()\n",
    "# seen = set()\n",
    "# mini = 1\n",
    "# maxi = 15\n",
    "# #dimslist = [1,2,3,5,10,25,100]:\n",
    "\n",
    "# dims = 100\n",
    "\n",
    "# inv_sigmoid = lambda pr : ( -log((1/pr) -1) )\n",
    "# min_sprd = inv_sigmoid(0.02**(1/dims))\n",
    "# mid_sprd = inv_sigmoid(0.5**(1/dims))\n",
    "# max_sprd = inv_sigmoid(0.98**(1/dims))\n",
    "\n",
    "# min_b = 1\n",
    "# max_th = min_b + max_sprd\n",
    "\n",
    "\n",
    "# best_run = -1\n",
    "\n",
    "# minb_spd = 2\n",
    "# maxb_spd = 6\n",
    "\n",
    "# for maxi in [20]:\n",
    "#     i=0\n",
    "#     while i < 100:\n",
    "#         rnge = uniform(minb_spd, maxb_spd)\n",
    "#         minb = -rnge/2\n",
    "#         maxb = rnge/2\n",
    "        \n",
    "#         mu_th = uniform(mid_sprd, max_sprd)\n",
    "#         sd_th = uniform(1,2)\n",
    "    \n",
    "#         i+=1\n",
    "#         print(\">>>\",i)\n",
    "#         outz = gen_run(dims, minb, maxb, mu_th, sd_th, dims, dims)\n",
    "#         balance, probz = outz[0], outz[1]\n",
    "\n",
    "#         loss = numpy.mean([abs(p-0.5) for p in probz])\n",
    "        \n",
    "#         sd = numpy.std(numpy.array(probz))\n",
    "        \n",
    "#         print(\"?\",loss,sd)\n",
    "#         if (dims not in dims_scores) or (dims_scores[dims][0] >= loss and dims_scores[dims][2] < sd):\n",
    "#             print(\"+++\")\n",
    "#             dims_scores[dims] = (loss, balance, sd, mu_th,sd_th,minb,maxb)\n",
    "#             best_probs[dims] = probz\n",
    "#             best_run = i-1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 1\n",
      "? 0.247208539901 0.0572729505148\n",
      "+++\n",
      ">>> 2\n",
      "? 0.322355493047 0.0984122235313\n",
      ">>> 3\n",
      "? 0.480964345258 0.0163271269316\n",
      ">>> 4\n",
      "? 0.499951278162 0.000371541714793\n",
      ">>> 5\n",
      "? 0.416459204538 0.0491047869127\n",
      ">>> 6\n",
      "? 0.449982376221 0.0336117305072\n",
      ">>> 7\n",
      "? 0.387886523446 0.0801339335003\n",
      ">>> 8\n",
      "? 0.134201646069 0.0732322097142\n",
      "+++\n",
      ">>> 9\n",
      "? 0.0375483453513 0.0782483395124\n",
      "+++\n",
      ">>> 10\n",
      "? 0.347887947553 0.0287116607152\n",
      ">>> 11\n",
      "? 0.466762811568 0.0245767190481\n",
      ">>> 12\n",
      "? 0.499465451808 0.00249474344661\n",
      ">>> 13\n",
      "? 0.314367770625 0.0720249731627\n",
      ">>> 14\n",
      "? 0.351604026674 0.0577283454374\n",
      ">>> 15\n",
      "? 0.322766130908 0.0745420230274\n",
      ">>> 16\n",
      "? 0.0935611345081 0.0789404567425\n",
      ">>> 17\n",
      "? 0.215259694552 0.0745226612423\n",
      ">>> 18\n",
      "? 0.0145097429241 0.0745585228034\n",
      "+++\n",
      ">>> 19\n",
      "? 0.243778589506 0.0832370633066\n",
      ">>> 20\n",
      "? 0.374202523597 0.0662192258914\n",
      ">>> 21\n",
      "? 0.473351731782 0.0271154965416\n",
      ">>> 22\n",
      "? 0.40279396225 0.0630082471811\n",
      ">>> 23\n",
      "? 0.493192172324 0.00894768628497\n",
      ">>> 24\n",
      "? 0.425777437081 0.0538069118354\n",
      ">>> 25\n",
      "? 0.499379768841 0.00194473227021\n",
      ">>> 26\n",
      "? 0.237152854378 0.0979180597757\n",
      ">>> 27\n",
      "? 0.373849284299 0.0646831288369\n",
      ">>> 28\n",
      "? 0.316547151538 0.101640542791\n",
      ">>> 29\n",
      "? 0.273003389949 0.0897567122918\n",
      ">>> 30\n",
      "? 0.162223214189 0.0765366770642\n",
      ">>> 31\n",
      "? 0.499905337601 0.000547901697711\n",
      ">>> 32\n",
      "? 0.401992114019 0.0473529089549\n",
      ">>> 33\n",
      "? 0.325560713548 0.0788500773223\n",
      ">>> 34\n",
      "? 0.499916663784 0.000688809939571\n",
      ">>> 35\n",
      "? 0.267333513328 0.109371253814\n",
      ">>> 36\n",
      "? 0.478221315155 0.0232801164039\n",
      ">>> 37\n",
      "? 0.477759298207 0.0239331574747\n",
      ">>> 38\n",
      "? 0.464590384804 0.0332936777128\n",
      ">>> 39\n",
      "? 0.405559757846 0.0708601046746\n",
      ">>> 40\n",
      "? 0.0970048899159 0.0936578987164\n",
      ">>> 41\n",
      "? 0.27909082484 0.0347790141968\n",
      ">>> 42\n",
      "? 0.444261204214 0.0439426952653\n",
      ">>> 43\n",
      "? 0.499991765398 9.70327965584e-05\n",
      ">>> 44\n",
      "? 0.49608032663 0.00919644568336\n",
      ">>> 45\n",
      "? 0.400425382004 0.056496151568\n",
      ">>> 46\n",
      "? 0.335357536325 0.100694279698\n",
      ">>> 47\n",
      "? 0.480325327012 0.0219896666721\n",
      ">>> 48\n",
      "? 0.0836658608587 0.093737206587\n",
      ">>> 49\n",
      "? 0.172610618322 0.103958215389\n",
      ">>> 50\n",
      "? 0.454335994366 0.044424704787\n",
      ">>> 51\n",
      "? 0.114451900829 0.109085208682\n",
      ">>> 52\n",
      "? 0.3150752415 0.0989906111207\n",
      ">>> 53\n",
      "? 0.480083380706 0.027948676085\n",
      ">>> 54\n",
      "? 0.465411765051 0.0340911022585\n",
      ">>> 55\n",
      "? 0.47278811134 0.0313145872089\n",
      ">>> 56\n",
      "? 0.477859881045 0.0236795379243\n",
      ">>> 57\n",
      "? 0.1199505948 0.0833633469166\n",
      ">>> 58\n",
      "? 0.498278615221 0.00421207490278\n",
      ">>> 59\n",
      "? 0.390629900676 0.0883634286301\n",
      ">>> 60\n",
      "? 0.442402274906 0.0499999893447\n",
      ">>> 61\n",
      "? 0.497063319675 0.00470452759346\n",
      ">>> 62\n",
      "? 0.498574986374 0.00379033387267\n",
      ">>> 63\n",
      "? 0.155408908462 0.0765309757132\n",
      ">>> 64\n",
      "? 0.0454771990167 0.0800720720109\n",
      ">>> 65\n",
      "? 0.32566292193 0.0839662976481\n",
      ">>> 66\n",
      "? 0.487158827703 0.0225057239815\n",
      ">>> 67\n",
      "? 0.190700263471 0.115032994287\n",
      ">>> 68\n",
      "? 0.321422707334 0.0990662309647\n",
      ">>> 69\n",
      "? 0.486469233308 0.0183657911496\n",
      ">>> 70\n",
      "? 0.132635311587 0.0741053555744\n",
      ">>> 71\n",
      "? 0.499904988609 0.000408374241012\n",
      ">>> 72\n",
      "? 0.364278817513 0.0789838489437\n",
      ">>> 73\n",
      "? 0.153861293961 0.070425865852\n",
      ">>> 74\n",
      "? 0.0989850515268 0.0795672345355\n",
      ">>> 75\n",
      "? 0.318580776999 0.0756607578325\n",
      ">>> 76\n",
      "? 0.226089734203 0.0552862507694\n",
      ">>> 77\n",
      "? 0.211988467138 0.0665342192623\n",
      ">>> 78\n",
      "? 0.00796250306588 0.100143228156\n",
      "+++\n",
      ">>> 79\n",
      "? 0.309315943763 0.0393640810014\n",
      ">>> 80\n",
      "? 0.118129382615 0.117115891112\n",
      ">>> 81\n",
      "? 0.455874634844 0.0428528030485\n",
      ">>> 82\n",
      "? 0.19289258168 0.0682253552563\n",
      ">>> 83\n",
      "? 0.0262598824982 0.107480576698\n",
      ">>> 84\n",
      "? 0.467757812766 0.0306306158887\n",
      ">>> 85\n",
      "? 0.180980936532 0.0511579175258\n",
      ">>> 86\n",
      "? 0.0522133646682 0.0841297609647\n",
      ">>> 87\n",
      "? 0.0722751382545 0.0957330469013\n",
      ">>> 88\n",
      "? 0.472420138024 0.0249658641354\n",
      ">>> 89\n",
      "? 0.471166146304 0.0306198030916\n",
      ">>> 90\n",
      "? 0.446831291032 0.0474717167146\n",
      ">>> 91\n",
      "? 0.479296422948 0.0230828571467\n",
      ">>> 92\n",
      "? 0.00176006932254 0.0920466798644\n",
      "+++\n",
      ">>> 93\n",
      "? 0.176461258722 0.0750266504595\n",
      ">>> 94\n",
      "? 0.473332492784 0.0265911679491\n",
      ">>> 95\n",
      "? 0.251410570684 0.111873969658\n",
      ">>> 96\n",
      "? 0.497900692971 0.00432924147098\n",
      ">>> 97\n",
      "? 0.442738179428 0.0336533570602\n",
      ">>> 98\n",
      "? 0.334799858788 0.0804366742688\n",
      ">>> 99\n",
      "? 0.0159718660112 0.0768748742831\n",
      ">>> 100\n",
      "? 0.16514687635 0.105203023811\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "from IPython.display import clear_output\n",
    "\n",
    "serieses = []\n",
    "min_errs = []\n",
    "n_items = 100\n",
    "n_students = 1000\n",
    "# desired confusion prop/n mx\n",
    "# .5  0 \n",
    "#  0 .5\n",
    "\n",
    "def gen_run(n_traits, minb, maxb, mu_th, sd_th, min_active_traits, max_active_traits):\n",
    "    qs = create_qs(n_items, n_traits, (min_active_traits, max_active_traits), minb, maxb)\n",
    "#     #     qs, q_table = create_qs_from_blobs(n_qs, 2, n_traits)\n",
    "    ss = create_students(n_students, n_traits, mu_th, sd_th)\n",
    "\n",
    "    x = []\n",
    "\n",
    "    for _ in range(1):\n",
    "        xa, _,_,_ = generate_attempts(qs,ss) # this is our x list of samples\n",
    "        x.extend(xa)\n",
    "    \n",
    "#     gaussian_pts = numpy.random.uniform((mu_th-3.0*sd_th),(mu_th+3.0*sd_th), n_students)\n",
    "#     uniform_pts = numpy.random.uniform(minb, maxb, n_items)\n",
    "#     gaussian_pts = numpy.repeat(gaussian_pts, n_items)\n",
    "#     uniform_pts = numpy.tile(uniform_pts, n_students)     \n",
    "    \n",
    "    tp,fp,tn,fn=0,0,0,0\n",
    "    base = 2\n",
    "    summa=0\n",
    "    N = len(x)\n",
    "    probs = []\n",
    "    for tup in x:\n",
    "        (psi_id, q_id, passed, passed) = tup\n",
    "        p = calculate_pass_probability(ss[psi_id].thetas, qs[q_id].betas)\n",
    "        summa += log((p if passed else (1-p)), base)\n",
    "        probs.append(p)\n",
    "        \n",
    "        pp = uniform(0,1)\n",
    "        if pp <= p:\n",
    "            if passed:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "        else:\n",
    "            if passed:\n",
    "                fn+=1\n",
    "            else:\n",
    "                tn+=1\n",
    "\n",
    "    acc = (tp+tn)/len(x)\n",
    "    print(\"model acc:\",acc)\n",
    "    print(tp,fp)\n",
    "    print(fn,tn)\n",
    "\n",
    "    ppx = pow( base, (-summa/N))\n",
    "    print(\"perplexity is {}\".format(ppx))\n",
    "    return ((fn + fp) + abs(tp-tn)), probs\n",
    "    \n",
    "dims_scores = {}\n",
    "best_probs = {}\n",
    "param_freedom = 10\n",
    "random.seed()\n",
    "seen = set()\n",
    "mini = 1\n",
    "maxi = 15\n",
    "#dimslist = [1,2,3,5,10,25,100]:\n",
    "\n",
    "dims = 100\n",
    "\n",
    "inv_sigmoid = lambda pr : ( -log((1/pr) -1) )\n",
    "min_sprd = inv_sigmoid(0.02**(1/dims))\n",
    "mid_sprd = inv_sigmoid(0.5**(1/dims))\n",
    "max_sprd = inv_sigmoid(0.98**(1/dims))\n",
    "\n",
    "min_b = 1\n",
    "max_th = min_b + max_sprd\n",
    "\n",
    "\n",
    "best_run = -1\n",
    "\n",
    "minb_spd = 2\n",
    "maxb_spd = 6\n",
    "\n",
    "for maxi in [20]:\n",
    "    i=0\n",
    "    while i < 100:\n",
    "        rnge = uniform(minb_spd, maxb_spd)\n",
    "        minb = -rnge/2\n",
    "        maxb = rnge/2\n",
    "        \n",
    "        mu_th = uniform(mid_sprd, max_sprd)\n",
    "        sd_th = uniform(1,2)\n",
    "    \n",
    "        i+=1\n",
    "        print(\">>>\",i)\n",
    "        \n",
    "        use_uniform_for_students = True\n",
    "        if use_uniform_for_students:\n",
    "            student_0 = mu_th-3.0*sd_th\n",
    "            student_1 = mu_th+3.0*sd_th\n",
    "            student_pts = numpy.random.uniform(student_0, student_1, (n_students,dims))\n",
    "        else:\n",
    "            student_0 = mu_th\n",
    "            student_1 = sd_th\n",
    "            student_pts = numpy.random.normal(mu_th, sd_th, (n_students,dims))\n",
    "            \n",
    "        uniform_pts = numpy.random.uniform(minb, maxb, (n_items,dims))\n",
    "#         student_pts = student_pts.reshape(n_students, dims)\n",
    "#         uniform_pts = uniform_pts.reshape(n_items, dims )\n",
    "        student_pts = numpy.repeat(student_pts, n_items, axis=0 )\n",
    "        uniform_pts = numpy.tile(uniform_pts, (n_students,1) )\n",
    "        diffs = 1.0 / (1.0 + numpy.exp(-(student_pts - uniform_pts)))\n",
    "        probz = numpy.prod(diffs, axis=1)\n",
    "\n",
    "        loss = numpy.abs(numpy.mean([(p-0.5) for p in probz]))\n",
    "        \n",
    "        sd = numpy.std(numpy.array(probz))\n",
    "        \n",
    "        print(\"?\",loss,sd)\n",
    "        if (dims not in dims_scores) or (dims_scores[dims][0] >= loss and dims_scores[dims][1]*.66 < sd):\n",
    "            print(\"+++\")\n",
    "            dims_scores[dims] = (loss, sd, student_0, student_1,minb,maxb)\n",
    "            best_probs[dims] = probz\n",
    "            best_run = i-1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clear_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7bbf3e6f7e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"
     ]
    }
   ],
   "source": [
    "clear_output()\n",
    "for dim in dims_scores:\n",
    "    print(best_run)\n",
    "    tup = dims_scores[dim]\n",
    "    print(dim, tup)\n",
    "    \n",
    "#     print(best_probs[dim])\n",
    "    \n",
    "    probs = best_probs[dim]\n",
    "    plt.hist(probs)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    (loss, sd, st0 , st1 ,minb,maxb) = tup\n",
    "    offset = 1 - minb\n",
    "    #print((offset+minb, offset+maxb, offset+mu_th-3.0*sd_th, offset+mu_th+3.0*sd_th))\n",
    "    print((offset+minb, offset+maxb, offset+st0, offset+st1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying = [inv_sigmoid(p) for p in probs]\n",
    "plt.hist(underlying)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gaussian_pts = numpy.random.normal(5.15,1.51,1000)\n",
    "# n_students = 100\n",
    "# n_items = 100\n",
    "# n_traits = 100\n",
    "# gaussian_pts = numpy.random.normal(mu_th, sd_th, (n_students*n_traits))\n",
    "# uniform_pts = numpy.random.uniform(minb, maxb, (n_items*n_traits))\n",
    "# gaussian_pts = gaussian_pts.reshape(n_students, n_traits)\n",
    "# uniform_pts = uniform_pts.reshape(n_items, n_traits )\n",
    "# gaussian_pts = numpy.repeat(gaussian_pts, n_items, axis=0 )\n",
    "# uniform_pts = numpy.tile(uniform_pts, (n_students,1) )\n",
    "\n",
    "# print(gaussian_pts)\n",
    "# print(uniform_pts)\n",
    "\n",
    "# diffs = 1.0 / (1.0 + numpy.exp(-(gaussian_pts - uniform_pts)))\n",
    "# pps = numpy.prod(diffs, axis=1)\n",
    "\n",
    "# print(pps.shape)\n",
    "# print(pps)\n",
    "\n",
    "# # print((pt, u) for pt, u in zip(gaussian_pts, uniform_pts))\n",
    "# # transformed_pts = [ numpy.prod(1.0 / (1.0 + exp(-(pt - u)))) for pt,u in zip(gaussian_pts,uniform_pts)]\n",
    "# f,axes = plt.subplots(1,2)\n",
    "# axes[0].hist(pps)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
